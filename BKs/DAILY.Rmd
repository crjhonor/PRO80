---
title: "DAILY PROCESSING"
#author: "CHENRUJIE"
#date: "2022/5/6"
output: 
  flexdashboard::flex_dashboard:
    orientation: rows
    vertical_layout: scroll
    theme: united
---

```{r setup, include=FALSE}
#Loading All Libraries At Once--------------------------------------------------
library(flexdashboard)
library(lubridate)
library(readxl)
library(readr)
library(zoo)
library(xts)
library(mFilter)
library(timeDate)
library(timeSeries)
library(numDeriv)
library(coda)
library(bayesDccGarch)
library(keras)
library(ggplot2)
library(gridExtra)
library(imputeTS)
library(magrittr)
library(ggpubr)
#Rmarkdown Global Setup--------------------------------------------------
library(knitr)
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE,
                      fig.width = 16,
                      fig.height = 7)
#Global Enviornment Setup---------------------------------------------------
globalWD <- getwd()
globalWD.data <- file.path(globalWD, "DATA")
globalStartYear <- c(2010)
globalEndYear <- c(as.numeric(year(Sys.Date())))
midtermYear1 <- c(3) #Parameter for midterm output calculation.
AssFun <- new.env() #Enviornment to store assistant functions.
```

```{r TARGET DEFINE}
##Defining Variables for Trend and Cycle analysis and comparing.
T1 <- "RU0"
T2 <- "RB0"
T3 <- "TA0"
T4 <- "P0"
T5 <- "I0"
T6 <- "SR0"
T7 <- "M0"
T8 <- "AL0"
T9 <- "ZN0"
T10 <- "BU0"
T11 <- "FU0"
CMD.ind <- c(T1, T2, T3, 
             T4, T5, T6, T7, T8, T9, T10, T11,
             "CL00Y")
CUR.ind <- c("GBPUSD", "EURUSD", "AUDUSD", "USDJPY")
```

MacroEco {data-height=3000}
==================================================

### BUILD AT: `r Sys.time()`

All Rights Reserved <br> Rujie Chen <br> 18666712666 <br>

MacroEcoBaselines...... {.tabset .tabset-pills .tabset-fade}
-------------------------------------

### YIELDS PROSPECTS

```{r YIELDS PROSPECT}
Yields.Prospect.text <- matrix(
c("Above 3.00 \n

",
"2.90 \n

",
"Above 2.8 \n

",
"4.00 \n

",
"3.50 \n

",
"3.00 \n

"),
                     nrow = 3, ncol = 2)
  
Yields.Prospect.gg <- ggtexttable(Yields.Prospect.text, 
                            rows = c("Harkwish", "Moderate", "Dovish"),
                            cols = c("CN 10 Year Treasury Yield", "US 10 Year Treasury Yield"),
                    theme = ttheme(colnames.style = colnames_style(color = "black", 
                                                                   fill = "orange",
                                                                   size = 18), 
                    rownames.style = rownames_style(color = "black", 
                                                    fill = "lightblue",
                                                    size = 18),
                    tbody.style = tbody_style(size = 16)))
Yields.Prospect.gg
```

### CURRENCIES PROSPECTS

```{r CURRENCIES PROSPECT}
Currencies.Prospect.text <- matrix(
c("7.00: \n
(1) Rate hikes. \t
(2) Picking up inflation.
",
"Above 6.5: \n
(1) Dynamic Zero policies.\t
(2) US Dollar above 100.
",
"Below 6.5: \n
(1) US Dollar Turmoil. \t
(2) Rate cuts. \n
",
"
Above 110: \n
(1) Monetary Tightening. \t
(2) More rate hikes. \n
",
"
105: \n
(1) Tapering but not Tightening. \t
(2) Rate hikes. \n
",
"
100: \n
(1) Infrastructer Bill. \t
(2) Tapering. \n
"),
                     nrow = 3, ncol = 2)

Currencies.Prospect.gg <- ggtexttable(Currencies.Prospect.text, 
                            rows = c("Harkwish", "Moderate", "Dovish"),
                            cols = c("CHINA YUAN Offshore", "US Dollar Index"),
                    theme = ttheme(colnames.style = colnames_style(color = "purple", 
                                                                   fill = "lightgreen",
                                                                   size = 18), 
                    rownames.style = rownames_style(color = "yellow", 
                                                    fill = "darkgreen",
                                                    size = 18),
                    tbody.style = tbody_style(size = 16)))
Currencies.Prospect.gg
```

### FS OF YIELDS~CMD_PRICE

```{r Commordity Four Stages}
#In order to depict the model of 4 stages, I used package ggpubr and try to output tabel form of the model.
FourStages_CMD.text <- matrix(
c("
(1) Economic growth. \t
(2) Inflation.
(3) Wars / Trade War. \t
(4) Pandemic Resilient.", 
"
(1) Monetary Easing. \t
(2) Global Supply Chain Crunch. \n
",
"
(1) Monetary Tightening. \t
(2) Recession and Deflation. \t
(3) Fighting Inflation. \n
",
"
(1) Economies Slow Down. \t
(2) Political Uncertainties. \t
(3) Unprecedentic Risks. \t"),
nrow = 2, ncol = 2)

FourStage.gg <- ggtexttable(FourStages_CMD.text, rows = c("Yields Rise", "Yield Decline"),
                            cols = c("CMD UP", "CMD DOWN"),
                            theme = ttheme(colnames.style = colnames_style(color = "white", 
                                                                           fill = "purple",
                                                                           size = 18), 
                            rownames.style = rownames_style(color = "blue", 
                                                            fill = "gold",
                                                            size = 18),
                            tbody.style = tbody_style(size = 16)))
FourStage.gg
```


Status
==================================================

yields STATUS.......... {.tabset .tabset-pills .tabset-fade}
-------------------------------------

1) Status of yields.

```{r Data Preparation: yields}
#Functions---------------------------------------
#Functions to Read yields Data From Excel File
AssFun$read_excel_yields <- function(treasury_name){
  #Read Excel File Data.
  TD.read <- read_excel(file.path(globalWD.data, "yields.xls"),
                        col_types = c("text", rep("numeric", length(treasury_name))),
                        col_names = TRUE
  )
  colnames(TD.read) <- c("Date", treasury_name)
  #Subsetting Into 10 Year Window.
  TD.read <- subset.data.frame(TD.read, year(strptime(TD.read[[1]], format = "%Y-%m-%d")) >= globalStartYear)
  #Dealing with NAs.
  TD.read.na <- as.data.frame(na.approx(TD.read[,2:length(TD.read)]))
  TD.read.na <- cbind(TD.read[, 1], TD.read.na)
  colnames(TD.read.na) <- c("Date", treasury_name)
  #Return Dataframe without NAs.
  return(TD.read.na)
}
#Functions for yields to Apply HP Filter and Save to csv Files.
AssFun$hpf_save_yield <- function(proc_data, data_name = NULL, data_date = NULL){
  #Applying HP Filter to yields
  data.HPF <- hpfilter(na.approx(proc_data), freq=2419200, type=c("lambda"), drift = FALSE)
  #Output and Save to csv File if Given the Name.
  if(!is.null(data_name)){
    data.HPF.output <- as.data.frame(data_date[1:length(data.HPF$cycle)])
    data.HPF.output <- cbind(data.HPF.output,
                             proc_data[1:length(data.HPF$cycle)],
                             data.HPF$trend,
                             data.HPF$cycle)
    colnames(data.HPF.output) <- c(paste0(data_name, "Date"),
                         paste0(data_name, "Close"),
                         paste0(data_name, "_hpft"),
                         paste0(data_name, "_hpfc"))
    write.csv(data.HPF.output,file=paste0(file.path(globalWD, "DailyTDs/"), data_name, "DailyTD.csv"), row.names=FALSE)
  }
  #Convert the Output Into xts Object and Return.
  data.HPF.output.xts <- xts(data.HPF.output[, -1], order.by = data.HPF.output[[1]])
  return(data.HPF.output.xts)
}

#Processing--------------------------------------
#Read yields
ref_yields <- c("CN_10yry", "US_10yry", "UK_10yry", "GR_10yry", "IT_10yry", "AU_10yry", #10 year
                "CN_5yry", #5 year
                "CN_2yry", "US_2yry", #2 year
                "INA_10yry", "IND_10yry") #Other Asia Nations.
ref_yields.text <- c("China 10yr Yield",
                     "US 10yr Yield",
                     "UK 10yr Yield",
                     "Germany 10yr Yield",
                     "Italy 10yr Yield",
                     "Australia 10yr Yield",
                     "China 5yr Yield",
                     "China 2yr Yield",
                     "US 2yr Yield",
                     "Indonesia 10yr Yield",
                     "India 10yr Yield"
                     )
yields <- AssFun$read_excel_yields(ref_yields)

#Processing Data without India 10yr yield.
yields.HPFs <- list(NULL)
  for(i in 1:(length(ref_yields)-1)){
  #Processing with Hodrick Prescott Filter and Save to csv Files.
  yields.HPFs[i] <- list(AssFun$hpf_save_yield(yields[,i+1], ref_yields[i], as.Date(yields[,1])))
  names(yields.HPFs)[i] <- c(paste0(ref_yields[i],"DailyTD.hpf"))
}

#Processing India 10yr yield.
IND.i <- length(ref_yields)
IND.proc_data <- yields[, IND.i + 1]
IND.data_name <- ref_yields[IND.i]
IND.data_date <- as.Date(yields[, 1])
#For IND_10yry, correct mitaken data inputs.

#Applying HP Filter to India 10yr yield
IND.data.HPF <- hpfilter(na.interpolation(IND.proc_data), freq=2419200, type=c("lambda"), drift = FALSE)
#Creating HPF output
IND.data.HPF.output <- as.data.frame(IND.data_date[1:length(IND.data.HPF$cycle)])
IND.data.HPF.output <- cbind(IND.data.HPF.output,
                             IND.proc_data[1:length(IND.data.HPF$cycle)],
                             IND.data.HPF$trend,
                             IND.data.HPF$cycle)
colnames(IND.data.HPF.output) <- c(paste0(IND.data_name, "Date"),
                                   paste0(IND.data_name, "Close"),
                                   paste0(IND.data_name, "_hpft"),
                                   paste0(IND.data_name, "_hpfc"))
#Creating xts output
IND.data.HPF.output.xts <- xts(IND.data.HPF.output[, -1], order.by = IND.data.HPF.output[[1]])
#Bind to yields.HPFs
yields.HPFs[IND.i] <- list(IND.data.HPF.output.xts)
names(yields.HPFs)[IND.i] <- c(paste0(ref_yields[IND.i],"DailyTD.hpf"))

#Data correction process. For dozens of mistaken data inputs.
#For UK_10yry------------------------------------
correct.UK_10yry <- as.data.frame(yields.HPFs$UK_10yryDailyTD.hpf, stringsAsFactors = FALSE)
#"2018-09-11"
correct.UK_10yry[rownames(correct.UK_10yry) == "2018-09-11", ] <- 
  correct.UK_10yry[rownames(correct.UK_10yry) == "2018-09-10", ]
#"2018-12-03"
correct.UK_10yry[rownames(correct.UK_10yry) == "2018-12-03", ] <- 
  correct.UK_10yry[rownames(correct.UK_10yry) == "2018-11-30", ]
correct.UK_10yry[rownames(correct.UK_10yry) == "2018-12-02", ] <- 
  correct.UK_10yry[rownames(correct.UK_10yry) == "2018-11-30", ]
correct.UK_10yry[rownames(correct.UK_10yry) == "2018-12-01", ] <- 
  correct.UK_10yry[rownames(correct.UK_10yry) == "2018-11-30", ]
#Convert back to xts.
yields.HPFs$UK_10yryDailyTD.hpf <- as.xts(correct.UK_10yry, order.by = as.Date(rownames(correct.UK_10yry)))

#For GR_10yry------------------------------------
correct.GR_10yry <- as.data.frame(yields.HPFs$GR_10yryDailyTD.hpf, stringsAsFactors = FALSE)
#"2018-11-16" to "2018-10-19"
correct.GR_10yry[rownames(correct.GR_10yry) == "2018-11-19", ] <- 
  correct.GR_10yry[rownames(correct.GR_10yry) == "2018-11-16", ]
correct.GR_10yry[rownames(correct.GR_10yry) == "2018-11-18", ] <- 
  correct.GR_10yry[rownames(correct.GR_10yry) == "2018-11-16", ]
correct.GR_10yry[rownames(correct.GR_10yry) == "2018-11-17", ] <- 
  correct.GR_10yry[rownames(correct.GR_10yry) == "2018-11-16", ]
#Convert back to xts.
yields.HPFs$GR_10yryDailyTD.hpf <- as.xts(correct.GR_10yry, order.by = as.Date(rownames(correct.GR_10yry)))

#For IND_10yry------------------------------------
#correct.IND_10yry <- as.data.frame(yields.HPFs$IND_10yryDailyTD.hpf, stringsAsFactors = FALSE)
#"2018-03-01" to "2018-03-02"
#correct.IND_10yry[rownames(correct.IND_10yry) == "2018-03-02", ] <- 
#  correct.IND_10yry[rownames(correct.IND_10yry) == "2018-03-01", ]
#Convert back to xts.
#yields.HPFs$IND_10yryDailyTD.hpf <- as.xts(correct.IND_10yry, order.by = as.Date(rownames(correct.IND_10yry)))

#Set the yields to be focused on.
ref_yields.major <- c("CN_10yry", "US_10yry", "UK_10yry")
ref_yields.major.text <- c("China 10yr Yield",
                           "US 10yr Yield",
                           "UK 10yr Yield")

## Step to write down the reference index and text of commoredity trading data for further use.
ref_yields.output.df <- rbind(ref_yields, ref_yields.text)
write.csv(ref_yields.output.df, file=paste0("DailyTDs/ref_yields.csv"), row.names=FALSE)
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 1
```

### `r ref_yields[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][, -3],
     main=ref_yields.text[i2],observation.based = TRUE)
```

```{r}
addSeries(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][, 3],
          main=paste0(ref_yields.text[i2], " HPFC"))
```

### `r ref_yields[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_yields.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],
          main=paste0(ref_yields.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 2
```

### `r ref_yields[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][, -3],
     main=ref_yields.text[i2],observation.based = TRUE)
```

```{r}
addSeries(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][, 3],
          main=paste0(ref_yields.text[i2], " HPFC"))
```

### `r ref_yields[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_yields.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],
          main=paste0(ref_yields.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 3
```

### `r ref_yields[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][, -3],
     main=ref_yields.text[i2],observation.based = TRUE)
```

```{r}
addSeries(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][, 3],
          main=paste0(ref_yields.text[i2], " HPFC"))
```

### `r ref_yields[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_yields.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],
          main=paste0(ref_yields.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 4
```

### `r ref_yields[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][, -3],
     main=ref_yields.text[i2],observation.based = TRUE)
```

```{r}
addSeries(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][, 3],
          main=paste0(ref_yields.text[i2], " HPFC"))
```

### `r ref_yields[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_yields.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],
          main=paste0(ref_yields.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 5
```

### `r ref_yields[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][, -3],
     main=ref_yields.text[i2],observation.based = TRUE)
```

```{r}
addSeries(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][, 3],
          main=paste0(ref_yields.text[i2], " HPFC"))
```

### `r ref_yields[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_yields.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],
          main=paste0(ref_yields.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 6
```

### `r ref_yields[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][, -3],
     main=ref_yields.text[i2],observation.based = TRUE)
```

```{r}
addSeries(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][, 3],
          main=paste0(ref_yields.text[i2], " HPFC"))
```

### `r ref_yields[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_yields.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],
          main=paste0(ref_yields.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 7
```

### `r ref_yields[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][, -3],
     main=ref_yields.text[i2],observation.based = TRUE)
```

```{r}
addSeries(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][, 3],
          main=paste0(ref_yields.text[i2], " HPFC"))
```

### `r ref_yields[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_yields.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],
          main=paste0(ref_yields.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 8
```

### `r ref_yields[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][, -3],
     main=ref_yields.text[i2],observation.based = TRUE)
```

```{r}
addSeries(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][, 3],
          main=paste0(ref_yields.text[i2], " HPFC"))
```

### `r ref_yields[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_yields.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],
          main=paste0(ref_yields.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 9
```

### `r ref_yields[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][, -3],
     main=ref_yields.text[i2],observation.based = TRUE)
```

```{r}
addSeries(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][, 3],
          main=paste0(ref_yields.text[i2], " HPFC"))
```

### `r ref_yields[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_yields.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],
          main=paste0(ref_yields.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 10
```

### `r ref_yields[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][, -3],
     main=ref_yields.text[i2],observation.based = TRUE)
```

```{r}
addSeries(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][, 3],
          main=paste0(ref_yields.text[i2], " HPFC"))
```

### `r ref_yields[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_yields.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],
          main=paste0(ref_yields.text[i2]," HPFC in 1 Year."))
```


```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 11
```

### `r ref_yields[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][, -3],
     main=ref_yields.text[i2],observation.based = TRUE)
```

```{r}
addSeries(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][, 3],
          main=paste0(ref_yields.text[i2], " HPFC"))
```

### `r ref_yields[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_yields.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],
          main=paste0(ref_yields.text[i2]," HPFC in 1 Year."))
```


COMMORDITIES(1) {.tabset .tabset-fade}
-------------------------------------

2) Status of Trade Data.(1)

```{r Data Preparation: Trade Data}
setwd(globalWD)
#Functions---------------------------------------
#Functions to Read Trading Data From Excel File
AssFun$read_excel_TD <- function(contract_name){
  #Read Excel File Data.
  TD.read <- read_excel(file.path(globalWD.data, paste0(contract_name, ".xls")),
                        col_types = c("text", "text", "date",
                                      "numeric", "numeric", "numeric", 
                                      "numeric", "numeric", "numeric", 
                                      "numeric", "numeric", "numeric"),
                        col_names = TRUE
  )
  colnames(TD.read) <- c(paste0(contract_name, "Code"),
                         paste0(contract_name, "Contract"),
                         paste0(contract_name, "Date"),
                         paste0(contract_name, "Open"),
                         paste0(contract_name, "High"),
                         paste0(contract_name, "Low"),
                         paste0(contract_name, "Close"),
                         paste0(contract_name, "Chg"),
                         paste0(contract_name, "RateofChg"),
                         paste0(contract_name, "Vol"),
                         paste0(contract_name, "Amn"),
                         paste0(contract_name, "Settle"))
  TD.read <- TD.read[, -12]
  TD.read.na <- na.omit(TD.read)
  #Subsetting Into 10 Year Window.
  TD.read.na <- subset.data.frame(TD.read.na, 
                                  year(TD.read.na[[3]]) >= globalStartYear)
  #Return Dataframe without NA.
  return(TD.read.na)
}

AssFun$read_excel_TD2 <- function(contract_name){
  #Read Excel File Data.
  TD.read <- read_excel(file.path(globalWD.data, paste0(contract_name, ".xls")),
                        col_types = c("text", "text", "date",
                                      "numeric", "numeric", "numeric", 
                                      "numeric", "numeric", "numeric", 
                                      "numeric", "numeric"),
                        col_names = TRUE
  )
  colnames(TD.read) <- c(paste0(contract_name, "Code"),
                         paste0(contract_name, "Contract"),
                         paste0(contract_name, "Date"),
                         paste0(contract_name, "Open"),
                         paste0(contract_name, "High"),
                         paste0(contract_name, "Low"),
                         paste0(contract_name, "Close"),
                         paste0(contract_name, "Chg"),
                         paste0(contract_name, "RateofChg"),
                         paste0(contract_name, "Vol"),
                         paste0(contract_name, "Amn"))
  TD.read.na <- na.omit(TD.read)
  #Subsetting Into 10 Year Window.
  TD.read.na <- subset.data.frame(TD.read.na, 
                                  year(TD.read.na[[3]]) >= globalStartYear)
  #Return Dataframe without NA.
  return(TD.read.na)
}

#Functions to Apply HPfilters to Data And Save it to csv Files
AssFun$hpf_save_TD <- function(proc_data, data_name = NULL, data_date = NULL){
  #Applying HP Filter
  data.HPF <- hpfilter(proc_data, freq=2419200, type=c("lambda"), drift = FALSE)
  #Make sure file storage dirctor be created.
  if(!dir.exists("DailyTDs")){
    dir.create("DailyTDs") 
  }
  #Output and Save to csv File if Given the Name.
  if(!is.null(data_name)){
    data.HPF.output <- as.data.frame(data_date)
    data.HPF.output <- cbind(data.HPF.output,
                             proc_data,
                             data.HPF$trend,
                             data.HPF$cycle)
    colnames(data.HPF.output) <- c(paste0(data_name, "Date"),
                         paste0(data_name, "Close"),
                         paste0(data_name, "_hpft"),
                         paste0(data_name, "_hpfc"))
    write.csv(data.HPF.output,file=paste0("DailyTDs/", data_name, "DailyTD.csv"), row.names=FALSE)
  }
  #Convert the Output Into xts Object and Return.
  data.HPF.output.xts <- xts(data.HPF.output[, -1], order.by = data.HPF.output[[1]])
  return(data.HPF.output.xts)
}

#Processing--------------------------------------
#Read Trade Data.
ref_TD1 <- c("IF00C1", "IH00C1", "CU0", "T00C1", "TF00C1", 
             "CL00Y", "AU0", "AG0", "CT00Y", 
             "TA0", "SI00Y", "CF0",
             "TY00Y", "AL0", "TF00Y", "FV00Y", "GC00Y", "RB0", 
             "FU0", "BU0", "ZN0", "LCPT", "RU0", "LH0", "ZS00Y", "PK0",
             "LALT", "SR0", "JRU00Y", "FG0", "SA0", "P0", "I0", "M0", "PG0", "Y0")
ref_TD2 <- c( "SCM", "SPX", "FTSE")
ref_TD <- c(ref_TD1, ref_TD2)

ref_TD.text <- c("CFFEX CSI 300 Futures",
                 "CFFEX A50 Futures",
                 "SHFE Copper Futures",
                 "CFFEX 10yr Treasury Futures",
                 "CFFEX 5yr Treasury Futures", 
                 "NYMEX CRUDE OIL Futures",
                 "SHFE Gold Futures",
                 "SHFE SILVER Futures",
                 "NYMEX COTTON Futures",
                 "CZCE PTA Futures",
                 "COMEX SILVER Futures",
                 "CZCE COTTON Futures", 
                 "U.S. 10y Treasury Bond Futures",
                 "SHFE ALUMINUM Futures",
                 "SGX TSR20 Futures",
                 "U.S. 5y Treasury Bond Futures",
                 "COMEX GOLD Futures",
                 "SHFE Rebar Futures",
                 "SHFE FUEL Futures",
                 "SHFE Bitumen Futures",
                 "SHFE Znic Futures",
                 "LME COPPER 3Months",
                 "SHFE RUBBER Futures",
                 "DCE PORK Futures",
                 "CBOT SOYBEAN Futurres",
                 "DCE PEANUTS Futures",
                 "LME ALUMINUM 3Months",
                 "CZCE SUGAR Futures",
                 "TOKYO RUBBER Futures",
                 "CZCE FIBER GLASS Futures",
                 "CZCE SODIUM CARBONATE Futures",
                 "DCE Palm Oil Futures",
                 "DCE Ironore Futures",
                 "DCE Soymeal Futures",
                 "DCE PETROL GAS Futures",
                 "DCE SoyOil Futures",
                 "INE CRUDE Futures",
                 "S & P 500 Index",
                 "U.K. FTSE100"
                 )

#Set the targets and locker to be focused on.
ref_TD.major <- c("RU0", "RB0", "CU0")
ref_TD.major.text <- c("SHFE RUBBER Futures",
                       "SHFE REBAR Futures",
                       "SHFE COPPER Futures"
                       )

DailyTD <- list(NULL)
DailyTD.HPFs <- list(NULL)
##ref_TD1
for(i in 1:length(ref_TD1)){
  #Reading Data from Excel Files
  DailyTD[i] <- list(AssFun$read_excel_TD(ref_TD1[i]))
  names(DailyTD)[i] <- c(paste0(ref_TD1[i],"DailyTD"))
  #Processing with Hodrick Prescott Filter and Save to csv Files.
  DailyTD.HPFs[i] <- list(AssFun$hpf_save_TD(DailyTD[[paste0(ref_TD1[i],'DailyTD')]][[paste0(ref_TD1[i], 'Close')]], 
                                        ref_TD1[i], 
                                        DailyTD[[paste0(ref_TD1[i], 'DailyTD')]][[paste0(ref_TD1[i], 'Date')]]))
  names(DailyTD.HPFs)[i] <- c(paste0(ref_TD1[i],"DailyTD.hpf"))
}
##ref_TD2
ref_i <- length(ref_TD1)
for(i in 1:length(ref_TD2)){
  #Reading Data from Excel Files
  DailyTD[i + ref_i] <- list(AssFun$read_excel_TD2(ref_TD2[i]))
  names(DailyTD)[i + ref_i] <- c(paste0(ref_TD2[i],"DailyTD"))
  #Processing with Hodrick Prescott Filter and Save to csv Files.
  DailyTD.HPFs[i + ref_i] <- list(AssFun$hpf_save_TD(DailyTD[[paste0(ref_TD2[i],'DailyTD')]][[paste0(ref_TD2[i], 'Close')]], 
                                        ref_TD2[i], 
                                        DailyTD[[paste0(ref_TD2[i], 'DailyTD')]][[paste0(ref_TD2[i], 'Date')]]))
  names(DailyTD.HPFs)[i + ref_i] <- c(paste0(ref_TD2[i],"DailyTD.hpf"))
}

## Step to write down the reference index and text of commoredity trading data for further use.
ref_TD.output.df <- rbind(ref_TD, ref_TD.text)
write.csv(ref_TD.output.df, file=paste0("DailyTDs/ref_TD.csv"), row.names=FALSE)
```
 
```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 1
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 2
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```


```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 3
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 4
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 5
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 6
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 7
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 8
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```


```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 9
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```


```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 10
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 11
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```


```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 12
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 13
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```


```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 14
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```


```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 15
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 16
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 17
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```


```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 18
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 19
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 20
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 21
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```


```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 22
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```


```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 23
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 24
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 25
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```


```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 26
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 27
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```


```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 28
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```


```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 29
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```


```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 30
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```


```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 31
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```


```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 32
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 33
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```


```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 34
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```


```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 35
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```


```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 36
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```


```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 37
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 38
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 39
```

### `r ref_TD[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, -3],main=ref_TD.text[i2],observation.based = TRUE)
```

```{r}
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][, 3],main=paste0(ref_TD.text[i2], " HPFC"))
```

### `r ref_TD[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_TD.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(DailyTD.HPFs[[paste0(ref_TD[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],main=paste0(ref_TD.text[i2]," HPFC in 1 Year."))
```

Currencies STATUS {.tabset .tabset-fade}
-------------------------------------

3) Status of Currencies.

```{r Data Preparation: Currencies}
#Functions---------------------------------------
#Functions to Read Currency Data From Excel File
AssFun$read_excel_CURRENCY <- function(currency_name){
  #Read Excel File Data.
  TD.read <- read_excel(file.path(globalWD.data, paste0(currency_name, ".xls")),
                        col_types = c("text", "text", "date",
                                      "numeric", "numeric", "numeric", 
                                      "numeric", "numeric", "numeric"),
                        col_names = TRUE
  )
  colnames(TD.read) <- c(paste0(currency_name, "Code"),
                         paste0(currency_name, "Contract"),
                         paste0(currency_name, "Date"),
                         paste0(currency_name, "Open"),
                         paste0(currency_name, "High"),
                         paste0(currency_name, "Low"),
                         paste0(currency_name, "Close"),
                         paste0(currency_name, "Chg"),
                         paste0(currency_name, "RateofChg"))
  TD.read.na <- na.omit(TD.read)
  #Subsetting Into 10 Year Window.
  TD.read.na <- subset.data.frame(TD.read.na, 
                                  year(TD.read.na[[3]]) >= globalStartYear)
  #Return Dataframe without NA.
  return(TD.read.na)
}

#Processing--------------------------------------
#Reading Currency Data
ref_Currency <- c("USDX", "USDCNH", "GBPUSD", "EURUSD", "AUDUSD", "USDJPY", "AUDCAD")
ref_Currency.text <- c("US Dollar Index",
                       "China Offshore Yuan",
                       "British Pound",
                       "Euro",
                       "Aussie Dollar",
                       "Japan Yen",
                       "Aussie Dollar 2 Canadian Dollar")
CurrencyDaily <- list(NULL)
CurrencyDaily.HPFs <- list(NULL)
for(i in 1:length(ref_Currency)){
  CurrencyDaily[i] <- list(AssFun$read_excel_CURRENCY(ref_Currency[i]))
  names(CurrencyDaily)[i] <- c(paste0(ref_Currency[i], "DailyTD"))
  #Processing with Hodrick Prescott Filter and Save to csv Files.
  CurrencyDaily.HPFs[i] <- list(AssFun$hpf_save_TD(CurrencyDaily[[paste0(ref_Currency[i], 'DailyTD')]][[paste0(ref_Currency[i], 'Close')]], ref_Currency[i], CurrencyDaily[[paste0(ref_Currency[i], 'DailyTD')]][[paste0(ref_Currency[i], 'Date')]]))
  names(CurrencyDaily.HPFs)[i] <- c(paste0(ref_Currency[i],"DailyTD.hpf"))
}
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 1
```

### `r ref_Currency[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][, -3],
     main=ref_Currency.text[i2],observation.based = TRUE)
```

```{r}
addSeries(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][, 3],
          main=paste0(ref_Currency.text[i2], " HPFC"))
```

### `r ref_Currency[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_Currency.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],
          main=paste0(ref_Currency.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 2
```

### `r ref_Currency[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][, -3],
     main=ref_Currency.text[i2],observation.based = TRUE)
```

```{r}
addSeries(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][, 3],
          main=paste0(ref_Currency.text[i2], " HPFC"))
```

### `r ref_Currency[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_Currency.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],
          main=paste0(ref_Currency.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 3
```

### `r ref_Currency[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][, -3],
     main=ref_Currency.text[i2],observation.based = TRUE)
```

```{r}
addSeries(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][, 3],
          main=paste0(ref_Currency.text[i2], " HPFC"))
```

### `r ref_Currency[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_Currency.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],
          main=paste0(ref_Currency.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 4
```

### `r ref_Currency[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][, -3],
     main=ref_Currency.text[i2],observation.based = TRUE)
```

```{r}
addSeries(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][, 3],
          main=paste0(ref_Currency.text[i2], " HPFC"))
```

### `r ref_Currency[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_Currency.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],
          main=paste0(ref_Currency.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 5
```

### `r ref_Currency[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][, -3],
     main=ref_Currency.text[i2],observation.based = TRUE)
```

```{r}
addSeries(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][, 3],
          main=paste0(ref_Currency.text[i2], " HPFC"))
```

### `r ref_Currency[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_Currency.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],
          main=paste0(ref_Currency.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 6
```

### `r ref_Currency[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][, -3],
     main=ref_Currency.text[i2],observation.based = TRUE)
```

```{r}
addSeries(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][, 3],
          main=paste0(ref_Currency.text[i2], " HPFC"))
```

### `r ref_Currency[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_Currency.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],
          main=paste0(ref_Currency.text[i2]," HPFC in 1 Year."))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 7
```

### `r ref_Currency[i2]`

```{r include=FALSE}
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][, -3],
     main=ref_Currency.text[i2],observation.based = TRUE)
```

```{r}
addSeries(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][, 3],
          main=paste0(ref_Currency.text[i2], " HPFC"))
```

### `r ref_Currency[i2]`[CL]

```{r}
par(mfcol=c(1,2))
plot(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_Currency.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],
          main=paste0(ref_Currency.text[i2]," HPFC in 1 Year."))
```

OTHERS DAILY STATUS {.tabset .tabset-fade}
-------------------------------------

4) OTHERs

### CMX GC in YUAN

```{r}
##Functoins.=====================================
AssFun$Obtain_Hybrid <- function(Price1, weight, Price2){
  #Getting Price
  attach(c(DailyTD.HPFs, yields.HPFs, CurrencyDaily.HPFs))
  price.Price1.hpf <- get(paste0(Price1, "DailyTD.hpf"))
  price.Price2.hpf <- get(paste0(Price2, "DailyTD.hpf"))
  price.Price1 <- price.Price1.hpf[, paste0(Price1, "Close")]
  price.Price2 <- price.Price2.hpf[, paste0(Price2, "Close")]
  price.Hybrid <- price.Price1 * price.Price2 * weight
  
  return(price.Hybrid)
}

##Using the function of hybrid chunk, I am to calculate the price in YUAN of COMEX Gold.
subID.CSC.USD <- c("GC00Y")
weight.CSC <- c(1/31.1035) #1 ounce = 31.1035 gram
weight.CSC.CUR <- c("USDCNH")

##Calcuate the price of Comex Silver to Silver in CNH
GC_in_CNH <- AssFun$Obtain_Hybrid(subID.CSC.USD, weight.CSC, weight.CSC.CUR)

plot(GC_in_CNH[paste0("2017/", year(Sys.yearmon()))], main = "Comex Gold Price in USDCNH (per gram)")
```

### CMX SI in YUAN

```{r}
##Using the function of hybrid chunk, I am to calculate the price in YUAN of COMEX Silver.
subID.CSC.USD <- c("SI00Y")
weight.CSC <- c(1/31.1035 * 1000) #1 ounce = 31.1035 gram
weight.CSC.CUR <- c("USDCNH")

##Calcuate the price of Comex Silver to Silver in CNH
SI_in_CNH <- AssFun$Obtain_Hybrid(subID.CSC.USD, weight.CSC, weight.CSC.CUR)

plot(SI_in_CNH[paste0("2017/", year(Sys.yearmon()))], main = "Comex Silver Price in USDCNH (per gram)")
```

### NYMAX Crude in YUAN

```{r}
##Functoins.=====================================
AssFun$Obtain_Hybrid <- function(Price1, weight, Price2){
  #Getting Price
  attach(c(DailyTD.HPFs, yields.HPFs, CurrencyDaily.HPFs))
  price.Price1.hpf <- get(paste0(Price1, "DailyTD.hpf"))
  price.Price2.hpf <- get(paste0(Price2, "DailyTD.hpf"))
  price.Price1 <- price.Price1.hpf[, paste0(Price1, "Close")]
  price.Price2 <- price.Price2.hpf[, paste0(Price2, "Close")]
  price.Hybrid <- price.Price1 * price.Price2 * weight
  
  return(price.Hybrid)
}

##Using the function of hybrid chunk, I am to calculate the price in YUAN of COMEX Silver.
subID.CSC.USD <- c("CL00Y")
weight.CSC <- c(1/1) #1 barrel = 1 barrel
weight.CSC.CUR <- c("USDCNH")

##Calcuate the price of Comex Silver to Silver in CNH
CRUDE_in_CNH <- AssFun$Obtain_Hybrid(subID.CSC.USD, weight.CSC, weight.CSC.CUR)

plot(CRUDE_in_CNH[paste0("2017/", year(Sys.yearmon()))], main = "Nymax Crude Price in USDCNH (per berral)")
```


MACRO DATA STATUS {.tabset .tabset-fade}
-------------------------------------

6) Status of Macro Data.

```{r Data Preparation: Macro Data}
#Functions---------------------------------------
#Functions to Read Monthly Macro Data Data From Excel File
AssFun$read_excel_macanamonthly <- function(macanamonthly_name){
  #Read Excel File Data.
  TD.read <- read_excel(file.path(globalWD.data, "MacAnaMonthly.xls"),
                        col_types = c("text", rep("numeric", length(macanamonthly_name))),
                        col_names = TRUE
  )
  colnames(TD.read) <- c("Date", macanamonthly_name)
  #Make Correction the formate of the Date Column.
  TD.read$Date <- paste0(gsub("\\D", "", TD.read$Date), "01")
  #Subsetting Into 10 Year Window.
  TD.read <- subset.data.frame(TD.read, year(strptime(TD.read[[1]], 
                                                      format = "%Y%m%d")) >= globalStartYear)
  #Dealing with NAs.
  TD.read.na <- as.data.frame(na.approx(TD.read[,2:length(TD.read)]))
  TD.read.na <- cbind(TD.read[, 1], TD.read.na)
  colnames(TD.read.na) <- c("Date", macanamonthly_name)
  #Return Dataframe without NAs.
  return(TD.read.na)
}

#Functions for Macro Data to Apply HP Filter and Save to csv Files.
AssFun$hpf_save_MacAnaMonthly <- function(proc_data, data_name = NULL, data_date = NULL){
  #Applying HP Filter to Macro Data, frequency of 1200 Is For Monthly Data.
  data.HPF <- hpfilter(na.approx(proc_data), freq=1200, type=c("lambda"), drift = FALSE)
  #Output and Save to csv File if Given the Name.
  if(!is.null(data_name)){
    data.HPF.output <- as.data.frame(data_date[1:length(data.HPF$cycle)])
    data.HPF.output <- cbind(data.HPF.output,
                             proc_data[1:length(data.HPF$cycle)],
                             data.HPF$trend,
                             data.HPF$cycle)
    colnames(data.HPF.output) <- c(paste0(data_name, "Date"),
                         paste0(data_name),
                         paste0(data_name, "_hpft"),
                         paste0(data_name, "_hpfc"))
    write.csv(data.HPF.output,file=paste0("DailyTDs/", data_name, "Monthly.csv"), row.names=FALSE)
  }
  #Convert the Output Into xts Object and Return.
  data.HPF.output.xts <- xts(data.HPF.output[, -1], order.by = data.HPF.output[[1]])
  return(data.HPF.output.xts)
}

#Processing--------------------------------------
#Read Monthly Macro Analysis Datas
ref_MacAnaMonthly <- c("CNPMI", "CAIXINPMI", "USPMI", "EUPMI", "UKPMI", 
                       "cncpi", "uscpi", "eucpi", "ukcpi", 
                       "CN_PPI", "US_PPI")
ref_MacAnaMonthly.text <- c("China PMI",
                            "China CaiXin PMI",
                            "United States PMI",
                            "Europe PMI",
                            "United Kingdom PMI",
                            "China cpi",
                            "United States cpi",
                            "Europe cpi",
                            "United Kingdom cpi",
                            "China PPI",
                            "US PPI")
MacAnaMonthly <- AssFun$read_excel_macanamonthly(ref_MacAnaMonthly)

#Processing Data
MacAnaMonthly.HPFs <- list(NULL)
for(i in 1:length(ref_MacAnaMonthly)){
  #Processing with Hodrick Prescott Filter and Save to csv Files.
  MacAnaMonthly.HPFs[i] <- list(AssFun$hpf_save_MacAnaMonthly(MacAnaMonthly[,i+1], 
                                                              ref_MacAnaMonthly[i], 
                              strptimeDate(MacAnaMonthly[, 1], format = "%Y%m%d")))
  names(MacAnaMonthly.HPFs)[i] <- c(paste0(ref_MacAnaMonthly[i],"Monthly.hpf"))
}
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 1
```

### `r ref_MacAnaMonthly[i2]`

```{r }
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,2))
plot(MacAnaMonthly.HPFs[[paste0(ref_MacAnaMonthly[i2], 'Monthly.hpf')]][, -3],
     main=ref_MacAnaMonthly.text[i2],observation.based = TRUE)
addSeries(MacAnaMonthly.HPFs[[paste0(ref_MacAnaMonthly[i2], 'Monthly.hpf')]][, 3],
          main=paste0(ref_MacAnaMonthly.text[i2], " HPFC"))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 2
```

### `r ref_MacAnaMonthly[i2]`

```{r }
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,2))
plot(MacAnaMonthly.HPFs[[paste0(ref_MacAnaMonthly[i2], 'Monthly.hpf')]][, -3],
     main=ref_MacAnaMonthly.text[i2],observation.based = TRUE)
addSeries(MacAnaMonthly.HPFs[[paste0(ref_MacAnaMonthly[i2], 'Monthly.hpf')]][, 3],
          main=paste0(ref_MacAnaMonthly.text[i2], " HPFC"))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 3
```

### `r ref_MacAnaMonthly[i2]`

```{r }
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,2))
plot(MacAnaMonthly.HPFs[[paste0(ref_MacAnaMonthly[i2], 'Monthly.hpf')]][, -3],
     main=ref_MacAnaMonthly.text[i2],observation.based = TRUE)
addSeries(MacAnaMonthly.HPFs[[paste0(ref_MacAnaMonthly[i2], 'Monthly.hpf')]][, 3],
          main=paste0(ref_MacAnaMonthly.text[i2], " HPFC"))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 4
```

### `r ref_MacAnaMonthly[i2]`

```{r }
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,2))
plot(MacAnaMonthly.HPFs[[paste0(ref_MacAnaMonthly[i2], 'Monthly.hpf')]][, -3],
     main=ref_MacAnaMonthly.text[i2],observation.based = TRUE)
addSeries(MacAnaMonthly.HPFs[[paste0(ref_MacAnaMonthly[i2], 'Monthly.hpf')]][, 3],
          main=paste0(ref_MacAnaMonthly.text[i2], " HPFC"))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 5
```

### `r ref_MacAnaMonthly[i2]`

```{r }
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,2))
plot(MacAnaMonthly.HPFs[[paste0(ref_MacAnaMonthly[i2], 'Monthly.hpf')]][, -3],
     main=ref_MacAnaMonthly.text[i2],observation.based = TRUE)
addSeries(MacAnaMonthly.HPFs[[paste0(ref_MacAnaMonthly[i2], 'Monthly.hpf')]][, 3],
          main=paste0(ref_MacAnaMonthly.text[i2], " HPFC"))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 6
```

### `r ref_MacAnaMonthly[i2]`

```{r }
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,2))
plot(MacAnaMonthly.HPFs[[paste0(ref_MacAnaMonthly[i2], 'Monthly.hpf')]][, -3],
     main=ref_MacAnaMonthly.text[i2],observation.based = TRUE)
addSeries(MacAnaMonthly.HPFs[[paste0(ref_MacAnaMonthly[i2], 'Monthly.hpf')]][, 3],
          main=paste0(ref_MacAnaMonthly.text[i2], " HPFC"))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 7
```

### `r ref_MacAnaMonthly[i2]`

```{r }
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,2))
plot(MacAnaMonthly.HPFs[[paste0(ref_MacAnaMonthly[i2], 'Monthly.hpf')]][, -3],
     main=ref_MacAnaMonthly.text[i2],observation.based = TRUE)
addSeries(MacAnaMonthly.HPFs[[paste0(ref_MacAnaMonthly[i2], 'Monthly.hpf')]][, 3],
          main=paste0(ref_MacAnaMonthly.text[i2], " HPFC"))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 8
```

### `r ref_MacAnaMonthly[i2]`

```{r }
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,2))
plot(MacAnaMonthly.HPFs[[paste0(ref_MacAnaMonthly[i2], 'Monthly.hpf')]][, -3],
     main=ref_MacAnaMonthly.text[i2],observation.based = TRUE)
addSeries(MacAnaMonthly.HPFs[[paste0(ref_MacAnaMonthly[i2], 'Monthly.hpf')]][, 3],
          main=paste0(ref_MacAnaMonthly.text[i2], " HPFC"))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 9
```

### `r ref_MacAnaMonthly[i2]`

```{r }
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,2))
plot(MacAnaMonthly.HPFs[[paste0(ref_MacAnaMonthly[i2], 'Monthly.hpf')]][, -3],
     main=ref_MacAnaMonthly.text[i2],observation.based = TRUE)
addSeries(MacAnaMonthly.HPFs[[paste0(ref_MacAnaMonthly[i2], 'Monthly.hpf')]][, 3],
          main=paste0(ref_MacAnaMonthly.text[i2], " HPFC"))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 10
```

### `r ref_MacAnaMonthly[i2]`

```{r }
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,2))
plot(MacAnaMonthly.HPFs[[paste0(ref_MacAnaMonthly[i2], 'Monthly.hpf')]][, -3],
     main=ref_MacAnaMonthly.text[i2],observation.based = TRUE)
addSeries(MacAnaMonthly.HPFs[[paste0(ref_MacAnaMonthly[i2], 'Monthly.hpf')]][, 3],
          main=paste0(ref_MacAnaMonthly.text[i2], " HPFC"))
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 11
```

### `r ref_MacAnaMonthly[i2]`

```{r }
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,2))
plot(MacAnaMonthly.HPFs[[paste0(ref_MacAnaMonthly[i2], 'Monthly.hpf')]][, -3],
     main=ref_MacAnaMonthly.text[i2],observation.based = TRUE)
addSeries(MacAnaMonthly.HPFs[[paste0(ref_MacAnaMonthly[i2], 'Monthly.hpf')]][, 3],
          main=paste0(ref_MacAnaMonthly.text[i2], " HPFC"))
```


MultiVariates
==================================================

MULTI VARIATES {.tabset .tabset-fade}
-------------------------------------

1) Multi Variates: All Trading Datas.

```{r YIELDS: Multi Variates, All Trading Datas}
#Align monthly macro data to daily trading data and giving output.
#Functions---------------------------------------
#Functions align monthgly macro data to daily trading data. Arguments are strings of trading data name and macro data names.
#Return with timeSeries files for convience of further analysis.
AssFun$TD_MacAna_align <- function(TD_ref, MacAna_ref){
  #Gets trading data
  TD.get <- DailyTD.HPFs[[paste0(TD_ref, "DailyTD.hpf")]]
  #Align Macro Data to trading data
  for(i in 1:length(MacAna_ref)){
    MacAna.get <- MacAnaMonthly.HPFs[[paste0(MacAna_ref[i], "Monthly.hpf")]]
    TD.get <- merge.xts(TD.get, MacAna.get, join = "left")
  }
  TD.get.ts <- timeSeries(na.approx(TD.get), index(TD.get), format = "%Y-%m-%d")
  return(TD.get.ts)
}
#Funtions to plot timeSeries in necessary way.
AssFun$TD_MacAna_plot <- function(TD2MacAna = timeSeries(NULL),
                                  plotv = 2, #1 for Close, 2 for trend, 3 for cycle
                                  MacAna_ref){ #String of MacroData willing to plot
  par(mai=c(0.5,0.5,0.5,0.5))
  par(mfcol=c(1,1))
  for(ig in 1:length(MacAna_ref)){
    if(ig == 1){
      par(new = F)
      timeSeries::plot(TD2MacAna[, plotv], plot.type = c("single"), ann = FALSE, col = 1, lwd = 3)
      grid()
      par(new = T)
      timeSeries::plot(TD2MacAna[, ig*3+plotv], plot.type = c("single"), 
                       ann = FALSE, col = ig+1, yaxt = "n", xaxt = "n", axes = FALSE)
    }else{
      par(new = T)
      timeSeries::plot(TD2MacAna[, ig*3+plotv], plot.type = c("single"),
                       ann = FALSE, col = ig+1, yaxt = "n", xaxt = "n", axes = FALSE)
    }
  }
  plotv.text <- c("CLOSE", "TRENDS", "CYCLES")
  mtext(paste0(colnames(TD2MacAna)[plotv], " to ", toString(MacAna_ref), " ", plotv.text[plotv]), 
        side =3, ces = 1)
  legend("topleft", c(colnames(TD2MacAna)[plotv], MacAna_ref), lty =1, 
         col = seq.int(1, length(MacAna_ref)+1))
}

#Align all Trading Datas and giving output.
#Functions---------------------------------------
#Functions to align all trading Datas.
#Return with timeSeries files for convience of further analysis.
AssFun$TD_align_all <- function(Major_ref, Align_ref){
  attach(c(DailyTD.HPFs, yields.HPFs, CurrencyDaily.HPFs))
  #Gets major trading data
  All.get <- get(paste0(Major_ref, "DailyTD.hpf"))
  #Align all trading data
  for(i in 1:length(Align_ref)){
    toAlign.get <- get(paste0(Align_ref[i], "DailyTD.hpf"))
    All.get <- merge.xts(All.get, toAlign.get, join = "left")
  }
  All.get.ts <- timeSeries(All.get, index(All.get), format = "%Y-%m-%d")
  #Return desired objects
  detach(c(DailyTD.HPFs, yields.HPFs, CurrencyDaily.HPFs))
  return(All.get.ts)
}

#Processing--------------------------------------
#Align all to CN 10yr Treasury Futures Close Price
Major_ref <- ref_TD[1]
Align_ref <- c(ref_TD[-1], ref_Currency, ref_yields)
#Process to get all Trade Data aligned.
TD_All.ts <- AssFun$TD_align_all(Major_ref, Align_ref)
#Switching the yields above all.
TD_All.adj.x <- length(c(ref_TD, ref_Currency)) * 3
TD_All.ts <- TD_All.ts[, c((TD_All.adj.x+1):length(TD_All.ts@units), 1:TD_All.adj.x)]
#Output to CSV files for Deep Learning Analysis
if(!dir.exists("DEEPLEARN")){
  dir.create("DEEPLEARN") 
}
#Original Data
write.csv(tail(TD_All.ts, n = nrow(TD_All.ts) - 1200), "DEEPLEARN/TD_All.csv", col.names = TRUE) 
# Remove the first 1200 row which contains too many NAs.
output_ref <- c("All Trends", "All Cycles")
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 1
```

### `r output_ref[i2]`

```{r}
#Ploting Trading to Macro Data
AssFun$TD_MacAna_plot(TD_All.ts, plotv = 2, Align_ref)
```


```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 2
```

### `r output_ref[i2]`

```{r}
#Ploting Trading to Macro Data
AssFun$TD_MacAna_plot(TD_All.ts, plotv = 3, Align_ref)
```

TRADE TO MACROS {.tabset .tabset-fade}
-------------------------------------

2) Macro Data Trends Aligned to Trade Data, yields.

```{r MIUtoMACRO: Trade Datas to Macro Datas}

#Processing--------------------------------------
ref_TD2Mac <- c(paste0(ref_TD.major[1], "2PMIs"), 
                paste0(ref_TD.major[1], "2cpis"),
                paste0(ref_TD.major[2], "2PMIs"), 
                paste0(ref_TD.major[2], "2cpis"),
                paste0(ref_TD.major[3], "2PMIs"), 
                paste0(ref_TD.major[3], "2cpis")
)
```

```{r}
#Processing--------------------------------------
#Align futures close price to PMIs.
TD_ref <- ref_TD.major[1]
MacAna_ref <- ref_MacAnaMonthly[c(1:5,10:11)] #PMIs
#Align Macro Monthly Data to Trade Data
assign(paste0(ref_TD2Mac[1], ".ts"), AssFun$TD_MacAna_align(TD_ref, MacAna_ref))
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 1
```

### `r ref_TD2Mac[i2]`

```{r}
#Ploting Trading Data to Macro Data
AssFun$TD_MacAna_plot(get(paste0(ref_TD2Mac[i2], ".ts")), plotv = 2, MacAna_ref)
```

```{r}
#Processing--------------------------------------
#Align futures close price to cpis.
TD_ref <- ref_TD.major[1] #CN 10yr treasury futures
MacAna_ref <- ref_MacAnaMonthly[6:9] #cpis
#Align Macro Monthly Data to Trade Data
assign(paste0(ref_TD2Mac[2], ".ts"), AssFun$TD_MacAna_align(TD_ref, MacAna_ref))
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 2
```

### `r ref_TD2Mac[i2]`

```{r}
#Ploting Trading to Macro Data
AssFun$TD_MacAna_plot(get(paste0(ref_TD2Mac[i2], ".ts")), plotv = 2, MacAna_ref)
```

```{r}
#Processing--------------------------------------
#Align futures close price to PMIs.
TD_ref <- ref_TD.major[2]
MacAna_ref <- ref_MacAnaMonthly[c(1:5,10:11)] #PMIs
#Align Macro Monthly Data to Trade Data
assign(paste0(ref_TD2Mac[3], ".ts"), AssFun$TD_MacAna_align(TD_ref, MacAna_ref))
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 3
```

### `r ref_TD2Mac[i2]`

```{r}
#Ploting Trading Data to Macro Data
AssFun$TD_MacAna_plot(get(paste0(ref_TD2Mac[i2], ".ts")), plotv = 2, MacAna_ref)
```

```{r}
#Processing--------------------------------------
#Align futures close price to cpis.
TD_ref <- ref_TD.major[2] #CN 10yr treasury futures
MacAna_ref <- ref_MacAnaMonthly[6:9] #cpis
#Align Macro Monthly Data to Trade Data
assign(paste0(ref_TD2Mac[4], ".ts"), AssFun$TD_MacAna_align(TD_ref, MacAna_ref))
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 4
```

### `r ref_TD2Mac[i2]`

```{r}
#Ploting Trading to Macro Data
AssFun$TD_MacAna_plot(get(paste0(ref_TD2Mac[i2], ".ts")), plotv = 2, MacAna_ref)
```

```{r}
#Processing--------------------------------------
#Align futures close price to PMIs.
TD_ref <- ref_TD.major[3]
MacAna_ref <- ref_MacAnaMonthly[c(1:5,10:11)] #PMIs
#Align Macro Monthly Data to Trade Data
assign(paste0(ref_TD2Mac[5], ".ts"), AssFun$TD_MacAna_align(TD_ref, MacAna_ref))
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 5
```

### `r ref_TD2Mac[i2]`

```{r}
#Ploting Trading Data to Macro Data
AssFun$TD_MacAna_plot(get(paste0(ref_TD2Mac[i2], ".ts")), plotv = 2, MacAna_ref)
```

```{r}
#Processing--------------------------------------
#Align futures close price to cpis.
TD_ref <- ref_TD.major[3] #CN 10yr treasury futures
MacAna_ref <- ref_MacAnaMonthly[6:9] #cpis
#Align Macro Monthly Data to Trade Data
assign(paste0(ref_TD2Mac[6], ".ts"), AssFun$TD_MacAna_align(TD_ref, MacAna_ref))
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 6
```

### `r ref_TD2Mac[i2]`

```{r}
#Ploting Trading to Macro Data
AssFun$TD_MacAna_plot(get(paste0(ref_TD2Mac[i2], ".ts")), plotv = 2, MacAna_ref)
```

```{r yields to Macro Datas}
#Functions.======================================
#Functions align monthgly macro data to yields.
#Return with timeSeries files for convience of further analysis.
AssFun$yields_MacAna_align <- function(TD_ref, MacAna_ref){
  attach(c(DailyTD.HPFs, yields.HPFs, CurrencyDaily.HPFs))
  #Gets trading data
  TD.get <- get(paste0(TD_ref, "DailyTD.hpf"))
  #Align Macro Data to trading data
  for(i in 1:length(MacAna_ref)){
    MacAna.get <- MacAnaMonthly.HPFs[[paste0(MacAna_ref[i], "Monthly.hpf")]]
    TD.get <- merge.xts(TD.get, MacAna.get, join = "left")
  }
  TD.get.ts <- timeSeries(na.approx(TD.get), index(TD.get), format = "%Y-%m-%d")
  detach(c(DailyTD.HPFs, yields.HPFs, CurrencyDaily.HPFs))
  return(TD.get.ts)
}

#Funtions to plot timeSeries in necessary way.
AssFun$yields_MacAna_plot <- function(yields2MacAna = timeSeries(NULL),
                                      plotv = 2, #1 for Close, 2 for trend, 3 for cycle
                                      MacAna_ref){ #String of MacroData willing to plot
  par(mai=c(0.5,0.5,0.5,0.5))
  par(mfcol=c(1,1))
  for(ig in 1:length(MacAna_ref)){
    if(ig == 1){
      par(new = F)
      timeSeries::plot(yields2MacAna[, plotv], plot.type = c("single"), ann = FALSE, col = 1, lwd = 3)
      grid()
      par(new = T)
      timeSeries::plot(yields2MacAna[, ig*3+plotv], plot.type = c("single"), 
                       ann = FALSE, col = ig+1, yaxt = "n", xaxt = "n", axes = FALSE)
    }else{
      par(new = T)
      timeSeries::plot(yields2MacAna[, ig*3+plotv], plot.type = c("single"),
                       ann = FALSE, col = ig+1, yaxt = "n", xaxt = "n", axes = FALSE)
    }
  }
  plotv.text <- c("CLOSE", "TRENDS", "CYCLES")
  mtext(paste0(colnames(yields2MacAna)[plotv], " to ", toString(MacAna_ref), " ", plotv.text[plotv]), 
        side =3, ces = 1)
  legend("topleft", c(colnames(yields2MacAna)[plotv], MacAna_ref), lty =1, 
         col = seq.int(1, length(MacAna_ref)+1))
}


#Processing--------------------------------------
ref_yields2Mac <- c(paste0(ref_yields.major[1], "2PMIs"), 
                    paste0(ref_yields.major[1], "2cpis"), 
                    paste0(ref_yields.major[2], "2PMIs"), 
                    paste0(ref_yields.major[2], "2cpis"),
                    paste0(ref_yields.major[3], "2PMIs"), 
                    paste0(ref_yields.major[3], "2cpis"), 
                    paste0(ref_yields.major[4], "2PMIs"), 
                    paste0(ref_yields.major[4], "2cpis")
                   )
```

```{r}
#Processing--------------------------------------
#Align yields to PMIs.
yields_ref <- ref_yields.major[1]
MacAna_ref <- ref_MacAnaMonthly[c(1:5,10:11)] #PMIs
#Align Macro Monthly Data to yields
assign(paste0(ref_yields2Mac[1], ".ts"), AssFun$yields_MacAna_align(yields_ref, MacAna_ref))
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 1
```

### `r ref_yields2Mac[i2]`

```{r}
#Ploting Trading Data to Macro Data
AssFun$yields_MacAna_plot(get(paste0(ref_yields2Mac[i2], ".ts")), plotv = 2, MacAna_ref)
```

```{r}
#Processing--------------------------------------
#Align yields to cpis.
yields_ref <- ref_yields.major[1]
MacAna_ref <- ref_MacAnaMonthly[6:9] #cpis
#Align Macro Monthly Data to Trade Data
assign(paste0(ref_yields2Mac[2], ".ts"), AssFun$yields_MacAna_align(yields_ref, MacAna_ref))
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 2
```

### `r ref_yields2Mac[i2]`

```{r}
#Ploting Trading Data to Macro Data
AssFun$yields_MacAna_plot(get(paste0(ref_yields2Mac[i2], ".ts")), plotv = 2, MacAna_ref)
```

```{r}
#Processing--------------------------------------
#Align yields to PMIs.
yields_ref <- ref_yields.major[2]
MacAna_ref <- ref_MacAnaMonthly[c(1:5,10:11)] #PMIs
#Align Macro Monthly Data to yields
assign(paste0(ref_yields2Mac[3], ".ts"), AssFun$yields_MacAna_align(yields_ref, MacAna_ref))
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 3
```

### `r ref_yields2Mac[i2]`

```{r}
#Ploting Trading Data to Macro Data
AssFun$yields_MacAna_plot(get(paste0(ref_yields2Mac[i2], ".ts")), plotv = 2, MacAna_ref)
```

```{r}
#Processing--------------------------------------
#Align yields to cpis.
yields_ref <- ref_yields.major[2]
MacAna_ref <- ref_MacAnaMonthly[6:9] #cpis
#Align Macro Monthly Data to Trade Data
assign(paste0(ref_yields2Mac[4], ".ts"), AssFun$yields_MacAna_align(yields_ref, MacAna_ref))
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 4
```

### `r ref_yields2Mac[i2]`

```{r}
#Ploting Trading to Macro Data
AssFun$yields_MacAna_plot(get(paste0(ref_yields2Mac[i2], ".ts")), plotv = 2, MacAna_ref)
```

```{r}
#Processing--------------------------------------
#Align yields to PMIs.
yields_ref <- ref_yields.major[3]
MacAna_ref <- ref_MacAnaMonthly[c(1:5,10:11)] #PMIs
#Align Macro Monthly Data to yields
assign(paste0(ref_yields2Mac[5], ".ts"), AssFun$yields_MacAna_align(yields_ref, MacAna_ref))
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 5
```

### `r ref_yields2Mac[i2]`

```{r}
#Ploting Trading Data to Macro Data
AssFun$yields_MacAna_plot(get(paste0(ref_yields2Mac[i2], ".ts")), plotv = 2, MacAna_ref)
```

```{r}
#Processing--------------------------------------
#Align yields to cpis.
yields_ref <- ref_yields.major[3]
MacAna_ref <- ref_MacAnaMonthly[6:9] #cpis
#Align Macro Monthly Data to Trade Data
assign(paste0(ref_yields2Mac[6], ".ts"), AssFun$yields_MacAna_align(yields_ref, MacAna_ref))
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 6
```

### `r ref_yields2Mac[i2]`

```{r}
#Ploting Trading to Macro Data
AssFun$yields_MacAna_plot(get(paste0(ref_yields2Mac[i2], ".ts")), plotv = 2, MacAna_ref)
```

WEEKLY MACROS {.tabset .tabset-fade}
-------------------------------------

4) Weekly Macro Datas.

```{r Weekly Macro Datas, fig.width=15}
#Functions---------------------------------------
#Functions to Read Weekly Macro Data Data From Excel File
AssFun$read_excel_macanaweekly <- function(macanaweekly_name){
  #Read Excel File Data.
  MacAna.read <- read_excel(file.path(globalWD.data, "MacAnaWeekly.xls"),
                        col_types = c("text", rep("numeric", length(macanaweekly_name))),
                        col_names = TRUE
  )
  colnames(MacAna.read) <- c("Date", macanaweekly_name)
  #Subsetting Into 10 Year Window.
  MacAna.read <- subset.data.frame(MacAna.read, 
                                   year(strptime(MacAna.read[[1]], format = "%Y-%m-%d")) >= globalStartYear)
  #Dealing with NAs.
  MacAna.read.na <- as.data.frame(na.approx(MacAna.read[,2:length(MacAna.read)]))
  MacAna.read.na <- cbind(MacAna.read[, 1], MacAna.read.na)
  colnames(MacAna.read.na) <- c("Date", macanaweekly_name)
  #Return Dataframe without NAs.
  return(MacAna.read.na)
}

#Processing--------------------------------------
#Read Daily Macro Analysis Data.
ref_MacAnaWeekly <- c("SI_CS", "GC_CS", "ZS00Y_CS")
ref_MacAnaWeekly.text <- c("COMEX Silver Commercial Short OPIs",
                          "COMEX Gold Commercial Short OPIs",
                          "CBOT Soybean Commercial Short OPIs")
MacAnaWeekly <- AssFun$read_excel_macanaweekly(ref_MacAnaWeekly)
```

### SI_CS VS. CU0

```{r}
#Use XTS package.
SI_OPIs.futures <- DailyTD.HPFs$CU0DailyTD.hpf
SI_OPIs.OPIs <- as.xts((MacAnaWeekly$SI_CS - mean(MacAnaWeekly$SI_CS, na.rm = TRUE)) / 20, 
                      order.by = strptime(MacAnaWeekly$Date, tz = "GMT", format = "%Y-%m-%d"))
#index(SI_OPIs.futures)
#index(SI_OPIs.OPIs)
SI_OPIs.xts <- merge.xts(SI_OPIs.futures, SI_OPIs.OPIs, join = "right")
SI_OPIs.xts.2 <- SI_OPIs.xts[paste0(toString(globalEndYear-5), "/", toString(globalEndYear))]

#Graphical Output of the Spread Using ggplot2 package.
x_label <- seq.Date(from = as.Date(index(SI_OPIs.xts.2[1])), 
                    to = as.Date(index(SI_OPIs.xts.2[dim(SI_OPIs.xts.2)[1]])), by = "month")
SI_OPIs.gg1 <- ggplot(SI_OPIs.xts.2, aes(x = factor(index(SI_OPIs.xts.2)),group = 1)) +
  geom_bar(aes(y = SI_OPIs.OPIs), fill = "blue", colour = "lightblue", stat = "identity") + 
  geom_line(aes(y = CU0_hpfc), colour = "black") + 
  geom_point(aes(y = CU0_hpfc), colour = "red") +
  scale_x_discrete(breaks = c(as.character(x_label)), 
                   labels = format(x = x_label, format = "%m%d\n%Y")) +
  ggtitle("COMEX Silver Commercial Short OPIs") + xlab("Date of Trade") + 
  ylab(paste0("Demeaned SI_CS( X 20000), MEAN = ", toString(round(mean(MacAnaWeekly$SI_CS, 
                                                                 na.rm = TRUE)) / 200 )))
SI_OPIs.gg1

```

### GC_CS VS. CU0

```{r}
#Use XTS package.
GC_OPIs.futures <- DailyTD.HPFs$CU0DailyTD.hpf
GC_OPIs.OPIs <- as.xts((MacAnaWeekly$GC_CS - mean(MacAnaWeekly$GC_CS, na.rm = TRUE)) / 10, 
                      order.by = strptime(MacAnaWeekly$Date, tz = "GMT", format = "%Y-%m-%d"))
#index(GC_OPIs.futures)
#index(GC_OPIs.OPIs)
GC_OPIs.xts <- merge.xts(GC_OPIs.futures, GC_OPIs.OPIs, join = "right")
GC_OPIs.xts.2 <- GC_OPIs.xts[paste0(toString(globalEndYear-5), "/", toString(globalEndYear))]

#Graphical Output of the Spread Using ggplot2 package.
x_label <- seq.Date(from = as.Date(index(GC_OPIs.xts.2[1])), 
                    to = as.Date(index(GC_OPIs.xts.2[dim(GC_OPIs.xts.2)[1]])), by = "month")
GC_OPIs.gg1 <- ggplot(GC_OPIs.xts.2, aes(x = factor(index(GC_OPIs.xts.2)),group = 1)) +
  geom_bar(aes(y = GC_OPIs.OPIs), fill = "purple", colour = "lightblue", stat = "identity") + 
  geom_line(aes(y = CU0_hpfc), colour = "black") +
  geom_point(aes(y = CU0_hpfc), colour = "red") +
  scale_x_discrete(breaks = c(as.character(x_label)), 
                   labels = format(x = x_label, format = "%m%d\n%Y")) +
  ggtitle("COMEX Gold Commercial Short OPIs") + xlab("Date of Trade") + 
  ylab(paste0("Demeaned GC_CS( X 500), MEAN = ", toString(round(mean(MacAnaWeekly$GC_CS, 
                                                                 na.rm = TRUE)) / 500 )))
GC_OPIs.gg1

```

### SI_CS VS. AG0

```{r}
#Use XTS package.
SI_OPIs.futures <- DailyTD.HPFs$AG0DailyTD.hpf
SI_OPIs.OPIs <- as.xts((MacAnaWeekly$SI_CS - mean(MacAnaWeekly$SI_CS, na.rm = TRUE)) / 100, 
                      order.by = strptime(MacAnaWeekly$Date, tz = "GMT", format = "%Y-%m-%d"))
#index(SI_OPIs.futures)
#index(SI_OPIs.OPIs)
SI_OPIs.xts <- merge.xts(SI_OPIs.futures, SI_OPIs.OPIs, join = "right")
SI_OPIs.xts.2 <- SI_OPIs.xts[paste0(toString(globalEndYear-5), "/", toString(globalEndYear))]

#Graphical Output of the Spread Using ggplot2 package.
x_label <- seq.Date(from = as.Date(index(SI_OPIs.xts.2[1])), 
                    to = as.Date(index(SI_OPIs.xts.2[dim(SI_OPIs.xts.2)[1]])), by = "month")
SI_OPIs.gg1 <- ggplot(SI_OPIs.xts.2, aes(x = factor(index(SI_OPIs.xts.2)),group = 1)) +
  geom_bar(aes(y = SI_OPIs.OPIs), fill = "blue", colour = "lightblue", stat = "identity") + 
  geom_line(aes(y = AG0_hpfc), colour = "black") + 
  geom_point(aes(y = AG0_hpfc), colour = "red") +
  scale_x_discrete(breaks = c(as.character(x_label)), 
                   labels = format(x = x_label, format = "%m%d\n%Y")) +
  ggtitle("COMEX Silver Commercial Short OPIs") + xlab("Date of Trade") + 
  ylab(paste0("Demeaned SI_CS( X 20000), MEAN = ", toString(round(mean(MacAnaWeekly$SI_CS, 
                                                                 na.rm = TRUE)) / 200 )))
SI_OPIs.gg1

```

### GC_CS VS. AG0

```{r}
#Use XTS package.
GC_OPIs.futures <- DailyTD.HPFs$AG0DailyTD.hpf
GC_OPIs.OPIs <- as.xts((MacAnaWeekly$GC_CS - mean(MacAnaWeekly$GC_CS, na.rm = TRUE)) / 200, 
                      order.by = strptime(MacAnaWeekly$Date, tz = "GMT", format = "%Y-%m-%d"))
#index(GC_OPIs.futures)
#index(GC_OPIs.OPIs)
GC_OPIs.xts <- merge.xts(GC_OPIs.futures, GC_OPIs.OPIs, join = "right")
GC_OPIs.xts.2 <- GC_OPIs.xts[paste0(toString(globalEndYear-5), "/", toString(globalEndYear))]

#Graphical Output of the Spread Using ggplot2 package.
x_label <- seq.Date(from = as.Date(index(GC_OPIs.xts.2[1])), 
                    to = as.Date(index(GC_OPIs.xts.2[dim(GC_OPIs.xts.2)[1]])), by = "month")
GC_OPIs.gg1 <- ggplot(GC_OPIs.xts.2, aes(x = factor(index(GC_OPIs.xts.2)),group = 1)) +
  geom_bar(aes(y = GC_OPIs.OPIs), fill = "purple", colour = "lightblue", stat = "identity") + 
  geom_line(aes(y = AG0_hpfc), colour = "black") +
  geom_point(aes(y = AG0_hpfc), colour = "red") +
  scale_x_discrete(breaks = c(as.character(x_label)), 
                   labels = format(x = x_label, format = "%m%d\n%Y")) +
  ggtitle("COMEX Gold Commercial Short OPIs") + xlab("Date of Trade") + 
  ylab(paste0("Demeaned GC_CS( X 200), MEAN = ", toString(round(mean(MacAnaWeekly$GC_CS, 
                                                                 na.rm = TRUE)) / 500 )))
GC_OPIs.gg1

```

### SI_CS VS. AU0

```{r SI_CS}
#Use XTS package.
SI_OPIs.futures <- DailyTD.HPFs$AU0DailyTD.hpf
SI_OPIs.OPIs <- as.xts((MacAnaWeekly$SI_CS - mean(MacAnaWeekly$SI_CS, na.rm = TRUE)) / 2000, 
                      order.by = strptime(MacAnaWeekly$Date, tz = "GMT", format = "%Y-%m-%d"))
#index(SI_OPIs.futures)
#index(SI_OPIs.OPIs)
SI_OPIs.xts <- merge.xts(SI_OPIs.futures, SI_OPIs.OPIs, join = "right")
SI_OPIs.xts.2 <- SI_OPIs.xts[paste0(toString(globalEndYear-5), "/", toString(globalEndYear))]

#Graphical Output of the Spread Using ggplot2 package.
x_label <- seq.Date(from = as.Date(index(SI_OPIs.xts.2[1])), 
                    to = as.Date(index(SI_OPIs.xts.2[dim(SI_OPIs.xts.2)[1]])), by = "month")
SI_OPIs.gg1 <- ggplot(SI_OPIs.xts.2, aes(x = factor(index(SI_OPIs.xts.2)),group = 1)) +
  geom_bar(aes(y = SI_OPIs.OPIs), fill = "blue", colour = "lightblue", stat = "identity") + 
  geom_line(aes(y = AU0_hpfc), colour = "black") +
  geom_point(aes(y = AU0_hpfc), colour = "red") +
  scale_x_discrete(breaks = c(as.character(x_label)), 
                   labels = format(x = x_label, format = "%m%d\n%Y")) +
  ggtitle("COMEX Silver Commercial Short OPIs") + xlab("Date of Trade") + 
  ylab(paste0("Demeaned SI_CS( X 2000), MEAN = ", toString(round(mean(MacAnaWeekly$SI_CS, 
                                                                 na.rm = TRUE)) / 2000 )))
SI_OPIs.gg1

```

### GC_CS VS. AU0

```{r GC_CS}
#Use XTS package.
GC_OPIs.futures <- DailyTD.HPFs$AU0DailyTD.hpf
GC_OPIs.OPIs <- as.xts((MacAnaWeekly$GC_CS - mean(MacAnaWeekly$GC_CS, na.rm = TRUE)) / 1000, 
                      order.by = strptime(MacAnaWeekly$Date, tz = "GMT", format = "%Y-%m-%d"))
#index(GC_OPIs.futures)
#index(GC_OPIs.OPIs)
GC_OPIs.xts <- merge.xts(GC_OPIs.futures, GC_OPIs.OPIs, join = "right")
GC_OPIs.xts.2 <- GC_OPIs.xts[paste0(toString(globalEndYear-5), "/", toString(globalEndYear))]

#Graphical Output of the Spread Using ggplot2 package.
x_label <- seq.Date(from = as.Date(index(GC_OPIs.xts.2[1])), 
                    to = as.Date(index(GC_OPIs.xts.2[dim(GC_OPIs.xts.2)[1]])), by = "month")
GC_OPIs.gg1 <- ggplot(GC_OPIs.xts.2, aes(x = factor(index(GC_OPIs.xts.2)),group = 1)) +
  geom_bar(aes(y = GC_OPIs.OPIs), fill = "purple", colour = "lightblue", stat = "identity") + 
  geom_line(aes(y = AU0_hpfc), colour = "black") +
  geom_point(aes(y = AU0_hpfc), colour = "red") +
  scale_x_discrete(breaks = c(as.character(x_label)), 
                   labels = format(x = x_label, format = "%m%d\n%Y")) +
  ggtitle("COMEX Gold Commercial Short OPIs") + xlab("Date of Trade") + 
  ylab(paste0("Demeaned GC_CS( X 5000), MEAN = ", toString(round(mean(MacAnaWeekly$GC_CS, 
                                                                 na.rm = TRUE)) / 5000 )))
GC_OPIs.gg1

```

### ZS00Y_CS VS. M0

```{r ZS00Y_CS 2 M0}
#Use XTS package.
ZS_OPIs.futures <- DailyTD.HPFs$M0DailyTD.hpf
ZS_OPIs.OPIs <- as.xts((MacAnaWeekly$ZS00Y_CS - mean(MacAnaWeekly$ZS00Y_CS, na.rm = TRUE)) / 500 , 
                      order.by = strptime(MacAnaWeekly$Date, tz = "GMT", format = "%Y-%m-%d"))
#index(GC_OPIs.futures)
#index(GC_OPIs.OPIs)
ZS_OPIs.xts <- merge.xts(ZS_OPIs.futures, ZS_OPIs.OPIs, join = "right")
ZS_OPIs.xts.2 <- ZS_OPIs.xts[paste0(toString(globalEndYear-5), "/", toString(globalEndYear))]

#Graphical Output of the Spread Using ggplot2 package.
x_label <- seq.Date(from = as.Date(index(ZS_OPIs.xts.2[1])), 
                    to = as.Date(index(ZS_OPIs.xts.2[dim(ZS_OPIs.xts.2)[1]])), by = "2 weeks")
ZS_OPIs.gg1 <- ggplot(ZS_OPIs.xts.2, aes(x = factor(index(ZS_OPIs.xts.2)),group = 1)) +
  geom_bar(aes(y = ZS_OPIs.OPIs), fill = "purple", colour = "lightblue", stat = "identity") + 
  geom_line(aes(y = M0_hpfc), colour = "black") +
  geom_point(aes(y = M0_hpfc), colour = "red") +
  scale_x_discrete(breaks = c(as.character(x_label)), 
                   labels = format(x = x_label, format = "%m%d\n%Y")) +
  ggtitle("CBOT SOYBEANS Commercial Short OPIs") + xlab("Date of Trade") + 
  ylab(paste0("Demeaned ZS_CS( X 500), MEAN = ", toString(round(mean(MacAnaWeekly$ZS_CS, 
                                                                 na.rm = TRUE)) / 500 )))
ZS_OPIs.gg1

```

### GC_CS VS. RU0

```{r GC_CS 2 RU}
#Use XTS package.
GC_OPIs.futures <- DailyTD.HPFs$RU0DailyTD.hpf
GC_OPIs.OPIs <- as.xts((MacAnaWeekly$GC_CS - mean(MacAnaWeekly$GC_CS, na.rm = TRUE)) / 50, 
                      order.by = strptime(MacAnaWeekly$Date, tz = "GMT", format = "%Y-%m-%d"))
#index(GC_OPIs.futures)
#index(GC_OPIs.OPIs)
GC_OPIs.xts <- merge.xts(GC_OPIs.futures, GC_OPIs.OPIs, join = "right")
GC_OPIs.xts.2 <- GC_OPIs.xts[paste0(toString(globalEndYear-5), "/", toString(globalEndYear))]

#Graphical Output of the Spread Using ggplot2 package.
x_label <- seq.Date(from = as.Date(index(GC_OPIs.xts.2[1])), 
                    to = as.Date(index(GC_OPIs.xts.2[dim(GC_OPIs.xts.2)[1]])), by = "month")
GC_OPIs.gg1 <- ggplot(GC_OPIs.xts.2, aes(x = factor(index(GC_OPIs.xts.2)),group = 1)) +
  geom_bar(aes(y = GC_OPIs.OPIs), fill = "purple", colour = "lightblue", stat = "identity") + 
  geom_line(aes(y = RU0_hpfc), colour = "black") +
  geom_point(aes(y = RU0_hpfc), colour = "red") +
  scale_x_discrete(breaks = c(as.character(x_label)), 
                   labels = format(x = x_label, format = "%m%d\n%Y")) +
  ggtitle("COMEX Gold Commercial Short OPIs") + xlab("Date of Trade") + 
  ylab(paste0("Demeaned GC_CS( X 50), MEAN = ", toString(round(mean(MacAnaWeekly$GC_CS, 
                                                                 na.rm = TRUE)) / 5000 )))
GC_OPIs.gg1

```


### SI_CS VS. RU0

```{r SI_CS to RU}
#Use XTS package.
SI_OPIs.futures <- DailyTD.HPFs$RU0DailyTD.hpf
SI_OPIs.OPIs <- as.xts((MacAnaWeekly$SI_CS - mean(MacAnaWeekly$SI_CS, na.rm = TRUE)) / 20, 
                      order.by = strptime(MacAnaWeekly$Date, tz = "GMT", format = "%Y-%m-%d"))
#index(SI_OPIs.futures)
#index(SI_OPIs.OPIs)
SI_OPIs.xts <- merge.xts(SI_OPIs.futures, SI_OPIs.OPIs, join = "right")
SI_OPIs.xts.2 <- SI_OPIs.xts[paste0(toString(globalEndYear-5), "/", toString(globalEndYear))]

#Graphical Output of the Spread Using ggplot2 package.
x_label <- seq.Date(from = as.Date(index(SI_OPIs.xts.2[1])), 
                    to = as.Date(index(SI_OPIs.xts.2[dim(SI_OPIs.xts.2)[1]])), by = "month")
SI_OPIs.gg1 <- ggplot(SI_OPIs.xts.2, aes(x = factor(index(SI_OPIs.xts.2)),group = 1)) +
  geom_bar(aes(y = SI_OPIs.OPIs), fill = "blue", colour = "lightblue", stat = "identity") + 
  geom_line(aes(y = RU0_hpfc), colour = "black") +
  geom_point(aes(y = RU0_hpfc), colour = "red") +
  scale_x_discrete(breaks = c(as.character(x_label)), 
                   labels = format(x = x_label, format = "%m%d\n%Y")) +
  ggtitle("COMEX Silver Commercial Short OPIs") + xlab("Date of Trade") + 
  ylab(paste0("Demeaned SI_CS( X 20), MEAN = ", toString(round(mean(MacAnaWeekly$SI_CS, 
                                                                 na.rm = TRUE)) / 2000 )))
SI_OPIs.gg1

```

### ZS00Y_CS VS. RU0

```{r ZS00Y_CS 2 RU0}
#Use XTS package.
ZS_OPIs.futures <- DailyTD.HPFs$RU0DailyTD.hpf
ZS_OPIs.OPIs <- as.xts((MacAnaWeekly$ZS00Y_CS - mean(MacAnaWeekly$ZS00Y_CS, na.rm = TRUE)) / 100 , 
                      order.by = strptime(MacAnaWeekly$Date, tz = "GMT", format = "%Y-%m-%d"))
#index(GC_OPIs.futures)
#index(GC_OPIs.OPIs)
ZS_OPIs.xts <- merge.xts(ZS_OPIs.futures, ZS_OPIs.OPIs, join = "right")
ZS_OPIs.xts.2 <- ZS_OPIs.xts[paste0(toString(globalEndYear-5), "/", toString(globalEndYear))]

#Graphical Output of the Spread Using ggplot2 package.
x_label <- seq.Date(from = as.Date(index(ZS_OPIs.xts.2[1])), 
                    to = as.Date(index(ZS_OPIs.xts.2[dim(ZS_OPIs.xts.2)[1]])), by = "month")
ZS_OPIs.gg1 <- ggplot(ZS_OPIs.xts.2, aes(x = factor(index(ZS_OPIs.xts.2)),group = 1)) +
  geom_bar(aes(y = ZS_OPIs.OPIs), fill = "purple", colour = "lightblue", stat = "identity") + 
  geom_line(aes(y = RU0_hpfc), colour = "black") +
  geom_point(aes(y = RU0_hpfc), colour = "red") +
  scale_x_discrete(breaks = c(as.character(x_label)), 
                   labels = format(x = x_label, format = "%m%d\n%Y")) +
  ggtitle("CBOT SOYBEANS Commercial Short OPIs") + xlab("Date of Trade") + 
  ylab(paste0("Demeaned ZS_CS( X 100), MEAN = ", toString(round(mean(MacAnaWeekly$ZS_CS, 
                                                                 na.rm = TRUE)) / 500 )))
ZS_OPIs.gg1

```

TREASURY YIELD SPREADS {.tabset .tabset-fade}
-------------------------------------

3) Treasury Yield Spreads.

```{r MIUtoMACRO: Treasury Yield Spreads}
#Funtions----------------------------------------
#Here We Calculate the Spreads over China 10yr Treasury Yields to Others.
#Functions to calculate the spread, return spread value and its name.
AssFun$yield_spread_calculate <- function(yields_dataset, minuid, subtrahid){
  yields_spread <- xts(as.numeric(yields_dataset[, minuid]) - as.numeric(yields_dataset[,subtrahid]), 
                       order.by = index(yields_dataset))
  colnames(yields_spread) <- c(paste0(colnames(yields_dataset[,minuid]), 
                                      "2",
                                      colnames(yields_dataset[,subtrahid]))
                               )
  return(yields_spread)
}

#Processing--------------------------------------
#Convert yields to xts object for convience, in the same time remove the Date column.
yields.xts <- xts(yields[,-1], order.by = strptime(yields[,1], format = "%Y-%m-%d")) # 1 for CN_10yry, 7 for CN_5yry
yields.spread <- yields.xts[,1]
for(i in c(2:dim(yields.xts)[2])){
  yields.spread <- merge.xts(yields.spread,
                             AssFun$yield_spread_calculate(yields.xts, 1, i))
}
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 2
```

### `r colnames(yields.spread)[i2]`

```{r }
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot.xts(yields.spread[, i2][paste(toString(globalEndYear-midtermYear1),toString(globalEndYear),sep="/")],
         type="h",col="blue",
         main=paste0(colnames(yields.spread)[i2], " in ", toString(midtermYear1), " years."),legend.loc="topleft",
         observation.based = T)
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 3
```

### `r colnames(yields.spread)[i2]`

```{r }
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot.xts(yields.spread[, i2][paste(toString(globalEndYear-midtermYear1),toString(globalEndYear),sep="/")],
         type="h",col="blue",
         main=paste0(colnames(yields.spread)[i2], " in ", toString(midtermYear1), " years."),legend.loc="topleft",
         observation.based = T)
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 4
```

### `r colnames(yields.spread)[i2]`

```{r }
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot.xts(yields.spread[, i2][paste(toString(globalEndYear-midtermYear1),toString(globalEndYear),sep="/")],
         type="h",col="blue",
         main=paste0(colnames(yields.spread)[i2], " in ", toString(midtermYear1), " years."),legend.loc="topleft",
         observation.based = T)
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 5
```

### `r colnames(yields.spread)[i2]`

```{r }
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot.xts(yields.spread[, i2][paste(toString(globalEndYear-midtermYear1),toString(globalEndYear),sep="/")],
         type="h",col="blue",
         main=paste0(colnames(yields.spread)[i2], " in ", toString(midtermYear1), " years."),legend.loc="topleft",
         observation.based = T)
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 6
```

### `r colnames(yields.spread)[i2]`

```{r }
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot.xts(yields.spread[, i2][paste(toString(globalEndYear-midtermYear1),toString(globalEndYear),sep="/")],
         type="h",col="blue",
         main=paste0(colnames(yields.spread)[i2], " in ", toString(midtermYear1), " years."),legend.loc="topleft",
         observation.based = T)
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 7
```

### `r colnames(yields.spread)[i2]`

```{r }
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot.xts(yields.spread[, i2][paste(toString(globalEndYear-midtermYear1),toString(globalEndYear),sep="/")],
         type="h",col="blue",
         main=paste0(colnames(yields.spread)[i2], " in ", toString(midtermYear1), " years."),legend.loc="topleft",
         observation.based = T)
```

```{r}
#At This Chunks, we Defined i2 for Automatic Output
i2 <- 8
```

### `r colnames(yields.spread)[i2]`

```{r }
par(mai=c(0.5,0.5,0.5,0.5))
par(mfcol=c(1,1))
plot.xts(yields.spread[, i2][paste(toString(globalEndYear-midtermYear1),toString(globalEndYear),sep="/")],
         type="h",col="blue",
         main=paste0(colnames(yields.spread)[i2], " in ", toString(midtermYear1), " years."),legend.loc="topleft",
         observation.based = T)
```


Yields
==================================================

TRENDS and CYCLES {.tabset .tabset-pills data-height=800}
-------------------------------------

### YIELDS TREND

```{r YIELDS yields trend}
#Processing--------------------------------------
#Align all to CN 10yr yields Futures Close Price
Major_ref <- ref_yields[1]
Align_ref <- c(ref_yields[-1])
#Process to get all yields aligned.
yields_All.ts <- AssFun$TD_align_all(Major_ref, Align_ref)

#Output------------------------------------------
#Ploting all yeilds aligned
AssFun$TD_MacAna_plot(yields_All.ts, plotv = 2, Align_ref)
```

### YIELDS TREND 2

```{r YIELDS yields trend 2}
#Processing--------------------------------------
#Align all to CN 10yr yields Futures Close Price
Major_ref <- ref_yields[1]
Align_ref <- c(ref_yields[2:4])
#Process to get all yields aligned.
yields_All.ts <- AssFun$TD_align_all(Major_ref, Align_ref)

#Output------------------------------------------
#Ploting all yeilds aligned
AssFun$TD_MacAna_plot(yields_All.ts, plotv = 2, Align_ref)
Major_ref <- ref_yields[1]
Align_ref <- c(ref_yields[-1])
yields_All.ts <- AssFun$TD_align_all(Major_ref, Align_ref)
```

### CN_10yry

```{r}
i2 <- 1 #CN_10yry
par(mfcol=c(1,2))
plot(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_yields.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],
          main=paste0(ref_yields.text[i2]," HPFC in 1 Year."))
```

### US_10yry

```{r}
i2 <- 2 #US_10yry
par(mfcol=c(1,2))
plot(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_yields.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],
          main=paste0(ref_yields.text[i2]," HPFC in 1 Year."))
```

### CN_2yry

```{r}
i2 <- 8 #CN_2yry
par(mfcol=c(1,2))
plot(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_yields.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],
          main=paste0(ref_yields.text[i2]," HPFC in 1 Year."))
```

### Indonasia_10yry

```{r}
i2 <- 9 #US_2yry
par(mfcol=c(1,2))
plot(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_yields.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(yields.HPFs[[paste0(ref_yields[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],
          main=paste0(ref_yields.text[i2]," HPFC in 1 Year."))
```

### USDX

```{r}
i2 <- 1 #USDX
par(mfcol=c(1,2))
plot(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_Currency.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],
          main=paste0(ref_Currency.text[i2]," HPFC in 1 Year."))
```

### USDCNH

```{r}
i2 <- 2 #USDCNH
par(mfcol=c(1,2))
plot(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_Currency.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],
          main=paste0(ref_Currency.text[i2]," HPFC in 1 Year."))
```

### GBPUSD

```{r}
i2 <- 3 #GBPUSD
par(mfcol=c(1,2))
plot(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_Currency.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],
          main=paste0(ref_Currency.text[i2]," HPFC in 1 Year."))
```

### EURUSD

```{r}
i2 <- 4 #EURUSD
par(mfcol=c(1,2))
plot(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][,-3][paste(toString(globalEndYear-1),
                                        toString(globalEndYear),sep="/")], 
     main=paste0(ref_Currency.text[i2]," in 1 Year."), 
     observation.based = TRUE)
addSeries(CurrencyDaily.HPFs[[paste0(ref_Currency[i2], 'DailyTD.hpf')]][,3][paste(toString(globalEndYear-1),
                                      toString(globalEndYear),sep="/")],
          main=paste0(ref_Currency.text[i2]," HPFC in 1 Year."))
```

## YIELDS CYCLE {data-height=3500}

```{r YIELDS yields cycle, fig.width=16}
#Visualizing Functions.==========================
#Fucntion using plot in timeSeries package.
AssFun$Cycles_Visualize <- function(Cycle_dataset, #Cycles
                              Major_id = 1){ #For Ploting Major curve
  #Setting ploting layout.
  par(mai=c(0.38,0.5,0.3,0.5))
  par(mfcol = c(2,1))
  #Ploting
    for(ig in 1:dim(Cycle_dataset)[2]){
      if(ig == dim(Cycle_dataset)[2]){
        par(new = F)
        timeSeries::plot(Cycle_dataset[, Major_id], plot.type = c("single"), ann = FALSE, col = Major_id)
        grid()
        par(new = T)
        timeSeries::plot(Cycle_dataset[, ig], plot.type = c("single"), 
                         ann = FALSE, col = ig, yaxt = "n", xaxt = "n")
        mtext(paste0("CYCLES VISUALIZING: ", 
                     Cycle_dataset@units[Major_id], " to ", 
                     Cycle_dataset@units[ig]), side = 3, cex = 1)
        legend("topleft", c(Cycle_dataset@units[Major_id], Cycle_dataset@units[ig]), 
               lty = 1, col= c(Major_id, ig))
        #Then plot layer shows all curves.
        for (ig2 in 1: dim(Cycle_dataset)[2]){
          if(ig2 == 1){
            par(new = F)
            timeSeries::plot(Cycle_dataset[, ig2], plot.type = c("single"), ann = FALSE, col = ig2)
            grid()
          }else{
            par(new = T)
            timeSeries::plot(Cycle_dataset[, ig2], plot.type = c("single"), 
                             ann = FALSE, col = ig2, yaxt = "n", xaxt = "n")
          }
        }
        mtext(paste0("CYCLES VISUALIZING: ", Cycle_dataset@units[Major_id], 
                     " to All Cycles."), side = 3, cex = 1)
        legend("topleft", Cycle_dataset@units, lty = 1, col= seq.int(1, dim(Cycle_dataset)[2]))
      }else{
        par(new = F)
        timeSeries::plot(Cycle_dataset[, Major_id], plot.type = c("single"), ann = FALSE, col = Major_id)
        grid()
        par(new = T)
        timeSeries::plot(Cycle_dataset[, ig], plot.type = c("single"), 
                         ann = FALSE, col = ig, yaxt = "n", xaxt = "n")
        mtext(paste0("CYCLES VISUALIZING: ", 
                     Cycle_dataset@units[Major_id], " to ", 
                     Cycle_dataset@units[ig]), side = 3, cex = 1)
        legend("topleft", c(Cycle_dataset@units[Major_id], Cycle_dataset@units[ig]), 
               lty = 1, col= c(Major_id, ig))
      }
    }
}


#Processing.=====================================
Cycles.yields_All <- yields_All.ts[, paste0(ref_yields, "_hpfc")]
#Windows the dataset into midterm1 framework.
Cycles.yields_All <- window(Cycles.yields_All, end(Cycles.yields_All) - years(midtermYear1),
                            end(Cycles.yields_All))

#Visualzing.=====================================
AssFun$Cycles_Visualize(Cycles.yields_All, Major_id = 1)
```

Turns
==================================================

WHAT TURNS {.tabset .tabset-fade}
-------------------------------------

### DOMESTIC TURNS

```{r Domestic Turns}
#Functions to Plot.------------------------------
AssFun$Turns_Plot <- function(Trends_DS = timeSeries(NULL), Cycles_DS = timeSeries(NULL)){ 
  par(mai=c(0.38,0.5,0.3,0.5))
  par(mfcol=c(2,1))
  #Plot the Trends.
  for(ig in 1:(dim(Trends_DS)[2]-1)){
    if(ig == 1){
      par(new = F)
      timeSeries::plot(Trends_DS[, ig], plot.type = c("single"), ann = FALSE, col = 1, lwd = 1)
      grid()
      par(new = T)
      timeSeries::plot(Trends_DS[, ig+1], plot.type = c("single"), 
                       ann = FALSE, col = ig+1, yaxt = "n", xaxt = "n", axes = FALSE)
    }else{
      par(new = T)
      timeSeries::plot(Trends_DS[, ig+1], plot.type = c("single"), 
                       ann = FALSE, col = ig+1, yaxt = "n", xaxt = "n", axes = FALSE)
    }
  }
  mtext(paste0("Domestic Turns Trends. ", colnames(Trends_DS)[1], " to ", 
               toString(colnames(Trends_DS)[-1]), "."), 
        side =3, ces = 1)
  legend("topleft", c(colnames(Trends_DS)), lty =1, 
         col = seq.int(1, dim(Trends_DS)[2]))
  #Plot the Cycles.
  for(ig in 1:(dim(Cycles_DS)[2]-1)){
    if(ig == 1){
      par(new = F)
      timeSeries::plot(Cycles_DS[, ig], plot.type = c("single"), ann = FALSE, col = 1, lwd = 1)
      grid()
      par(new = T)
      timeSeries::plot(Cycles_DS[, ig+1], plot.type = c("single"), 
                       ann = FALSE, col = ig+1, yaxt = "n", xaxt = "n", axes = FALSE)
    }else{
      par(new = T)
      timeSeries::plot(Cycles_DS[, ig+1], plot.type = c("single"), 
                       ann = FALSE, col = ig+1, yaxt = "n", xaxt = "n", axes = FALSE)
    }
  }
  mtext(paste0("Domestic Turns Cycless. ", colnames(Cycles_DS)[1], " to ", 
               toString(colnames(Cycles_DS)[-1]), "."), 
        side =3, ces = 1)
  legend("topleft", c(colnames(Cycles_DS)), lty =1, 
         col = seq.int(1, dim(Cycles_DS)[2]))
}

#Processsing-------------------------------------
#Abtain domestic turns dataset. 
subID.DomTurns <- c("CN_10yry", "USDCNH") 
#Use subID throught TRENDS and CYCLES
DomTurns.Trends <- TD_All.ts[, paste0(subID.DomTurns, "_hpft")]
DomTurns.Cycles <- TD_All.ts[, paste0(subID.DomTurns, "_hpfc")]
#Plot The Turns

AssFun$Turns_Plot(Trends_DS = DomTurns.Trends, Cycles_DS = DomTurns.Cycles)
```

### AMERICA TURNS

```{r America Turns}
#Processsing-------------------------------------
#Abtain domestic turns dataset. 
subID.ForTurns <- c("US_10yry", "USDX") 
#Use subID throught TRENDS and CYCLES
ForTurns.Trends <- TD_All.ts[, paste0(subID.ForTurns, "_hpft")]
ForTurns.Cycles <- TD_All.ts[, paste0(subID.ForTurns, "_hpfc")]
#Plot The Turns

AssFun$Turns_Plot(Trends_DS = ForTurns.Trends, Cycles_DS = ForTurns.Cycles)
```

### UK TURNS

```{r UK Turns}
#Processsing-------------------------------------
#Abtain domestic turns dataset. 
subID.ForTurns <- c("UK_10yry", "GBPUSD") 
#Use subID throught TRENDS and CYCLES
ForTurns.Trends <- TD_All.ts[, paste0(subID.ForTurns, "_hpft")]
ForTurns.Cycles <- TD_All.ts[, paste0(subID.ForTurns, "_hpfc")]
#Plot The Turns

AssFun$Turns_Plot(Trends_DS = ForTurns.Trends, Cycles_DS = ForTurns.Cycles)
```

NEWIE {.tabset .tabset-fade .tabset-pills data-height=3200}
-------------------------------------

### Miuntes

1) Original VAR(p)

The original VAR(p) model has the disadvantage that it requires the dataset to be stationary, which means no information of the trends should be kept. After Implementation to multiple yields dataset, unitroot test and structural analysis are both carried out respectively to trends and cycles. Conserning a stationary process, trends and cycles of yields are both tested to be stationary. Causalities are detected in trends but not in cycles.

Discoveries:

  - The probability of stability increase along with increasement of K-dimention of trends.
  
  - But causality of cycles decreases along with increasement of K-dimention.
  
But This part has been removed at 9/26/2018.
  
(2) Distributions.

  For the purpose of further learning, I started with an analysis of the distributions of the targets and locker cycles and trends.
  
  Analysis found that cycles fits well into GHD(Generalized Hypobolic Distribution).
  
  For all targets and locker and, together with, yields and EURUSD, distributuions are observed and analyized.
  
  Problems to solve:
  
  - ES of J0_hpfc are far more underestimating the risk.
  
  - GHD of T00C2_hpfc is now visable.

### GHD

```{r DIST, include=FALSE}
#Loading Libraries.==============================
library(ghyp)
library(fBasics)

#Preparing Dataset.==============================
subID.DIST <- c("CN_10yry", "US_10yry", "USDCNH", "USDX", "EURUSD", "GBPUSD")
DIST.Dataset.trend <- na.interpolation(TD_All.ts[, c(paste0(subID.DIST, "_hpft"))])
DIST.Dataset.cycle <- na.interpolation(TD_All.ts[, c(paste0(subID.DIST, "_hpfc"))])

#Fitting Target Cycle to distribution function.
#CN_10yry Cycle
DIST.ycycle <- DIST.Dataset.cycle[, c("CN_10yry_hpfc")]
DIST.ef <- density(DIST.ycycle)
#Density
DIST.ghdfit <- fit.ghypuv(DIST.ycycle, symmetric = FALSE, control = list(maxit = 1000))
DIST.ghddense <- dghyp(DIST.ef$x, DIST.ghdfit)
DIST.col.def <- c("black", "red")
#VaR and ES
DIST.yield.p <- seq(0.001, 0.05, 0.001)
DIST.yield.emp.VaR <- abs(quantile(x = DIST.ycycle, probs = DIST.yield.p))
DIST.yield.VaR <- abs(qghyp(DIST.yield.p, DIST.ghdfit))
DIST.yield.ES <- abs(ESghyp(DIST.yield.p, DIST.ghdfit))
DIST.yield.obs.p <- ceiling(DIST.yield.p * length(DIST.ycycle))
DIST.yield.emp.ES <- sapply(DIST.yield.obs.p, function(x) abs(mean(sort(c(DIST.ycycle))[1:x])))

#USDCNH Cycle
DIST.ycycle.USDCNH <- DIST.Dataset.cycle[, c("USDCNH_hpfc")]
DIST.ef.USDCNH <- density(DIST.ycycle.USDCNH)
#Density
DIST.ghdfit.USDCNH <- fit.ghypuv(DIST.ycycle.USDCNH, symmetric = FALSE, control = list(maxit = 1000))
DIST.ghddense.USDCNH <- dghyp(DIST.ef.USDCNH$x, DIST.ghdfit.USDCNH)
#VaR and ES
DIST.USDCNH.p <- seq(0.001, 0.05, 0.001)
DIST.USDCNH.emp.VaR <- abs(quantile(x = DIST.ycycle.USDCNH, probs = DIST.USDCNH.p))
DIST.USDCNH.VaR <- abs(qghyp(DIST.USDCNH.p, DIST.ghdfit.USDCNH))
DIST.USDCNH.ES <- abs(ESghyp(DIST.USDCNH.p, DIST.ghdfit.USDCNH))
DIST.USDCNH.obs.p <- ceiling(DIST.USDCNH.p * length(DIST.ycycle.USDCNH))
DIST.USDCNH.emp.ES <- sapply(DIST.USDCNH.obs.p, function(x) abs(mean(sort(c(DIST.ycycle.USDCNH))[1:x])))

#EURUSD Cycle
DIST.ycycle.EURUSD <- DIST.Dataset.cycle[, c("EURUSD_hpfc")]
DIST.ef.EURUSD <- density(DIST.ycycle.EURUSD)
#Density
DIST.ghdfit.EURUSD <- fit.ghypuv(DIST.ycycle.EURUSD, symmetric = FALSE, control = list(maxit = 1000))
DIST.ghddense.EURUSD <- dghyp(DIST.ef.EURUSD$x, DIST.ghdfit.EURUSD)
#VaR and ES
DIST.EURUSD.p <- seq(0.001, 0.05, 0.001)
DIST.EURUSD.emp.VaR <- abs(quantile(x = DIST.ycycle.EURUSD, probs = DIST.EURUSD.p))
DIST.EURUSD.VaR <- abs(qghyp(DIST.EURUSD.p, DIST.ghdfit.EURUSD))
DIST.EURUSD.ES <- abs(ESghyp(DIST.EURUSD.p, DIST.ghdfit.EURUSD))
DIST.EURUSD.obs.p <- ceiling(DIST.EURUSD.p * length(DIST.ycycle.EURUSD))
DIST.EURUSD.emp.ES <- sapply(DIST.EURUSD.obs.p, function(x) abs(mean(sort(c(DIST.ycycle.EURUSD))[1:x])))

#GBPUSD Cycle
DIST.ycycle.GBPUSD <- DIST.Dataset.cycle[, c("GBPUSD_hpfc")]
DIST.ef.GBPUSD <- density(DIST.ycycle.GBPUSD)
#Density
DIST.ghdfit.GBPUSD <- fit.ghypuv(DIST.ycycle.GBPUSD, symmetric = FALSE, control = list(maxit = 1000))
DIST.ghddense.GBPUSD <- dghyp(DIST.ef.GBPUSD$x, DIST.ghdfit.GBPUSD)
#VaR and ES
DIST.GBPUSD.p <- seq(0.001, 0.05, 0.001)
DIST.GBPUSD.emp.VaR <- abs(quantile(x = DIST.ycycle.GBPUSD, probs = DIST.GBPUSD.p))
DIST.GBPUSD.VaR <- abs(qghyp(DIST.GBPUSD.p, DIST.ghdfit.GBPUSD))
DIST.GBPUSD.ES <- abs(ESghyp(DIST.GBPUSD.p, DIST.ghdfit.GBPUSD))
DIST.GBPUSD.obs.p <- ceiling(DIST.GBPUSD.p * length(DIST.ycycle.GBPUSD))
DIST.GBPUSD.emp.ES <- sapply(DIST.GBPUSD.obs.p, function(x) abs(mean(sort(c(DIST.ycycle.GBPUSD))[1:x])))

#CN_10yry Cycle
DIST.ycycle.yield2 <- DIST.Dataset.cycle[, c("US_10yry_hpfc")]
DIST.ef.yield2 <- density(DIST.ycycle.yield2)
#Density
DIST.ghdfit.yield2 <- fit.ghypuv(DIST.ycycle.yield2, symmetric = FALSE, control = list(maxit = 1000))
DIST.ghddense.yield2 <- dghyp(DIST.ef.yield2$x, DIST.ghdfit.yield2)
DIST.col.def.yield2 <- c("black", "red")
#VaR and ES
DIST.yield2.p <- seq(0.001, 0.05, 0.001)
DIST.yield2.emp.VaR <- abs(quantile(x = DIST.ycycle.yield2, probs = DIST.yield2.p))
DIST.yield2.VaR <- abs(qghyp(DIST.yield2.p, DIST.ghdfit.yield2))
DIST.yield2.ES <- abs(ESghyp(DIST.yield2.p, DIST.ghdfit.yield2))
DIST.yield2.obs.p <- ceiling(DIST.yield2.p * length(DIST.ycycle.yield2))
DIST.yield2.emp.ES <- sapply(DIST.yield2.obs.p, function(x) abs(mean(sort(c(DIST.ycycle.yield2))[1:x])))

```

```{r DIST OUTPUT of yields, fig.height=6, fig.width=14}

par(mfcol = c(1, 3))

#Ploting Density map.
#CN_10yry Cycle
plot(DIST.ef, xlab = "CN_10yry_hpfc", ylab = expression(f(x)), ylim = c(0, max(DIST.ef$y)*1.2),
     main = "Distribution of CN_10yry_hpfc")
lines(DIST.ef$x, DIST.ghddense, col = "red")
legend("topleft", legend = c("empirical", "GHD"),
       col = DIST.col.def, lty = 1)

#VaR
plot(DIST.yield.emp.VaR, type = "l", xlab = "", ylab = "VaR", axes = FALSE, 
     ylim = range(c(DIST.yield.emp.VaR)), main = "Value at Risk of CN_10yry_hpfc")
box()
axis(1, at = seq(along = DIST.yield.p), labels = names(DIST.yield.emp.VaR), tick = FALSE)
axis(2, at = pretty(range(DIST.yield.emp.VaR)))
lines(seq(along = DIST.yield.p), DIST.yield.VaR, col = "red")
legend("topleft", legend = c("Empirical", "GHD"), col = DIST.col.def, lty = 1)

#ES
plot(DIST.yield.emp.ES, type = "l", xlab = "", ylab = "ES", axes = FALSE, ylim = range(c(DIST.yield.emp.ES)), main = "Expected Shortfall of CN_10yry_hpfc")
box()
axis(1, at = 1:length(DIST.yield.p), labels = names(DIST.yield.emp.VaR), tick = FALSE)
axis(2, at = pretty(range(DIST.yield.emp.ES)))
lines(1:length(DIST.yield.p), DIST.yield.ES, col = "red")
legend("topleft", legend = c("Empirical", "GHD"), col = DIST.col.def, lty = 1)

#CURRENCY Cycle
plot(DIST.ef.USDCNH, xlab = "USDCNH_hpfc", ylab = expression(f(x)), ylim = c(0, max(DIST.ef.USDCNH$y)*1.2),
     main = "Distribution of USDCNH_hpfc")
lines(DIST.ef.USDCNH$x, DIST.ghddense.USDCNH, col = "red")
legend("topleft", legend = c("empirical", "GHD"),
       col = DIST.col.def, lty = 1)

#VaR
plot(DIST.USDCNH.emp.VaR, type = "l", xlab = "", ylab = "VaR", axes = FALSE, 
     ylim = range(c(DIST.USDCNH.emp.VaR)), main = "Value at Risk of USDCNH_hpfc")
box()
axis(1, at = seq(along = DIST.USDCNH.p), labels = names(DIST.USDCNH.emp.VaR), tick = FALSE)
axis(2, at = pretty(range(DIST.USDCNH.emp.VaR)))
lines(seq(along = DIST.USDCNH.p), DIST.USDCNH.VaR, col = "red")
legend("topleft", legend = c("Empirical", "GHD"), col = DIST.col.def, lty = 1)

#ES
plot(DIST.USDCNH.emp.ES, type = "l", xlab = "", ylab = "ES", axes = FALSE, ylim = range(c(DIST.USDCNH.emp.ES)), main = "Expected Shortfall of USDCNH_hpfc")
box()
axis(1, at = 1:length(DIST.USDCNH.p), labels = names(DIST.USDCNH.emp.VaR), tick = FALSE)
axis(2, at = pretty(range(DIST.USDCNH.emp.ES)))
lines(1:length(DIST.USDCNH.p), DIST.USDCNH.ES, col = "red")
legend("topleft", legend = c("Empirical", "GHD"), col = DIST.col.def, lty = 1)

#EURUSD Cycle
plot(DIST.ef.EURUSD, xlab = "EURUSD_hpfc", ylab = expression(f(x)), 
     ylim = c(0, max(DIST.ef.EURUSD$y)*1.2),
     main = "Distribution of EURUSD_hpfc")
lines(DIST.ef.EURUSD$x, DIST.ghddense.EURUSD, col = "red")
legend("topleft", legend = c("empirical", "GHD"),
       col = DIST.col.def, lty = 1)

#VaR
plot(DIST.EURUSD.emp.VaR, type = "l", xlab = "", ylab = "VaR", axes = FALSE, 
     ylim = range(c(DIST.EURUSD.emp.VaR)), main = "Value at Risk of EURUSD_hpfc")
box()
axis(1, at = seq(along = DIST.EURUSD.p), labels = names(DIST.EURUSD.emp.VaR), tick = FALSE)
axis(2, at = pretty(range(DIST.EURUSD.emp.VaR)))
lines(seq(along = DIST.EURUSD.p), DIST.EURUSD.VaR, col = "red")
legend("topleft", legend = c("Empirical", "GHD"), col = DIST.col.def, lty = 1)

#ES
plot(DIST.EURUSD.emp.ES, type = "l", xlab = "", ylab = "ES", axes = FALSE, ylim = range(c(DIST.EURUSD.emp.ES)), main = "Expected Shortfall of EURUSD_hpfc")
box()
axis(1, at = 1:length(DIST.EURUSD.p), labels = names(DIST.EURUSD.emp.VaR), tick = FALSE)
axis(2, at = pretty(range(DIST.EURUSD.emp.ES)))
lines(1:length(DIST.EURUSD.p), DIST.EURUSD.ES, col = "red")
legend("topleft", legend = c("Empirical", "GHD"), col = DIST.col.def, lty = 1)

#GBPUSD Cycle
plot(DIST.ef.GBPUSD, xlab = "GBPUSD_hpfc", ylab = expression(f(x)), 
     ylim = c(0, max(DIST.ef.GBPUSD$y)*1.2),
     main = "Distribution of GBPUSD_hpfc")
lines(DIST.ef.GBPUSD$x, DIST.ghddense.GBPUSD, col = "red")
legend("topleft", legend = c("empirical", "GHD"),
       col = DIST.col.def, lty = 1)

#VaR
plot(DIST.GBPUSD.emp.VaR, type = "l", xlab = "", ylab = "VaR", axes = FALSE, 
     ylim = range(c(DIST.GBPUSD.emp.VaR)), main = "Value at Risk of GBPUSD_hpfc")
box()
axis(1, at = seq(along = DIST.GBPUSD.p), labels = names(DIST.GBPUSD.emp.VaR), tick = FALSE)
axis(2, at = pretty(range(DIST.GBPUSD.emp.VaR)))
lines(seq(along = DIST.GBPUSD.p), DIST.GBPUSD.VaR, col = "red")
legend("topleft", legend = c("Empirical", "GHD"), col = DIST.col.def, lty = 1)

#ES
plot(DIST.GBPUSD.emp.ES, type = "l", xlab = "", ylab = "ES", axes = FALSE, ylim = range(c(DIST.GBPUSD.emp.ES)), main = "Expected Shortfall of GBPUSD_hpfc")
box()
axis(1, at = 1:length(DIST.GBPUSD.p), labels = names(DIST.GBPUSD.emp.VaR), tick = FALSE)
axis(2, at = pretty(range(DIST.GBPUSD.emp.ES)))
lines(1:length(DIST.GBPUSD.p), DIST.GBPUSD.ES, col = "red")
legend("topleft", legend = c("Empirical", "GHD"), col = DIST.col.def, lty = 1)

#Ploting Density map.
#US_10yry Cycle
plot(DIST.ef, xlab = "US_10yry_hpfc", ylab = expression(f(x)), ylim = c(0, max(DIST.ef.yield2$y)*1.2),
     main = "Distribution of US_10yry_hpfc")
lines(DIST.ef.yield2$x, DIST.ghddense.yield2, col = "red")
legend("topleft", legend = c("empirical", "GHD"),
       col = DIST.col.def.yield2, lty = 1)

#VaR
plot(DIST.yield2.emp.VaR, type = "l", xlab = "", ylab = "VaR", axes = FALSE, 
     ylim = range(c(DIST.yield2.emp.VaR)), main = "Value at Risk of US_10yry_hpfc")
box()
axis(1, at = seq(along = DIST.yield2.p), labels = names(DIST.yield2.emp.VaR), tick = FALSE)
axis(2, at = pretty(range(DIST.yield2.emp.VaR)))
lines(seq(along = DIST.yield2.p), DIST.yield2.VaR, col = "red")
legend("topleft", legend = c("Empirical", "GHD"), col = DIST.col.def.yield2, lty = 1)

#ES
plot(DIST.yield2.emp.ES, type = "l", xlab = "", ylab = "ES", axes = FALSE, ylim = range(c(DIST.yield2.emp.ES)), main = "Expected Shortfall of US_10yry_hpfc")
box()
axis(1, at = 1:length(DIST.yield2.p), labels = names(DIST.yield2.emp.VaR), tick = FALSE)
axis(2, at = pretty(range(DIST.yield2.emp.ES)))
lines(1:length(DIST.yield2.p), DIST.yield2.ES, col = "red")
legend("topleft", legend = c("Empirical", "GHD"), col = DIST.col.def.yield2, lty = 1)

par(mfcol = c(1,1))

```

### POT

```{r POT of yield, fig.height=7, fig.width=16, paged.print=TRUE}
##Loading Packages.------------------------------
library(fBasics)
library(fExtremes)

##Data Preparation.------------------------------
POT.yield <- DIST.ycycle
POT.USDCNH <- DIST.ycycle.USDCNH
POT.EURUSD <- DIST.ycycle.EURUSD
POT.GBPUSD <- DIST.ycycle.GBPUSD
POT.yield2 <- DIST.ycycle.yield2
##GPD
POT.yield.gpdfit <- gpdFit(POT.yield, u = 0.12)
POT.USDCNH.gpdfit <- gpdFit(POT.USDCNH, u = 0.115)
POT.EURUSD.gpdfit <- gpdFit(POT.EURUSD, u = 0.024)
POT.GBPUSD.gpdfit <- gpdFit(POT.GBPUSD, u = 0.03)
POT.yield2.gpdfit <- gpdFit(POT.yield2, u = 0.12)
##Risk Measure
POT.yield.VaRES <- round(gpdRiskMeasures(POT.yield.gpdfit, prob = c(0.95, 0.99, 0.995)), digits = 4)
POT.USDCNH.VaRES <- round(gpdRiskMeasures(POT.USDCNH.gpdfit, prob = c(0.95, 0.99, 0.995)), digits = 4)
POT.EURUSD.VaRES <- round(gpdRiskMeasures(POT.EURUSD.gpdfit, prob = c(0.95, 0.99, 0.995)), digits = 4)
POT.GBPUSD.VaRES <- round(gpdRiskMeasures(POT.GBPUSD.gpdfit, prob = c(0.95, 0.99, 0.995)), digits = 4)
POT.yield2.VaRES <- round(gpdRiskMeasures(POT.yield2.gpdfit, prob = c(0.95, 0.99, 0.995)), digits = 4)
##Output
POT.yield.VaRES.gg <- ggtexttable(POT.yield.VaRES, 
                                  cols = c("Prob", "VaR", "ES"),
                                  theme = ttheme(colnames.style = colnames_style(color = "pink", 
                                                                                 fill = "yellow",
                                                                                 size = 20),
                                                 tbody.style = tbody_style(size = 20))
                                 )
POT.USDCNH.VaRES.gg <- ggtexttable(POT.USDCNH.VaRES, 
                                   cols = c("Prob", "VaR", "ES"),
                                   theme = ttheme(colnames.style = colnames_style(color = "pink", 
                                                                                  fill = "yellow",
                                                                                  size = 20),
                                                  tbody.style = tbody_style(size = 20))
                                  )
POT.EURUSD.VaRES.gg <- ggtexttable(POT.EURUSD.VaRES, 
                                   cols = c("Prob", "VaR", "ES"),
                                   theme = ttheme(colnames.style = colnames_style(color = "pink", 
                                                                                  fill = "yellow",
                                                                                  size = 20),
                                                  tbody.style = tbody_style(size = 20))
                                  )
POT.GBPUSD.VaRES.gg <- ggtexttable(POT.GBPUSD.VaRES, 
                                   cols = c("Prob", "VaR", "ES"),
                                   theme = ttheme(colnames.style = colnames_style(color = "pink", 
                                                                                  fill = "yellow",
                                                                                  size = 20),
                                                  tbody.style = tbody_style(size = 20))
                                  )
POT.yield2.VaRES.gg <- ggtexttable(POT.yield2.VaRES, 
                                  cols = c("Prob", "VaR", "ES"),
                                  theme = ttheme(colnames.style = colnames_style(color = "pink", 
                                                                                 fill = "yellow",
                                                                                 size = 20),
                                                 tbody.style = tbody_style(size = 20))
                                 )
POT.VaRES.gg.output <- ggarrange(POT.yield.VaRES.gg, 
                                 POT.USDCNH.VaRES.gg,
                                 POT.EURUSD.VaRES.gg,
                                 POT.GBPUSD.VaRES.gg,
                                 POT.yield2.VaRES.gg,
                                 ncol = 2, nrow = 3)
annotate_figure(POT.VaRES.gg.output, top = text_grob(
  "VaR and ES under GPD of \t
  CN_10yry_hpfc,  USDCNH_hpfc, 
  EURUSD_hpfc ,  GBPUSD_hpfc AND US_10yry_hpfc.\t",
  size = 18, vjust = 1)
  )

```

FIN_T...
==================================================

TRENDS {.tabset .tabset-fade}
-------------------------------------

TARGET TRENDS

```{r Prepare Trade Data Bayesian DCC Garch Data}
AssFun$Garch_plot2 <- function(Output_dataset, #Output of a Garch Model in timeSeries class
                              nameref = NULL, #Strings or colnames of the dataset.
                              Major_id = 1){ #For Ploting Major curve
  par(mai=c(0.5,0.5,0.5,0.5))
  par(mfcol = c(1,1))
  #Ploting
  #Then plot layer shows all curves.
  for (ig2 in 1: dim(Output_dataset)[2]){
    if(ig2 == 1){
      par(new = F)
      timeSeries::plot(Output_dataset[, ig2], plot.type = c("single"), ann = FALSE, col = ig2)
      grid()
    }else{
      par(new = T)
      timeSeries::plot(Output_dataset[, ig2], plot.type = c("single"), 
                       ann = FALSE, col = ig2, yaxt = "n", xaxt = "n")
    }
  }
  mtext(paste0(nameref[Major_id], " to All Volatilities."), side = 3, cex = 1)
  legend("topleft", nameref, lty = 1, col= seq.int(1, length(nameref)))
}  
```

### A50 PRIMES

```{r Reengineer the Trends for TARGET 1}
#Abtain reengineered dataset. 
subID.Target1 <- c("IH00C1", 
                   "T00C1", "CN_10yry", "US_10yry", "UK_10yry", 
                   "USDX", "USDCNH"
                  ) 
emphasis.lwd.Target1 <- c(rep(3, 1), rep(4, 4), rep(3, 2))
emphasis.lty.Target1 <- c(rep(1, 1), rep(4, 4), rep(3, 2))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.Target1 <- TD_All.ts[, paste0(subID.Target1, "_hpft")]
Cycles.Reengineered.Target1 <- TD_All.ts[, paste0(subID.Target1, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.Target1, "DEEPLEARN/Trends_Reengineered_Trend1.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.Target1, "DEEPLEARN/Cycles_Reengineered_Trend1.csv", col.names = TRUE)
```

```{r Reengineered Atempted Output for TARGET 1}
#Functions to plot the reengineered data.
#Function 1 to use plot()
AssFun$Reengineered_Dataset_Plot <- function(Reengineered_DS = timeSeries(NULL),
                                             emphasis.lwd = NULL,
                                             emphasis.lty = NULL){#Parameter for emphasis in plot.
  #Checking emphasis parameter.
  if(is.null(emphasis.lwd)){
    emphasis.lwd <- c(3, rep(1, dim(Reengineered_DS)[2]-1))
  }
  if(is.null(emphasis.lty)){
    emphasis.lty <- c(1, rep(3, dim(Reengineered_DS)[2]-1))
  }
  par(mai=c(0.5,0.5,0.5,0.5))
  par(mfcol=c(1,1))
  for(ig in 1:(dim(Reengineered_DS)[2]-1)){
    if(ig == 1){
      par(new = F)
      timeSeries::plot(Reengineered_DS[, ig], plot.type = c("single"), 
                       ann = FALSE, col = 1, lwd = emphasis.lwd[ig], lty = emphasis.lty[ig])
      grid()
      par(new = T)
      timeSeries::plot(Reengineered_DS[, ig+1], plot.type = c("single"), 
                       ann = FALSE, col = ig+1, yaxt = "n", xaxt = "n", 
                       axes = FALSE, lwd = emphasis.lwd[ig + 1], lty = emphasis.lty[ig + 1])
    }else{
      par(new = T)
      timeSeries::plot(Reengineered_DS[, ig+1], plot.type = c("single"), 
                       ann = FALSE, col = ig+1, yaxt = "n", xaxt = "n", 
                       axes = FALSE, lwd = emphasis.lwd[ig + 1], lty = emphasis.lty[ig + 1])
    }
  }
  mtext(paste0("FIGUER 1. ", colnames(Reengineered_DS)[1], " to ", 
               toString(colnames(Reengineered_DS)[-1]), "."), 
        side =3, ces = 1)
  legend("topleft", c(colnames(Reengineered_DS)), lty =1, 
         col = seq.int(1, dim(Reengineered_DS)[2]),
         lwd = emphasis.lwd)
}

##Standardize JM and J specific month contracts.
#Trends.Reengineered.Target1@.Data[1, "JM1905_hpft"] <- 
#  min(Trends.Reengineered.Target1@.Data[, "JM0_hpft"], na.rm = TRUE)
#Trends.Reengineered.Target1@.Data[2, "JM1905_hpft"] <- 
#  max(Trends.Reengineered.Target1@.Data[, "JM0_hpft"], na.rm = TRUE)

#Trends.Reengineered.Target1@.Data[1, "J1905_hpft"] <- 
#  min(Trends.Reengineered.Target1@.Data[, "J0_hpft"], na.rm = TRUE)
#Trends.Reengineered.Target1@.Data[2, "J1905_hpft"] <- 
#  max(Trends.Reengineered.Target1@.Data[, "J0_hpft"], na.rm = TRUE)

##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.Target1, 
                                 emphasis.lwd.Target1, emphasis.lty.Target1)
```

### CSI300 PRIMES

```{r Reengineer the Trends for TARGET 2}
#Abtain reengineered dataset. 
subID.Target2 <- c("IF00C1", "SPX",
                  "CN_10yry", "US_10yry", "UK_10yry",
                  "T00C1", "USDX", "USDCNH"
                  ) 
emphasis.lwd.Target2 <- c(rep(3, 2), rep(4, 3), rep(3, 3))
emphasis.lty.Target2 <- c(rep(1, 2), rep(4, 3), rep(3, 3))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.Target2 <- TD_All.ts[, paste0(subID.Target2, "_hpft")]
Cycles.Reengineered.Target2 <- TD_All.ts[, paste0(subID.Target2, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.Target2, "DEEPLEARN/Trends_Reengineered_Trend2.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.Target2, "DEEPLEARN/Cycles_Reengineered_Trend2.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.Target2, 
                                 emphasis.lwd.Target2, emphasis.lty.Target2)
```

### 10yr TREASURY PRIME

```{r Reengineer the Trends for TREASURY}
#Abtain reengineered dataset. 
subID.Treasury <- c("T00C1", "CN_10yry", "USDCNH", "CN_5yry", "CN_2yry", "IH00C1", "IF00C1", "SPX") 
emphasis.lwd.Treasury <- c(rep(3, 1), rep(3, length(subID.Treasury) - 1))
emphasis.lty.Treasury <- c(1, 5, rep(4, length(subID.Treasury) - 2))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.Treasury <- TD_All.ts[, paste0(subID.Treasury, "_hpft")]
Cycles.Reengineered.Treasury <- TD_All.ts[, paste0(subID.Treasury, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.Treasury, "DEEPLEARN/Trends_Reengineered_Treasury.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.Treasury, "DEEPLEARN/Cycles_Reengineered_Treasury.csv", col.names = TRUE)
#Plot the reengineered data.
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.Treasury, 
                                 emphasis.lwd.Treasury, emphasis.lty.Treasury)
```

### SPX PRIME

```{r}
#Abtain reengineered dataset. 
subID.Stocks <- c("SPX", "IH00C1",
                  "US_10yry", "CN_10yry", "UK_10yry",
                  "T00C1", "USDX", "USDCNH"
                  ) 
emphasis.lwd.Stocks <- c(rep(3, 2), rep(4, 3), rep(3, 3))
emphasis.lty.Stocks <- c(rep(1, 2), rep(4, 3), rep(3, 3))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.Stocks <- TD_All.ts[, paste0(subID.Stocks, "_hpft")]
Cycles.Reengineered.Stocks <- TD_All.ts[, paste0(subID.Stocks, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.Stocks, "DEEPLEARN/Trends_Reengineered_Stocks.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.Stocks, "DEEPLEARN/Cycles_Reengineered_Stocks.csv", col.names = TRUE)
#Plot the reengineered data.
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.Stocks, 
                                 emphasis.lwd.Stocks, emphasis.lty.Stocks)
```

### A50_to_Yields

```{r}
#Abtain reengineered dataset. 
subID.A50toYield <- c("IH00C1", 
                      "CN_10yry", "US_10yry",
                      "UK_10yry", "GR_10yry", "IT_10yry", "AU_10yry", "INA_10yry", "IND_10yry"
                     ) 
emphasis.lwd.A50toYield <- c(rep(3, 1), rep(4, 2), rep(3, 6))
emphasis.lty.A50toYield <- c(rep(1, 1), rep(4, 2), rep(3, 6))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.A50toYield <- TD_All.ts[, paste0(subID.A50toYield, "_hpft")]
Cycles.Reengineered.A50toYield <- TD_All.ts[, paste0(subID.A50toYield, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.A50toYield, "DEEPLEARN/Trends_Reengineered_A50toYield.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.A50toYield, "DEEPLEARN/Cycles_Reengineered_A50toYield.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.A50toYield, 
                                 emphasis.lwd.A50toYield, emphasis.lty.A50toYield)
```

### A50_to_TRs

```{r}
#Abtain reengineered dataset. 
subID.A50toTRs <- c("IH00C1", 
                    "T00C1",
                    "TF00C1",
                    "TY00Y"
                   ) 
emphasis.lwd.A50toTRs <- c(rep(3, 1), rep(4, 2), rep(3, 1))
emphasis.lty.A50toTRs <- c(rep(1, 1), rep(4, 2), rep(3, 1))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.A50toTRs <- TD_All.ts[, paste0(subID.A50toTRs, "_hpft")]
Cycles.Reengineered.A50toTRs <- TD_All.ts[, paste0(subID.A50toTRs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.A50toTRs, "DEEPLEARN/Trends_Reengineered_A50toTRs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.A50toTRs, "DEEPLEARN/Cycles_Reengineered_A50toTRs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.A50toTRs, 
                                 emphasis.lwd.A50toTRs, emphasis.lty.A50toTRs)
```

### A50_to_CURs

```{r}
#Abtain reengineered dataset. 
subID.A50toCURs <- c("IH00C1", 
                     "USDCNH", "USDX",
                     CUR.ind
                    ) 
emphasis.lwd.A50toCURs <- c(rep(3, 1), rep(4, 2), rep(3, 4))
emphasis.lty.A50toCURs <- c(rep(1, 1), rep(4, 2), rep(3, 4))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.A50toCURs <- TD_All.ts[, paste0(subID.A50toCURs, "_hpft")]
Cycles.Reengineered.A50toCURs <- TD_All.ts[, paste0(subID.A50toCURs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.A50toCURs, "DEEPLEARN/Trends_Reengineered_A50toCURs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.A50toCURs, "DEEPLEARN/Cycles_Reengineered_A50toCURs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.A50toCURs, 
                                 emphasis.lwd.A50toCURs, emphasis.lty.A50toCURs)
```


### A50_to_CMDs

```{r}
#Abtain reengineered dataset. 
subID.A50toCMDs <- c("IH00C1", 
                    "AU0", "RB0", "SCM",
                    CMD.ind
                   ) 
emphasis.lwd.A50toCMDs <- c(rep(3, 1), rep(4, 3), rep(3, length(CMD.ind)))
emphasis.lty.A50toCMDs <- c(rep(1, 1), rep(4, 3), rep(3, length(CMD.ind)))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.A50toCMDs <- TD_All.ts[, paste0(subID.A50toCMDs, "_hpft")]
Cycles.Reengineered.A50toCMDs <- TD_All.ts[, paste0(subID.A50toCMDs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.A50toCMDs, "DEEPLEARN/Trends_Reengineered_A50toCMDs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.A50toCMDs, "DEEPLEARN/Cycles_Reengineered_A50toCMDs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.A50toCMDs, 
                                 emphasis.lwd.A50toCMDs, emphasis.lty.A50toCMDs)
```

### A50_to_EQTs

```{r}
#Abtain reengineered dataset. 
subID.A50toEQTs <- c("IH00C1", 
                    "SPX", "FTSE"
                   ) 
emphasis.lwd.A50toEQTs <- c(rep(3, 1), rep(4, 1), rep(3, 1))
emphasis.lty.A50toEQTs <- c(rep(1, 1), rep(4, 1), rep(3, 1))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.A50toEQTs <- TD_All.ts[, paste0(subID.A50toEQTs, "_hpft")]
Cycles.Reengineered.A50toEQTs <- TD_All.ts[, paste0(subID.A50toEQTs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.A50toEQTs, "DEEPLEARN/Trends_Reengineered_A50toEQTs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.A50toEQTs, "DEEPLEARN/Cycles_Reengineered_A50toEQTs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.A50toEQTs, 
                                 emphasis.lwd.A50toEQTs, emphasis.lty.A50toEQTs)
```

### TR_to_Yields

```{r}
#Abtain reengineered dataset. 
subID.TRtoYield <- c("T00C1", 
                      "CN_10yry", "US_10yry",
                      "UK_10yry", "GR_10yry", "IT_10yry", "AU_10yry", "INA_10yry", "IND_10yry"
                     ) 
emphasis.lwd.TRtoYield <- c(rep(3, 1), rep(4, 2), rep(3, 6))
emphasis.lty.TRtoYield <- c(rep(1, 1), rep(4, 2), rep(3, 6))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.TRtoYield <- TD_All.ts[, paste0(subID.TRtoYield, "_hpft")]
Cycles.Reengineered.TRtoYield <- TD_All.ts[, paste0(subID.TRtoYield, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.TRtoYield, "DEEPLEARN/Trends_Reengineered_TRtoYield.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.TRtoYield, "DEEPLEARN/Cycles_Reengineered_TRtoYield.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.TRtoYield, 
                                 emphasis.lwd.TRtoYield, emphasis.lty.TRtoYield)
```

### TR_to_CURs

```{r}
#Abtain reengineered dataset. 
subID.TRtoCURs <- c("T00C1",  
                     "USDCNH", "USDX",
                     "EURUSD", "GBPUSD", "AUDUSD", "USDJPY"
                    ) 
emphasis.lwd.TRtoCURs <- c(rep(3, 1), rep(4, 2), rep(3, 4))
emphasis.lty.TRtoCURs <- c(rep(1, 1), rep(4, 2), rep(3, 4))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.TRtoCURs <- TD_All.ts[, paste0(subID.TRtoCURs, "_hpft")]
Cycles.Reengineered.TRtoCURs <- TD_All.ts[, paste0(subID.TRtoCURs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.TRtoCURs, "DEEPLEARN/Trends_Reengineered_TRtoCURs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.TRtoCURs, "DEEPLEARN/Cycles_Reengineered_TRtoCURs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.TRtoCURs, 
                                 emphasis.lwd.TRtoCURs, emphasis.lty.TRtoCURs)
```

### TR_to_CMDs

```{r}
#Abtain reengineered dataset. 
subID.TRtoCMDs <- c("T00C1",  
                    "AU0", "RB0", "SCM",
                    CMD.ind
                   ) 
emphasis.lwd.TRtoCMDs <- c(rep(3, 1), rep(4, 3), rep(3, length(CMD.ind)))
emphasis.lty.TRtoCMDs <- c(rep(1, 1), rep(4, 3), rep(3, length(CMD.ind)))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.TRtoCMDs <- TD_All.ts[, paste0(subID.TRtoCMDs, "_hpft")]
Cycles.Reengineered.TRtoCMDs <- TD_All.ts[, paste0(subID.TRtoCMDs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.TRtoCMDs, "DEEPLEARN/Trends_Reengineered_TRtoCMDs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.TRtoCMDs, "DEEPLEARN/Cycles_Reengineered_TRtoCMDs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.TRtoCMDs, 
                                 emphasis.lwd.TRtoCMDs, emphasis.lty.TRtoCMDs)
```

### TR_to_EQTs

```{r}
#Abtain reengineered dataset. 
subID.TRtoEQTs <- c("T00C1", 
                    "SPX", "FTSE", "IH00C1", "IF00C1"
                   ) 
emphasis.lwd.TRtoEQTs <- c(rep(3, 1), rep(4, 1), rep(3, 3))
emphasis.lty.TRtoEQTs <- c(rep(1, 1), rep(4, 1), rep(3, 3))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.TRtoEQTs <- TD_All.ts[, paste0(subID.TRtoEQTs, "_hpft")]
Cycles.Reengineered.TRtoEQTs <- TD_All.ts[, paste0(subID.TRtoEQTs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.TRtoEQTs, "DEEPLEARN/Trends_Reengineered_TRtoEQTs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.TRtoEQTs, "DEEPLEARN/Cycles_Reengineered_TRtoEQTs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.TRtoEQTs, 
                                 emphasis.lwd.TRtoEQTs, emphasis.lty.TRtoEQTs)
```


FIN_C...
==================================================

CYCLES {.tabset .tabset-fade data-height=6500}
-------------------------------------

CYCLES COMPARE VISUALIZING

```{r Preparing the Cycle Data}
#Windows the TD_All.ts into 2 years framework.
TD_All.ts.2 <- window(TD_All.ts,
                     end(TD_All.ts)-years(midtermYear1), end(TD_All.ts))

#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.Target1 <- TD_All.ts.2[, paste0(subID.Target1, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.Target1, "DEEPLEARN/Cycles_Visualizing_Cycle1.csv", col.names = TRUE)
```

### A50 PRIMES

```{r Cycles Visualizing for Target1}
##Function to visualize the cycle with amphasis of first 3.
AssFun$Cycles_Visualize_f3 <- function(Cycle_dataset, #Cycles
                              Major_id = 1){ #For Ploting Major curve
  #Setting ploting layout.
  par(mai=c(0.38,0.5,0.3,0.5))
  par(mfcol = c(2,1))
  #Ploting
    for(ig in 1:dim(Cycle_dataset)[2]){
      if(ig == dim(Cycle_dataset)[2]){
        par(new = F)
        timeSeries::plot(Cycle_dataset[, Major_id], plot.type = c("single"), ann = FALSE, 
                         col = Major_id)
        grid()
        par(new = T)
        timeSeries::plot(Cycle_dataset[, ig], plot.type = c("single"), 
                         ann = FALSE, col = ig, yaxt = "n", xaxt = "n")
        mtext(paste0("CYCLES VISUALIZING: ", 
                     Cycle_dataset@units[Major_id], " to ", 
                     Cycle_dataset@units[ig]), side = 3, cex = 1)
        legend("topleft", c(Cycle_dataset@units[Major_id], Cycle_dataset@units[ig]), 
               lty = 1, col= c(Major_id, ig))
        #Then plot layer shows all curves.
        for (ig2 in 1: dim(Cycle_dataset)[2]){
          if(ig2 == 1){
            par(new = F)
            timeSeries::plot(Cycle_dataset[, ig2], plot.type = c("single"), ann = FALSE, 
                             col = ig2, lwd = 2)
            grid()
          }else{
            par(new = T)
            timeSeries::plot(Cycle_dataset[, ig2], plot.type = c("single"), 
                             ann = FALSE, col = ig2, yaxt = "n", xaxt = "n")
          }
        }
        mtext(paste0("CYCLES VISUALIZING: ", Cycle_dataset@units[Major_id], 
                     " to All Cycles."), side = 3, cex = 1)
        legend("topleft", Cycle_dataset@units, lty = 1, col= seq.int(1, dim(Cycle_dataset)[2]))
      }else if(ig == 1){
        ##Plot the first 3 Colums together.
        par(new = F)
        timeSeries::plot(Cycle_dataset[, 1], plot.type = c("single"), ann = FALSE, col = 1, lwd = 2)
        grid()
        par(new = T)
        timeSeries::plot(Cycle_dataset[, 2], plot.type = c("single"), 
                         ann = FALSE, col = 2, yaxt = "n", xaxt = "n",
                         lwd = 1)
        par(new = T)
        timeSeries::plot(Cycle_dataset[, 3], plot.type = c("single"), 
                         ann = FALSE, col = 3, yaxt = "n", xaxt = "n",
                         lwd = 1)
        mtext(paste0("CYCLES VISUALIZING: ", 
                     Cycle_dataset@units[1], " to ", 
                     Cycle_dataset@units[2], " and ",
                     Cycle_dataset@units[3]), side = 3, cex = 1)
        legend("topleft", c(Cycle_dataset@units[1:3]), 
               lty = 1, col= c(1:3))
      }else{
        par(new = F)
        timeSeries::plot(Cycle_dataset[, Major_id], plot.type = c("single"), ann = FALSE, col = Major_id)
        grid()
        par(new = T)
        timeSeries::plot(Cycle_dataset[, ig], plot.type = c("single"), 
                         ann = FALSE, col = ig, yaxt = "n", xaxt = "n")
        mtext(paste0("CYCLES VISUALIZING: ", 
                     Cycle_dataset@units[Major_id], " to ", 
                     Cycle_dataset@units[ig]), side = 3, cex = 1)
        legend("topleft", c(Cycle_dataset@units[Major_id], Cycle_dataset@units[ig]), 
               lty = 1, col= c(Major_id, ig))
      }
    }
}

#Visualzing.=====================================
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.Target1, Major_id = 1)
```

### CSI300 PRIMES

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.Cycle2 <- TD_All.ts.2[, paste0(subID.Target2, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.Target2, "DEEPLEARN/Cycles_Visualizing_Target2.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.Cycle2, Major_id = 1)
```

### 10yr TREASURY PRIME

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.Treasury <- TD_All.ts.2[, paste0(subID.Treasury, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.Treasury, "DEEPLEARN/Cycles_Visualizing_Treasury.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.Treasury, Major_id = 1)
```

### SPX PRIME

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.Stocks <- TD_All.ts.2[, paste0(subID.Stocks, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.Stocks, "DEEPLEARN/Cycles_Visualizing_Stocks.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.Stocks, Major_id = 1)
```

### A50_to_Yields

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.A50toYield <- TD_All.ts.2[, paste0(subID.A50toYield, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.A50toYield, "DEEPLEARN/Cycles_Visualizing_A50toYield.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.A50toYield, Major_id = 1)
```

### A50_to_TRs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.A50toTRs <- TD_All.ts.2[, paste0(subID.A50toTRs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.A50toTRs, "DEEPLEARN/Cycles_Visualizing_A50toTRs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.A50toTRs, Major_id = 1)
```

### A50_to_CURs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.A50toCURs <- TD_All.ts.2[, paste0(subID.A50toCURs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.A50toCURs, "DEEPLEARN/Cycles_Visualizing_A50toCURs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.A50toCURs, Major_id = 1)
```


### A50_to_CMDs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.A50toCMDs <- TD_All.ts.2[, paste0(subID.A50toCMDs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.A50toCMDs, "DEEPLEARN/Cycles_Visualizing_A50toCMDs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.A50toCMDs, Major_id = 1)
```

### A50_to_EQTs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.A50toEQTs <- TD_All.ts.2[, paste0(subID.A50toEQTs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.A50toEQTs, "DEEPLEARN/Cycles_Visualizing_A50toEQTs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.A50toEQTs, Major_id = 1)
```

### TR_to_Yields

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.TRtoYield <- TD_All.ts.2[, paste0(subID.TRtoYield, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.TRtoYield, "DEEPLEARN/Cycles_Visualizing_TRtoYield.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.TRtoYield, Major_id = 1)
```

### TR_to_CURs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.TRtoCURs <- TD_All.ts.2[, paste0(subID.TRtoCURs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.TRtoCURs, "DEEPLEARN/Cycles_Visualizing_TRtoCURs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.TRtoCURs, Major_id = 1)
```

### TR_to_CMDs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.TRtoCMDs <- TD_All.ts.2[, paste0(subID.TRtoCMDs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.TRtoCMDs, "DEEPLEARN/Cycles_Visualizing_TRtoCMDs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.TRtoCMDs, Major_id = 1)
```

### TR_to_EQTs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.TRtoEQTs <- TD_All.ts.2[, paste0(subID.TRtoEQTs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.TRtoEQTs, "DEEPLEARN/Cycles_Visualizing_TRtoEQTs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.TRtoEQTs, Major_id = 1)
```


T1_T
==================================================

T1_TRENDS {.tabset .tabset-fade}
-------------------------------------

### T1_to_Yields

```{r}
#Abtain reengineered dataset. 
subID.T1toYield <- c(T1, 
                     "CN_10yry", "US_10yry",
                     "UK_10yry", "GR_10yry", "IT_10yry", "AU_10yry", "INA_10yry", "IND_10yry"
                     ) 
emphasis.lwd.T1toYield <- c(rep(3, length(T1)), rep(4, 2), rep(3, 6))
emphasis.lty.T1toYield <- c(rep(1, length(T1)), rep(4, 2), rep(3, 6))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T1toYield <- TD_All.ts[, paste0(subID.T1toYield, "_hpft")]
Cycles.Reengineered.T1toYield <- TD_All.ts[, paste0(subID.T1toYield, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T1toYield, "DEEPLEARN/Trends_Reengineered_T1toYield.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T1toYield, "DEEPLEARN/Cycles_Reengineered_T1toYield.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T1toYield, 
                                 emphasis.lwd.T1toYield, emphasis.lty.T1toYield)
```

### T1_to_TRs

```{r}
#Abtain reengineered dataset. 
subID.T1toTRs <- c(T1,
                   "T00C1", 
                   "TF00C1",
                   "TY00Y",
                   "FV00Y"
                   ) 
emphasis.lwd.T1toTRs <- c(rep(3, length(T1)), rep(4, 2), rep(3, 2))
emphasis.lty.T1toTRs <- c(rep(1, length(T1)), rep(4, 2), rep(3, 2))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T1toTRs <- TD_All.ts[, paste0(subID.T1toTRs, "_hpft")]
Cycles.Reengineered.T1toTRs <- TD_All.ts[, paste0(subID.T1toTRs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T1toTRs, "DEEPLEARN/Trends_Reengineered_T1toTRs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T1toTRs, "DEEPLEARN/Cycles_Reengineered_T1toTRs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T1toTRs, 
                                 emphasis.lwd.T1toTRs, emphasis.lty.T1toTRs)
```

### T1_to_CURs

```{r}
#Abtain reengineered dataset. 
subID.T1toCURs <- c(T1, 
                    "USDCNH", "USDX",
                    CUR.ind) 
emphasis.lwd.T1toCURs <- c(rep(3, length(T1)), rep(4, 2), rep(3, 4))
emphasis.lty.T1toCURs <- c(rep(1, length(T1)), rep(4, 2), rep(3, 4))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T1toCURs <- TD_All.ts[, paste0(subID.T1toCURs, "_hpft")]
Cycles.Reengineered.T1toCURs <- TD_All.ts[, paste0(subID.T1toCURs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T1toCURs, "DEEPLEARN/Trends_Reengineered_T1toCURs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T1toCURs, "DEEPLEARN/Cycles_Reengineered_T1toCURs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T1toCURs, 
                                 emphasis.lwd.T1toCURs, emphasis.lty.T1toCURs)
```

### T1_to_CMDs

```{r}
#Abtain reengineered dataset. 
subID.T1toCMDs <- c(T1, 
                    CMD.ind
                   ) 
emphasis.lwd.T1toCMDs <- c(rep(3, length(T1)), rep(4, 3), rep(3, length(CMD.ind)-3))
emphasis.lty.T1toCMDs <- c(rep(1, length(T1)), rep(4, 3), rep(3, length(CMD.ind)-3))
#Use subID throught T1ENDS and CYCLES
T1ends.Reengineered.T1toCMDs <- TD_All.ts[, paste0(subID.T1toCMDs, "_hpft")]
Cycles.Reengineered.T1toCMDs <- TD_All.ts[, paste0(subID.T1toCMDs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(T1ends.Reengineered.T1toCMDs, "DEEPLEARN/T1ends_Reengineered_T1toCMDs.csv", col.names = T1UE)
write.csv(Cycles.Reengineered.T1toCMDs, "DEEPLEARN/Cycles_Reengineered_T1toCMDs.csv", col.names = T1UE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(T1ends.Reengineered.T1toCMDs, 
                                 emphasis.lwd.T1toCMDs, emphasis.lty.T1toCMDs)
```

### T1_to_EQTs

```{r}
#Abtain reengineered dataset. 
subID.T1toEQTs <- c(T1,
                    "IH00C1", "IF00C1", 
                    "SPX", "FTSE"
                   ) 
emphasis.lwd.T1toEQTs <- c(rep(3, length(T1)), rep(4, 2), rep(3, 2))
emphasis.lty.T1toEQTs <- c(rep(1, length(T1)), rep(4, 2), rep(3, 2))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T1toEQTs <- TD_All.ts[, paste0(subID.T1toEQTs, "_hpft")]
Cycles.Reengineered.T1toEQTs <- TD_All.ts[, paste0(subID.T1toEQTs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T1toEQTs, "DEEPLEARN/Trends_Reengineered_T1toEQTs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T1toEQTs, "DEEPLEARN/Cycles_Reengineered_T1toEQTs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T1toEQTs, 
                                 emphasis.lwd.T1toEQTs, emphasis.lty.T1toEQTs)
```

T1_C
==================================================

T1_CYCLES {.tabset .tabset-fade data-height=6500}
-------------------------------------

### T1_to_Yields

```{r}
#subID is used all throught T1ENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T1toYield <- TD_All.ts.2[, paste0(subID.T1toYield, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T1toYield, "DEEPLEARN/Cycles_Visualizing_T1toYield.csv", col.names = T1UE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T1toYield, Major_id = 1)
```

### T1_to_TRs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T1toTRs <- TD_All.ts.2[, paste0(subID.T1toTRs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T1toTRs, "DEEPLEARN/Cycles_Visualizing_T1toTRs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T1toTRs, Major_id = 1)
```

### T1_to_CURs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T1toCURs <- TD_All.ts.2[, paste0(subID.T1toCURs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T1toCURs, "DEEPLEARN/Cycles_Visualizing_T1toCURs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T1toCURs, Major_id = 1)
```

### T1_to_CMDs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T1toCMDs <- TD_All.ts.2[, paste0(subID.T1toCMDs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T1toCMDs, "DEEPLEARN/Cycles_Visualizing_T1toCMDs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T1toCMDs, Major_id = 1)
```

### T1_to_EQTs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T1toEQTs <- TD_All.ts.2[, paste0(subID.T1toEQTs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T1toEQTs, "DEEPLEARN/Cycles_Visualizing_T1toEQTs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T1toEQTs, Major_id = 1)
```

T2_T
==================================================

T2_TRENDS {.tabset .tabset-fade}
-------------------------------------

### T2_to_Yields

```{r}
#Abtain reengineered dataset. 
subID.T2toYield <- c(T2, 
                     "CN_10yry", "US_10yry",
                     "UK_10yry", "GR_10yry", "IT_10yry", "AU_10yry", "INA_10yry", "IND_10yry"
                     ) 
emphasis.lwd.T2toYield <- c(rep(3, length(T2)), rep(4, 2), rep(3, 6))
emphasis.lty.T2toYield <- c(rep(1, length(T2)), rep(4, 2), rep(3, 6))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T2toYield <- TD_All.ts[, paste0(subID.T2toYield, "_hpft")]
Cycles.Reengineered.T2toYield <- TD_All.ts[, paste0(subID.T2toYield, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T2toYield, "DEEPLEARN/Trends_Reengineered_T2toYield.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T2toYield, "DEEPLEARN/Cycles_Reengineered_T2toYield.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T2toYield, 
                                 emphasis.lwd.T2toYield, emphasis.lty.T2toYield)
```

### T2_to_TRs

```{r}
#Abtain reengineered dataset. 
subID.T2toTRs <- c(T2,
                   "T00C1", 
                   "TF00C1",
                   "TY00Y",
                   "FV00Y"
                   ) 
emphasis.lwd.T2toTRs <- c(rep(3, length(T2)), rep(4, 2), rep(3, 2))
emphasis.lty.T2toTRs <- c(rep(1, length(T2)), rep(4, 2), rep(3, 2))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T2toTRs <- TD_All.ts[, paste0(subID.T2toTRs, "_hpft")]
Cycles.Reengineered.T2toTRs <- TD_All.ts[, paste0(subID.T2toTRs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T2toTRs, "DEEPLEARN/Trends_Reengineered_T2toTRs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T2toTRs, "DEEPLEARN/Cycles_Reengineered_T2toTRs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T2toTRs, 
                                 emphasis.lwd.T2toTRs, emphasis.lty.T2toTRs)
```

### T2_to_CURs

```{r}
#Abtain reengineered dataset. 
subID.T2toCURs <- c(T2, 
                    "USDCNH", "USDX",
                    CUR.ind) 
emphasis.lwd.T2toCURs <- c(rep(3, length(T2)), rep(4, 2), rep(3, 4))
emphasis.lty.T2toCURs <- c(rep(1, length(T2)), rep(4, 2), rep(3, 4))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T2toCURs <- TD_All.ts[, paste0(subID.T2toCURs, "_hpft")]
Cycles.Reengineered.T2toCURs <- TD_All.ts[, paste0(subID.T2toCURs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T2toCURs, "DEEPLEARN/Trends_Reengineered_T2toCURs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T2toCURs, "DEEPLEARN/Cycles_Reengineered_T2toCURs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T2toCURs, 
                                 emphasis.lwd.T2toCURs, emphasis.lty.T2toCURs)
```

### T2_to_CMDs

```{r}
#Abtain reengineered dataset. 
subID.T2toCMDs <- c(T2, 
                    CMD.ind
                   ) 
emphasis.lwd.T2toCMDs <- c(rep(3, length(T2)), rep(4, 3), rep(3, length(CMD.ind)-3))
emphasis.lty.T2toCMDs <- c(rep(1, length(T2)), rep(4, 3), rep(3, length(CMD.ind)-3))
#Use subID throught T2ENDS and CYCLES
T2ends.Reengineered.T2toCMDs <- TD_All.ts[, paste0(subID.T2toCMDs, "_hpft")]
Cycles.Reengineered.T2toCMDs <- TD_All.ts[, paste0(subID.T2toCMDs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(T2ends.Reengineered.T2toCMDs, "DEEPLEARN/T2ends_Reengineered_T2toCMDs.csv", col.names = T2UE)
write.csv(Cycles.Reengineered.T2toCMDs, "DEEPLEARN/Cycles_Reengineered_T2toCMDs.csv", col.names = T2UE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(T2ends.Reengineered.T2toCMDs, 
                                 emphasis.lwd.T2toCMDs, emphasis.lty.T2toCMDs)
```

### T2_to_EQTs

```{r}
#Abtain reengineered dataset. 
subID.T2toEQTs <- c(T2,
                    "IH00C1", "IF00C1", 
                    "SPX", "FTSE"
                   ) 
emphasis.lwd.T2toEQTs <- c(rep(3, length(T2)), rep(4, 2), rep(3, 2))
emphasis.lty.T2toEQTs <- c(rep(1, length(T2)), rep(4, 2), rep(3, 2))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T2toEQTs <- TD_All.ts[, paste0(subID.T2toEQTs, "_hpft")]
Cycles.Reengineered.T2toEQTs <- TD_All.ts[, paste0(subID.T2toEQTs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T2toEQTs, "DEEPLEARN/Trends_Reengineered_T2toEQTs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T2toEQTs, "DEEPLEARN/Cycles_Reengineered_T2toEQTs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T2toEQTs, 
                                 emphasis.lwd.T2toEQTs, emphasis.lty.T2toEQTs)
```

T2_C
==================================================

T2_CYCLES {.tabset .tabset-fade data-height=6500}
-------------------------------------

### T2_to_Yields

```{r}
#subID is used all throught T2ENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T2toYield <- TD_All.ts.2[, paste0(subID.T2toYield, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T2toYield, "DEEPLEARN/Cycles_Visualizing_T2toYield.csv", col.names = T2UE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T2toYield, Major_id = 1)
```

### T2_to_TRs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T2toTRs <- TD_All.ts.2[, paste0(subID.T2toTRs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T2toTRs, "DEEPLEARN/Cycles_Visualizing_T2toTRs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T2toTRs, Major_id = 1)
```

### T2_to_CURs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T2toCURs <- TD_All.ts.2[, paste0(subID.T2toCURs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T2toCURs, "DEEPLEARN/Cycles_Visualizing_T2toCURs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T2toCURs, Major_id = 1)
```

### T2_to_CMDs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T2toCMDs <- TD_All.ts.2[, paste0(subID.T2toCMDs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T2toCMDs, "DEEPLEARN/Cycles_Visualizing_T2toCMDs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T2toCMDs, Major_id = 1)
```

### T2_to_EQTs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T2toEQTs <- TD_All.ts.2[, paste0(subID.T2toEQTs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T2toEQTs, "DEEPLEARN/Cycles_Visualizing_T2toEQTs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T2toEQTs, Major_id = 1)
```

T3_T
==================================================

T3_TRENDS {.tabset .tabset-fade}
-------------------------------------

### T3_to_Yields

```{r}
#Abtain reengineered dataset. 
subID.T3toYield <- c(T3, 
                     "CN_10yry", "US_10yry",
                     "UK_10yry", "GR_10yry", "IT_10yry", "AU_10yry", "INA_10yry", "IND_10yry"
                     ) 
emphasis.lwd.T3toYield <- c(rep(3, length(T3)), rep(4, 2), rep(3, 6))
emphasis.lty.T3toYield <- c(rep(1, length(T3)), rep(4, 2), rep(3, 6))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T3toYield <- TD_All.ts[, paste0(subID.T3toYield, "_hpft")]
Cycles.Reengineered.T3toYield <- TD_All.ts[, paste0(subID.T3toYield, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T3toYield, "DEEPLEARN/Trends_Reengineered_T3toYield.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T3toYield, "DEEPLEARN/Cycles_Reengineered_T3toYield.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T3toYield, 
                                 emphasis.lwd.T3toYield, emphasis.lty.T3toYield)
```

### T3_to_TRs

```{r}
#Abtain reengineered dataset. 
subID.T3toTRs <- c(T3,
                   "T00C1",
                   "TF00C1",
                   "TY00Y",
                   "FV00Y"
                   ) 
emphasis.lwd.T3toTRs <- c(rep(3, length(T3)), rep(4, 2), rep(3, 2))
emphasis.lty.T3toTRs <- c(rep(1, length(T3)), rep(4, 2), rep(3, 2))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T3toTRs <- TD_All.ts[, paste0(subID.T3toTRs, "_hpft")]
Cycles.Reengineered.T3toTRs <- TD_All.ts[, paste0(subID.T3toTRs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T3toTRs, "DEEPLEARN/Trends_Reengineered_T3toTRs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T3toTRs, "DEEPLEARN/Cycles_Reengineered_T3toTRs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T3toTRs, 
                                 emphasis.lwd.T3toTRs, emphasis.lty.T3toTRs)
```

### T3_to_CURs

```{r}
#Abtain reengineered dataset. 
subID.T3toCURs <- c(T3, 
                    "USDCNH", "USDX",
                    CUR.ind) 
emphasis.lwd.T3toCURs <- c(rep(3, length(T3)), rep(4, 2), rep(3, 4))
emphasis.lty.T3toCURs <- c(rep(1, length(T3)), rep(4, 2), rep(3, 4))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T3toCURs <- TD_All.ts[, paste0(subID.T3toCURs, "_hpft")]
Cycles.Reengineered.T3toCURs <- TD_All.ts[, paste0(subID.T3toCURs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T3toCURs, "DEEPLEARN/Trends_Reengineered_T3toCURs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T3toCURs, "DEEPLEARN/Cycles_Reengineered_T3toCURs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T3toCURs, 
                                 emphasis.lwd.T3toCURs, emphasis.lty.T3toCURs)
```

### T3_to_CMDs

```{r}
#Abtain reengineered dataset. 
subID.T3toCMDs <- c(T3, 
                    CMD.ind
                   ) 
emphasis.lwd.T3toCMDs <- c(rep(3, length(T3)), rep(4, 3), rep(3, length(CMD.ind)-3))
emphasis.lty.T3toCMDs <- c(rep(1, length(T3)), rep(4, 3), rep(3, length(CMD.ind)-3))
#Use subID throught T3ENDS and CYCLES
T3ends.Reengineered.T3toCMDs <- TD_All.ts[, paste0(subID.T3toCMDs, "_hpft")]
Cycles.Reengineered.T3toCMDs <- TD_All.ts[, paste0(subID.T3toCMDs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(T3ends.Reengineered.T3toCMDs, "DEEPLEARN/T3ends_Reengineered_T3toCMDs.csv", col.names = T3UE)
write.csv(Cycles.Reengineered.T3toCMDs, "DEEPLEARN/Cycles_Reengineered_T3toCMDs.csv", col.names = T3UE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(T3ends.Reengineered.T3toCMDs, 
                                 emphasis.lwd.T3toCMDs, emphasis.lty.T3toCMDs)
```

### T3_to_EQTs

```{r}
#Abtain reengineered dataset. 
subID.T3toEQTs <- c(T3,
                    "IH00C1", "IF00C1", 
                    "SPX", "FTSE"
                   ) 
emphasis.lwd.T3toEQTs <- c(rep(3, length(T3)), rep(4, 2), rep(3, 2))
emphasis.lty.T3toEQTs <- c(rep(1, length(T3)), rep(4, 2), rep(3, 2))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T3toEQTs <- TD_All.ts[, paste0(subID.T3toEQTs, "_hpft")]
Cycles.Reengineered.T3toEQTs <- TD_All.ts[, paste0(subID.T3toEQTs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T3toEQTs, "DEEPLEARN/Trends_Reengineered_T3toEQTs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T3toEQTs, "DEEPLEARN/Cycles_Reengineered_T3toEQTs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T3toEQTs, 
                                 emphasis.lwd.T3toEQTs, emphasis.lty.T3toEQTs)
```

T3_C
==================================================

T3_CYCLES {.tabset .tabset-fade data-height=6500}
-------------------------------------

### T3_to_Yields

```{r}
#subID is used all throught T3ENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T3toYield <- TD_All.ts.2[, paste0(subID.T3toYield, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T3toYield, "DEEPLEARN/Cycles_Visualizing_T3toYield.csv", col.names = T3UE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T3toYield, Major_id = 1)
```

### T3_to_TRs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T3toTRs <- TD_All.ts.2[, paste0(subID.T3toTRs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T3toTRs, "DEEPLEARN/Cycles_Visualizing_T3toTRs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T3toTRs, Major_id = 1)
```

### T3_to_CURs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T3toCURs <- TD_All.ts.2[, paste0(subID.T3toCURs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T3toCURs, "DEEPLEARN/Cycles_Visualizing_T3toCURs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T3toCURs, Major_id = 1)
```

### T3_to_CMDs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T3toCMDs <- TD_All.ts.2[, paste0(subID.T3toCMDs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T3toCMDs, "DEEPLEARN/Cycles_Visualizing_T3toCMDs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T3toCMDs, Major_id = 1)
```

### T3_to_EQTs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T3toEQTs <- TD_All.ts.2[, paste0(subID.T3toEQTs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T3toEQTs, "DEEPLEARN/Cycles_Visualizing_T3toEQTs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T3toEQTs, Major_id = 1)
```

T4_T
==================================================

T4_TRENDS {.tabset .tabset-fade}
-------------------------------------

### T4_to_Yields

```{r}
#Abtain reengineered dataset. 
subID.T4toYield <- c(T4, 
                     "CN_10yry", "US_10yry",
                     "UK_10yry", "GR_10yry", "IT_10yry", "AU_10yry", "INA_10yry", "IND_10yry"
                     ) 
emphasis.lwd.T4toYield <- c(rep(3, length(T4)), rep(4, 2), rep(3, 6))
emphasis.lty.T4toYield <- c(rep(1, length(T4)), rep(4, 2), rep(3, 6))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T4toYield <- TD_All.ts[, paste0(subID.T4toYield, "_hpft")]
Cycles.Reengineered.T4toYield <- TD_All.ts[, paste0(subID.T4toYield, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T4toYield, "DEEPLEARN/Trends_Reengineered_T4toYield.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T4toYield, "DEEPLEARN/Cycles_Reengineered_T4toYield.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T4toYield, 
                                 emphasis.lwd.T4toYield, emphasis.lty.T4toYield)
```

### T4_to_TRs

```{r}
#Abtain reengineered dataset. 
subID.T4toTRs <- c(T4,
                   "T00C1", 
                   "TF00C1",
                   "TY00Y",
                   "FV00Y"
                   ) 
emphasis.lwd.T4toTRs <- c(rep(3, length(T4)), rep(4, 2), rep(3, 2))
emphasis.lty.T4toTRs <- c(rep(1, length(T4)), rep(4, 2), rep(3, 2))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T4toTRs <- TD_All.ts[, paste0(subID.T4toTRs, "_hpft")]
Cycles.Reengineered.T4toTRs <- TD_All.ts[, paste0(subID.T4toTRs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T4toTRs, "DEEPLEARN/Trends_Reengineered_T4toTRs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T4toTRs, "DEEPLEARN/Cycles_Reengineered_T4toTRs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T4toTRs, 
                                 emphasis.lwd.T4toTRs, emphasis.lty.T4toTRs)
```

### T4_to_CURs

```{r}
#Abtain reengineered dataset. 
subID.T4toCURs <- c(T4, 
                    "USDCNH", "USDX",
                    CUR.ind) 
emphasis.lwd.T4toCURs <- c(rep(3, length(T4)), rep(4, 2), rep(3, 4))
emphasis.lty.T4toCURs <- c(rep(1, length(T4)), rep(4, 2), rep(3, 4))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T4toCURs <- TD_All.ts[, paste0(subID.T4toCURs, "_hpft")]
Cycles.Reengineered.T4toCURs <- TD_All.ts[, paste0(subID.T4toCURs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T4toCURs, "DEEPLEARN/Trends_Reengineered_T4toCURs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T4toCURs, "DEEPLEARN/Cycles_Reengineered_T4toCURs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T4toCURs, 
                                 emphasis.lwd.T4toCURs, emphasis.lty.T4toCURs)
```

### T4_to_CMDs

```{r}
#Abtain reengineered dataset. 
subID.T4toCMDs <- c(T4, 
                    CMD.ind
                   ) 
emphasis.lwd.T4toCMDs <- c(rep(3, length(T4)), rep(4, 3), rep(3, length(CMD.ind)-3))
emphasis.lty.T4toCMDs <- c(rep(1, length(T4)), rep(4, 3), rep(3, length(CMD.ind)-3))
#Use subID throught T4ENDS and CYCLES
T4ends.Reengineered.T4toCMDs <- TD_All.ts[, paste0(subID.T4toCMDs, "_hpft")]
Cycles.Reengineered.T4toCMDs <- TD_All.ts[, paste0(subID.T4toCMDs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(T4ends.Reengineered.T4toCMDs, "DEEPLEARN/T4ends_Reengineered_T4toCMDs.csv", col.names = T4UE)
write.csv(Cycles.Reengineered.T4toCMDs, "DEEPLEARN/Cycles_Reengineered_T4toCMDs.csv", col.names = T4UE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(T4ends.Reengineered.T4toCMDs, 
                                 emphasis.lwd.T4toCMDs, emphasis.lty.T4toCMDs)
```

### T4_to_EQTs

```{r}
#Abtain reengineered dataset. 
subID.T4toEQTs <- c(T4,
                    "IH00C1", "IF00C1", 
                    "SPX", "FTSE"
                   ) 
emphasis.lwd.T4toEQTs <- c(rep(3, length(T4)), rep(4, 2), rep(3, 2))
emphasis.lty.T4toEQTs <- c(rep(1, length(T4)), rep(4, 2), rep(3, 2))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T4toEQTs <- TD_All.ts[, paste0(subID.T4toEQTs, "_hpft")]
Cycles.Reengineered.T4toEQTs <- TD_All.ts[, paste0(subID.T4toEQTs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T4toEQTs, "DEEPLEARN/Trends_Reengineered_T4toEQTs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T4toEQTs, "DEEPLEARN/Cycles_Reengineered_T4toEQTs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T4toEQTs, 
                                 emphasis.lwd.T4toEQTs, emphasis.lty.T4toEQTs)
```

T4_C
==================================================

T4_CYCLES {.tabset .tabset-fade data-height=6500}
-------------------------------------

### T4_to_Yields

```{r}
#subID is used all throught T4ENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T4toYield <- TD_All.ts.2[, paste0(subID.T4toYield, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T4toYield, "DEEPLEARN/Cycles_Visualizing_T4toYield.csv", col.names = T4UE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T4toYield, Major_id = 1)
```

### T4_to_TRs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T4toTRs <- TD_All.ts.2[, paste0(subID.T4toTRs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T4toTRs, "DEEPLEARN/Cycles_Visualizing_T4toTRs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T4toTRs, Major_id = 1)
```

### T4_to_CURs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T4toCURs <- TD_All.ts.2[, paste0(subID.T4toCURs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T4toCURs, "DEEPLEARN/Cycles_Visualizing_T4toCURs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T4toCURs, Major_id = 1)
```

### T4_to_CMDs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T4toCMDs <- TD_All.ts.2[, paste0(subID.T4toCMDs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T4toCMDs, "DEEPLEARN/Cycles_Visualizing_T4toCMDs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T4toCMDs, Major_id = 1)
```

### T4_to_EQTs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T4toEQTs <- TD_All.ts.2[, paste0(subID.T4toEQTs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T4toEQTs, "DEEPLEARN/Cycles_Visualizing_T4toEQTs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T4toEQTs, Major_id = 1)
```

T5_T
==================================================

T5_TRENDS {.tabset .tabset-fade}
-------------------------------------

### T5_to_Yields

```{r}
#Abtain reengineered dataset. 
subID.T5toYield <- c(T5, 
                     "CN_10yry", "US_10yry",
                     "UK_10yry", "GR_10yry", "IT_10yry", "AU_10yry", "INA_10yry", "IND_10yry"
                     ) 
emphasis.lwd.T5toYield <- c(rep(3, length(T5)), rep(4, 2), rep(3, 6))
emphasis.lty.T5toYield <- c(rep(1, length(T5)), rep(4, 2), rep(3, 6))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T5toYield <- TD_All.ts[, paste0(subID.T5toYield, "_hpft")]
Cycles.Reengineered.T5toYield <- TD_All.ts[, paste0(subID.T5toYield, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T5toYield, "DEEPLEARN/Trends_Reengineered_T5toYield.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T5toYield, "DEEPLEARN/Cycles_Reengineered_T5toYield.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T5toYield, 
                                 emphasis.lwd.T5toYield, emphasis.lty.T5toYield)
```

### T5_to_TRs

```{r}
#Abtain reengineered dataset. 
subID.T5toTRs <- c(T5,
                   "T00C1", 
                   "TF00C1",
                   "TY00Y",
                   "FV00Y"
                   ) 
emphasis.lwd.T5toTRs <- c(rep(3, length(T5)), rep(4, 2), rep(3, 2))
emphasis.lty.T5toTRs <- c(rep(1, length(T5)), rep(4, 2), rep(3, 2))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T5toTRs <- TD_All.ts[, paste0(subID.T5toTRs, "_hpft")]
Cycles.Reengineered.T5toTRs <- TD_All.ts[, paste0(subID.T5toTRs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T5toTRs, "DEEPLEARN/Trends_Reengineered_T5toTRs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T5toTRs, "DEEPLEARN/Cycles_Reengineered_T5toTRs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T5toTRs, 
                                 emphasis.lwd.T5toTRs, emphasis.lty.T5toTRs)
```

### T5_to_CURs

```{r}
#Abtain reengineered dataset. 
subID.T5toCURs <- c(T5, 
                    "USDCNH", "USDX",
                    CUR.ind) 
emphasis.lwd.T5toCURs <- c(rep(3, length(T5)), rep(4, 2), rep(3, 4))
emphasis.lty.T5toCURs <- c(rep(1, length(T5)), rep(4, 2), rep(3, 4))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T5toCURs <- TD_All.ts[, paste0(subID.T5toCURs, "_hpft")]
Cycles.Reengineered.T5toCURs <- TD_All.ts[, paste0(subID.T5toCURs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T5toCURs, "DEEPLEARN/Trends_Reengineered_T5toCURs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T5toCURs, "DEEPLEARN/Cycles_Reengineered_T5toCURs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T5toCURs, 
                                 emphasis.lwd.T5toCURs, emphasis.lty.T5toCURs)
```

### T5_to_CMDs

```{r}
#Abtain reengineered dataset. 
subID.T5toCMDs <- c(T5, 
                    CMD.ind
                   ) 
emphasis.lwd.T5toCMDs <- c(rep(3, length(T5)), rep(4, 3), rep(3, length(CMD.ind)-3))
emphasis.lty.T5toCMDs <- c(rep(1, length(T5)), rep(4, 3), rep(3, length(CMD.ind)-3))
#Use subID throught T5ENDS and CYCLES
T5ends.Reengineered.T5toCMDs <- TD_All.ts[, paste0(subID.T5toCMDs, "_hpft")]
Cycles.Reengineered.T5toCMDs <- TD_All.ts[, paste0(subID.T5toCMDs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(T5ends.Reengineered.T5toCMDs, "DEEPLEARN/T5ends_Reengineered_T5toCMDs.csv", col.names = T5UE)
write.csv(Cycles.Reengineered.T5toCMDs, "DEEPLEARN/Cycles_Reengineered_T5toCMDs.csv", col.names = T5UE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(T5ends.Reengineered.T5toCMDs, 
                                 emphasis.lwd.T5toCMDs, emphasis.lty.T5toCMDs)
```

### T5_to_EQTs

```{r}
#Abtain reengineered dataset. 
subID.T5toEQTs <- c(T5,
                    "IH00C1", "IF00C1", 
                    "SPX", "FTSE"
                   ) 
emphasis.lwd.T5toEQTs <- c(rep(3, length(T5)), rep(4, 2), rep(3, 2))
emphasis.lty.T5toEQTs <- c(rep(1, length(T5)), rep(4, 2), rep(3, 2))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T5toEQTs <- TD_All.ts[, paste0(subID.T5toEQTs, "_hpft")]
Cycles.Reengineered.T5toEQTs <- TD_All.ts[, paste0(subID.T5toEQTs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T5toEQTs, "DEEPLEARN/Trends_Reengineered_T5toEQTs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T5toEQTs, "DEEPLEARN/Cycles_Reengineered_T5toEQTs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T5toEQTs, 
                                 emphasis.lwd.T5toEQTs, emphasis.lty.T5toEQTs)
```

T5_C
==================================================

T5_CYCLES {.tabset .tabset-fade data-height=6500}
-------------------------------------

### T5_to_Yields

```{r}
#subID is used all throught T5ENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T5toYield <- TD_All.ts.2[, paste0(subID.T5toYield, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T5toYield, "DEEPLEARN/Cycles_Visualizing_T5toYield.csv", col.names = T5UE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T5toYield, Major_id = 1)
```

### T5_to_TRs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T5toTRs <- TD_All.ts.2[, paste0(subID.T5toTRs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T5toTRs, "DEEPLEARN/Cycles_Visualizing_T5toTRs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T5toTRs, Major_id = 1)
```

### T5_to_CURs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T5toCURs <- TD_All.ts.2[, paste0(subID.T5toCURs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T5toCURs, "DEEPLEARN/Cycles_Visualizing_T5toCURs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T5toCURs, Major_id = 1)
```

### T5_to_CMDs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T5toCMDs <- TD_All.ts.2[, paste0(subID.T5toCMDs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T5toCMDs, "DEEPLEARN/Cycles_Visualizing_T5toCMDs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T5toCMDs, Major_id = 1)
```

### T5_to_EQTs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T5toEQTs <- TD_All.ts.2[, paste0(subID.T5toEQTs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T5toEQTs, "DEEPLEARN/Cycles_Visualizing_T5toEQTs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T5toEQTs, Major_id = 1)
```

T6_T
==================================================

T6_TRENDS {.tabset .tabset-fade}
-------------------------------------

### T6_to_Yields

```{r}
#Abtain reengineered dataset. 
subID.T6toYield <- c(T6, 
                     "CN_10yry", "US_10yry",
                     "UK_10yry", "GR_10yry", "IT_10yry", "AU_10yry", "INA_10yry", "IND_10yry"
                     ) 
emphasis.lwd.T6toYield <- c(rep(3, length(T6)), rep(4, 2), rep(3, 6))
emphasis.lty.T6toYield <- c(rep(1, length(T6)), rep(4, 2), rep(3, 6))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T6toYield <- TD_All.ts[, paste0(subID.T6toYield, "_hpft")]
Cycles.Reengineered.T6toYield <- TD_All.ts[, paste0(subID.T6toYield, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T6toYield, "DEEPLEARN/Trends_Reengineered_T6toYield.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T6toYield, "DEEPLEARN/Cycles_Reengineered_T6toYield.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T6toYield, 
                                 emphasis.lwd.T6toYield, emphasis.lty.T6toYield)
```

### T6_to_TRs

```{r}
#Abtain reengineered dataset. 
subID.T6toTRs <- c(T6,
                   "T00C1", 
                   "TF00C1",
                   "TY00Y",
                   "FV00Y"
                   ) 
emphasis.lwd.T6toTRs <- c(rep(3, length(T6)), rep(4, 2), rep(3, 2))
emphasis.lty.T6toTRs <- c(rep(1, length(T6)), rep(4, 2), rep(3, 2))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T6toTRs <- TD_All.ts[, paste0(subID.T6toTRs, "_hpft")]
Cycles.Reengineered.T6toTRs <- TD_All.ts[, paste0(subID.T6toTRs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T6toTRs, "DEEPLEARN/Trends_Reengineered_T6toTRs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T6toTRs, "DEEPLEARN/Cycles_Reengineered_T6toTRs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T6toTRs, 
                                 emphasis.lwd.T6toTRs, emphasis.lty.T6toTRs)
```

### T6_to_CURs

```{r}
#Abtain reengineered dataset. 
subID.T6toCURs <- c(T6, 
                    "USDCNH", "USDX",
                    CUR.ind) 
emphasis.lwd.T6toCURs <- c(rep(3, length(T6)), rep(4, 2), rep(3, 4))
emphasis.lty.T6toCURs <- c(rep(1, length(T6)), rep(4, 2), rep(3, 4))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T6toCURs <- TD_All.ts[, paste0(subID.T6toCURs, "_hpft")]
Cycles.Reengineered.T6toCURs <- TD_All.ts[, paste0(subID.T6toCURs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T6toCURs, "DEEPLEARN/Trends_Reengineered_T6toCURs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T6toCURs, "DEEPLEARN/Cycles_Reengineered_T6toCURs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T6toCURs, 
                                 emphasis.lwd.T6toCURs, emphasis.lty.T6toCURs)
```

### T6_to_CMDs

```{r}
#Abtain reengineered dataset. 
subID.T6toCMDs <- c(T6, 
                    CMD.ind
                   ) 
emphasis.lwd.T6toCMDs <- c(rep(3, length(T6)), rep(4, 3), rep(3, length(CMD.ind)-3))
emphasis.lty.T6toCMDs <- c(rep(1, length(T6)), rep(4, 3), rep(3, length(CMD.ind)-3))
#Use subID throught T6ENDS and CYCLES
T6ends.Reengineered.T6toCMDs <- TD_All.ts[, paste0(subID.T6toCMDs, "_hpft")]
Cycles.Reengineered.T6toCMDs <- TD_All.ts[, paste0(subID.T6toCMDs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(T6ends.Reengineered.T6toCMDs, "DEEPLEARN/T6ends_Reengineered_T6toCMDs.csv", col.names = T6UE)
write.csv(Cycles.Reengineered.T6toCMDs, "DEEPLEARN/Cycles_Reengineered_T6toCMDs.csv", col.names = T6UE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(T6ends.Reengineered.T6toCMDs, 
                                 emphasis.lwd.T6toCMDs, emphasis.lty.T6toCMDs)
```

### T6_to_EQTs

```{r}
#Abtain reengineered dataset. 
subID.T6toEQTs <- c(T6,
                    "IH00C1", "IF00C1", 
                    "SPX", "FTSE"
                   ) 
emphasis.lwd.T6toEQTs <- c(rep(3, length(T6)), rep(4, 2), rep(3, 2))
emphasis.lty.T6toEQTs <- c(rep(1, length(T6)), rep(4, 2), rep(3, 2))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T6toEQTs <- TD_All.ts[, paste0(subID.T6toEQTs, "_hpft")]
Cycles.Reengineered.T6toEQTs <- TD_All.ts[, paste0(subID.T6toEQTs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T6toEQTs, "DEEPLEARN/Trends_Reengineered_T6toEQTs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T6toEQTs, "DEEPLEARN/Cycles_Reengineered_T6toEQTs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T6toEQTs, 
                                 emphasis.lwd.T6toEQTs, emphasis.lty.T6toEQTs)
```

T6_C
==================================================

T6_CYCLES {.tabset .tabset-fade data-height=6500}
-------------------------------------

### T6_to_Yields

```{r}
#subID is used all throught T6ENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T6toYield <- TD_All.ts.2[, paste0(subID.T6toYield, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T6toYield, "DEEPLEARN/Cycles_Visualizing_T6toYield.csv", col.names = T6UE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T6toYield, Major_id = 1)
```

### T6_to_TRs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T6toTRs <- TD_All.ts.2[, paste0(subID.T6toTRs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T6toTRs, "DEEPLEARN/Cycles_Visualizing_T6toTRs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T6toTRs, Major_id = 1)
```

### T6_to_CURs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T6toCURs <- TD_All.ts.2[, paste0(subID.T6toCURs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T6toCURs, "DEEPLEARN/Cycles_Visualizing_T6toCURs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T6toCURs, Major_id = 1)
```

### T6_to_CMDs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T6toCMDs <- TD_All.ts.2[, paste0(subID.T6toCMDs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T6toCMDs, "DEEPLEARN/Cycles_Visualizing_T6toCMDs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T6toCMDs, Major_id = 1)
```

### T6_to_EQTs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T6toEQTs <- TD_All.ts.2[, paste0(subID.T6toEQTs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T6toEQTs, "DEEPLEARN/Cycles_Visualizing_T6toEQTs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T6toEQTs, Major_id = 1)
```


T7_T
==================================================

T7_TRENDS {.tabset .tabset-fade}
-------------------------------------

### T7_to_Yields

```{r}
#Abtain reengineered dataset. 
subID.T7toYield <- c(T7, 
                     "CN_10yry", "US_10yry",
                     "UK_10yry", "GR_10yry", "IT_10yry", "AU_10yry", "INA_10yry", "IND_10yry"
                     ) 
emphasis.lwd.T7toYield <- c(rep(3, length(T7)), rep(4, 2), rep(3, 6))
emphasis.lty.T7toYield <- c(rep(1, length(T7)), rep(4, 2), rep(3, 6))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T7toYield <- TD_All.ts[, paste0(subID.T7toYield, "_hpft")]
Cycles.Reengineered.T7toYield <- TD_All.ts[, paste0(subID.T7toYield, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T7toYield, "DEEPLEARN/Trends_Reengineered_T7toYield.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T7toYield, "DEEPLEARN/Cycles_Reengineered_T7toYield.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T7toYield, 
                                 emphasis.lwd.T7toYield, emphasis.lty.T7toYield)
```

### T7_to_TRs

```{r}
#Abtain reengineered dataset. 
subID.T7toTRs <- c(T7,
                   "T00C1", 
                   "TF00C1",
                   "TY00Y",
                   "FV00Y"
                   ) 
emphasis.lwd.T7toTRs <- c(rep(3, length(T7)), rep(4, 2), rep(3, 2))
emphasis.lty.T7toTRs <- c(rep(1, length(T7)), rep(4, 2), rep(3, 2))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T7toTRs <- TD_All.ts[, paste0(subID.T7toTRs, "_hpft")]
Cycles.Reengineered.T7toTRs <- TD_All.ts[, paste0(subID.T7toTRs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T7toTRs, "DEEPLEARN/Trends_Reengineered_T7toTRs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T7toTRs, "DEEPLEARN/Cycles_Reengineered_T7toTRs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T7toTRs, 
                                 emphasis.lwd.T7toTRs, emphasis.lty.T7toTRs)
```

### T7_to_CURs

```{r}
#Abtain reengineered dataset. 
subID.T7toCURs <- c(T7, 
                    "USDCNH", "USDX",
                    CUR.ind) 
emphasis.lwd.T7toCURs <- c(rep(3, length(T7)), rep(4, 2), rep(3, 4))
emphasis.lty.T7toCURs <- c(rep(1, length(T7)), rep(4, 2), rep(3, 4))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T7toCURs <- TD_All.ts[, paste0(subID.T7toCURs, "_hpft")]
Cycles.Reengineered.T7toCURs <- TD_All.ts[, paste0(subID.T7toCURs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T7toCURs, "DEEPLEARN/Trends_Reengineered_T7toCURs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T7toCURs, "DEEPLEARN/Cycles_Reengineered_T7toCURs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T7toCURs, 
                                 emphasis.lwd.T7toCURs, emphasis.lty.T7toCURs)
```

### T7_to_CMDs

```{r}
#Abtain reengineered dataset. 
subID.T7toCMDs <- c(T7, 
                    CMD.ind
                   ) 
emphasis.lwd.T7toCMDs <- c(rep(3, length(T7)), rep(4, 3), rep(3, length(CMD.ind)-3))
emphasis.lty.T7toCMDs <- c(rep(1, length(T7)), rep(4, 3), rep(3, length(CMD.ind)-3))
#Use subID throught T7ENDS and CYCLES
T7ends.Reengineered.T7toCMDs <- TD_All.ts[, paste0(subID.T7toCMDs, "_hpft")]
Cycles.Reengineered.T7toCMDs <- TD_All.ts[, paste0(subID.T7toCMDs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(T7ends.Reengineered.T7toCMDs, "DEEPLEARN/T7ends_Reengineered_T7toCMDs.csv", col.names = T7UE)
write.csv(Cycles.Reengineered.T7toCMDs, "DEEPLEARN/Cycles_Reengineered_T7toCMDs.csv", col.names = T7UE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(T7ends.Reengineered.T7toCMDs, 
                                 emphasis.lwd.T7toCMDs, emphasis.lty.T7toCMDs)
```

### T7_to_EQTs

```{r}
#Abtain reengineered dataset. 
subID.T7toEQTs <- c(T7,
                    "IH00C1", "IF00C1", 
                    "SPX", "FTSE"
                   ) 
emphasis.lwd.T7toEQTs <- c(rep(3, length(T7)), rep(4, 2), rep(3, 2))
emphasis.lty.T7toEQTs <- c(rep(1, length(T7)), rep(4, 2), rep(3, 2))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T7toEQTs <- TD_All.ts[, paste0(subID.T7toEQTs, "_hpft")]
Cycles.Reengineered.T7toEQTs <- TD_All.ts[, paste0(subID.T7toEQTs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T7toEQTs, "DEEPLEARN/Trends_Reengineered_T7toEQTs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T7toEQTs, "DEEPLEARN/Cycles_Reengineered_T7toEQTs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T7toEQTs, 
                                 emphasis.lwd.T7toEQTs, emphasis.lty.T7toEQTs)
```

T7_C
==================================================

T7_CYCLES {.tabset .tabset-fade data-height=6500}
-------------------------------------

### T7_to_Yields

```{r}
#subID is used all throught T7ENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T7toYield <- TD_All.ts.2[, paste0(subID.T7toYield, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T7toYield, "DEEPLEARN/Cycles_Visualizing_T7toYield.csv", col.names = T7UE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T7toYield, Major_id = 1)
```

### T7_to_TRs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T7toTRs <- TD_All.ts.2[, paste0(subID.T7toTRs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T7toTRs, "DEEPLEARN/Cycles_Visualizing_T7toTRs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T7toTRs, Major_id = 1)
```

### T7_to_CURs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T7toCURs <- TD_All.ts.2[, paste0(subID.T7toCURs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T7toCURs, "DEEPLEARN/Cycles_Visualizing_T7toCURs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T7toCURs, Major_id = 1)
```

### T7_to_CMDs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T7toCMDs <- TD_All.ts.2[, paste0(subID.T7toCMDs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T7toCMDs, "DEEPLEARN/Cycles_Visualizing_T7toCMDs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T7toCMDs, Major_id = 1)
```

### T7_to_EQTs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T7toEQTs <- TD_All.ts.2[, paste0(subID.T7toEQTs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T7toEQTs, "DEEPLEARN/Cycles_Visualizing_T7toEQTs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T7toEQTs, Major_id = 1)
```


T8_T
==================================================

T8_TRENDS {.tabset .tabset-fade}
-------------------------------------

### T8_to_Yields

```{r}
#Abtain reengineered dataset. 
subID.T8toYield <- c(T8, 
                     "CN_10yry", "US_10yry",
                     "UK_10yry", "GR_10yry", "IT_10yry", "AU_10yry", "INA_10yry", "IND_10yry"
                     ) 
emphasis.lwd.T8toYield <- c(rep(3, length(T8)), rep(4, 2), rep(3, 6))
emphasis.lty.T8toYield <- c(rep(1, length(T8)), rep(4, 2), rep(3, 6))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T8toYield <- TD_All.ts[, paste0(subID.T8toYield, "_hpft")]
Cycles.Reengineered.T8toYield <- TD_All.ts[, paste0(subID.T8toYield, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T8toYield, "DEEPLEARN/Trends_Reengineered_T8toYield.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T8toYield, "DEEPLEARN/Cycles_Reengineered_T8toYield.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T8toYield, 
                                 emphasis.lwd.T8toYield, emphasis.lty.T8toYield)
```

### T8_to_TRs

```{r}
#Abtain reengineered dataset. 
subID.T8toTRs <- c(T8,
                   "T00C1", 
                   "TF00C1",
                   "TY00Y",
                   "FV00Y"
                   ) 
emphasis.lwd.T8toTRs <- c(rep(3, length(T8)), rep(4, 2), rep(3, 2))
emphasis.lty.T8toTRs <- c(rep(1, length(T8)), rep(4, 2), rep(3, 2))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T8toTRs <- TD_All.ts[, paste0(subID.T8toTRs, "_hpft")]
Cycles.Reengineered.T8toTRs <- TD_All.ts[, paste0(subID.T8toTRs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T8toTRs, "DEEPLEARN/Trends_Reengineered_T8toTRs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T8toTRs, "DEEPLEARN/Cycles_Reengineered_T8toTRs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T8toTRs, 
                                 emphasis.lwd.T8toTRs, emphasis.lty.T8toTRs)
```

### T8_to_CURs

```{r}
#Abtain reengineered dataset. 
subID.T8toCURs <- c(T8, 
                    "USDCNH", "USDX",
                    CUR.ind) 
emphasis.lwd.T8toCURs <- c(rep(3, length(T8)), rep(4, 2), rep(3, 4))
emphasis.lty.T8toCURs <- c(rep(1, length(T8)), rep(4, 2), rep(3, 4))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T8toCURs <- TD_All.ts[, paste0(subID.T8toCURs, "_hpft")]
Cycles.Reengineered.T8toCURs <- TD_All.ts[, paste0(subID.T8toCURs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T8toCURs, "DEEPLEARN/Trends_Reengineered_T8toCURs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T8toCURs, "DEEPLEARN/Cycles_Reengineered_T8toCURs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T8toCURs, 
                                 emphasis.lwd.T8toCURs, emphasis.lty.T8toCURs)
```

### T8_to_CMDs

```{r}
#Abtain reengineered dataset. 
subID.T8toCMDs <- c(T8, 
                    CMD.ind
                   ) 
emphasis.lwd.T8toCMDs <- c(rep(3, length(T8)), rep(4, 3), rep(3, length(CMD.ind)-3))
emphasis.lty.T8toCMDs <- c(rep(1, length(T8)), rep(4, 3), rep(3, length(CMD.ind)-3))
#Use subID throught T8ENDS and CYCLES
T8ends.Reengineered.T8toCMDs <- TD_All.ts[, paste0(subID.T8toCMDs, "_hpft")]
Cycles.Reengineered.T8toCMDs <- TD_All.ts[, paste0(subID.T8toCMDs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(T8ends.Reengineered.T8toCMDs, "DEEPLEARN/T8ends_Reengineered_T8toCMDs.csv", col.names = T8UE)
write.csv(Cycles.Reengineered.T8toCMDs, "DEEPLEARN/Cycles_Reengineered_T8toCMDs.csv", col.names = T8UE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(T8ends.Reengineered.T8toCMDs, 
                                 emphasis.lwd.T8toCMDs, emphasis.lty.T8toCMDs)
```

### T8_to_EQTs

```{r}
#Abtain reengineered dataset. 
subID.T8toEQTs <- c(T8,
                    "IH00C1", "IF00C1", 
                    "SPX", "FTSE"
                   ) 
emphasis.lwd.T8toEQTs <- c(rep(3, length(T8)), rep(4, 2), rep(3, 2))
emphasis.lty.T8toEQTs <- c(rep(1, length(T8)), rep(4, 2), rep(3, 2))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T8toEQTs <- TD_All.ts[, paste0(subID.T8toEQTs, "_hpft")]
Cycles.Reengineered.T8toEQTs <- TD_All.ts[, paste0(subID.T8toEQTs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T8toEQTs, "DEEPLEARN/Trends_Reengineered_T8toEQTs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T8toEQTs, "DEEPLEARN/Cycles_Reengineered_T8toEQTs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T8toEQTs, 
                                 emphasis.lwd.T8toEQTs, emphasis.lty.T8toEQTs)
```

T8_C
==================================================

T8_CYCLES {.tabset .tabset-fade data-height=6500}
-------------------------------------

### T8_to_Yields

```{r}
#subID is used all throught T8ENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T8toYield <- TD_All.ts.2[, paste0(subID.T8toYield, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T8toYield, "DEEPLEARN/Cycles_Visualizing_T8toYield.csv", col.names = T8UE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T8toYield, Major_id = 1)
```

### T8_to_TRs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T8toTRs <- TD_All.ts.2[, paste0(subID.T8toTRs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T8toTRs, "DEEPLEARN/Cycles_Visualizing_T8toTRs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T8toTRs, Major_id = 1)
```

### T8_to_CURs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T8toCURs <- TD_All.ts.2[, paste0(subID.T8toCURs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T8toCURs, "DEEPLEARN/Cycles_Visualizing_T8toCURs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T8toCURs, Major_id = 1)
```

### T8_to_CMDs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T8toCMDs <- TD_All.ts.2[, paste0(subID.T8toCMDs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T8toCMDs, "DEEPLEARN/Cycles_Visualizing_T8toCMDs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T8toCMDs, Major_id = 1)
```

### T8_to_EQTs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T8toEQTs <- TD_All.ts.2[, paste0(subID.T8toEQTs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T8toEQTs, "DEEPLEARN/Cycles_Visualizing_T8toEQTs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T8toEQTs, Major_id = 1)
```


T9_T
==================================================

T9_TRENDS {.tabset .tabset-fade}
-------------------------------------

### T9_to_Yields

```{r}
#Abtain reengineered dataset. 
subID.T9toYield <- c(T9, 
                     "CN_10yry", "US_10yry",
                     "UK_10yry", "GR_10yry", "IT_10yry", "AU_10yry", "INA_10yry", "IND_10yry"
                     ) 
emphasis.lwd.T9toYield <- c(rep(3, length(T9)), rep(4, 2), rep(3, 6))
emphasis.lty.T9toYield <- c(rep(1, length(T9)), rep(4, 2), rep(3, 6))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T9toYield <- TD_All.ts[, paste0(subID.T9toYield, "_hpft")]
Cycles.Reengineered.T9toYield <- TD_All.ts[, paste0(subID.T9toYield, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T9toYield, "DEEPLEARN/Trends_Reengineered_T9toYield.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T9toYield, "DEEPLEARN/Cycles_Reengineered_T9toYield.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T9toYield, 
                                 emphasis.lwd.T9toYield, emphasis.lty.T9toYield)
```

### T9_to_TRs

```{r}
#Abtain reengineered dataset. 
subID.T9toTRs <- c(T9,
                   "T00C1", 
                   "TF00C1",
                   "TY00Y",
                   "FV00Y"
                   ) 
emphasis.lwd.T9toTRs <- c(rep(3, length(T9)), rep(4, 2), rep(3, 2))
emphasis.lty.T9toTRs <- c(rep(1, length(T9)), rep(4, 2), rep(3, 2))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T9toTRs <- TD_All.ts[, paste0(subID.T9toTRs, "_hpft")]
Cycles.Reengineered.T9toTRs <- TD_All.ts[, paste0(subID.T9toTRs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T9toTRs, "DEEPLEARN/Trends_Reengineered_T9toTRs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T9toTRs, "DEEPLEARN/Cycles_Reengineered_T9toTRs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T9toTRs, 
                                 emphasis.lwd.T9toTRs, emphasis.lty.T9toTRs)
```

### T9_to_CURs

```{r}
#Abtain reengineered dataset. 
subID.T9toCURs <- c(T9, 
                    "USDCNH", "USDX",
                    CUR.ind) 
emphasis.lwd.T9toCURs <- c(rep(3, length(T9)), rep(4, 2), rep(3, 4))
emphasis.lty.T9toCURs <- c(rep(1, length(T9)), rep(4, 2), rep(3, 4))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T9toCURs <- TD_All.ts[, paste0(subID.T9toCURs, "_hpft")]
Cycles.Reengineered.T9toCURs <- TD_All.ts[, paste0(subID.T9toCURs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T9toCURs, "DEEPLEARN/Trends_Reengineered_T9toCURs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T9toCURs, "DEEPLEARN/Cycles_Reengineered_T9toCURs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T9toCURs, 
                                 emphasis.lwd.T9toCURs, emphasis.lty.T9toCURs)
```

### T9_to_CMDs

```{r}
#Abtain reengineered dataset. 
subID.T9toCMDs <- c(T9, 
                    CMD.ind
                   ) 
emphasis.lwd.T9toCMDs <- c(rep(3, length(T9)), rep(4, 3), rep(3, length(CMD.ind)-3))
emphasis.lty.T9toCMDs <- c(rep(1, length(T9)), rep(4, 3), rep(3, length(CMD.ind)-3))
#Use subID throught T9ENDS and CYCLES
T9ends.Reengineered.T9toCMDs <- TD_All.ts[, paste0(subID.T9toCMDs, "_hpft")]
Cycles.Reengineered.T9toCMDs <- TD_All.ts[, paste0(subID.T9toCMDs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(T9ends.Reengineered.T9toCMDs, "DEEPLEARN/T9ends_Reengineered_T9toCMDs.csv", col.names = T9UE)
write.csv(Cycles.Reengineered.T9toCMDs, "DEEPLEARN/Cycles_Reengineered_T9toCMDs.csv", col.names = T9UE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(T9ends.Reengineered.T9toCMDs, 
                                 emphasis.lwd.T9toCMDs, emphasis.lty.T9toCMDs)
```

### T9_to_EQTs

```{r}
#Abtain reengineered dataset. 
subID.T9toEQTs <- c(T9,
                    "IH00C1", "IF00C1", 
                    "SPX", "FTSE"
                   ) 
emphasis.lwd.T9toEQTs <- c(rep(3, length(T9)), rep(4, 2), rep(3, 2))
emphasis.lty.T9toEQTs <- c(rep(1, length(T9)), rep(4, 2), rep(3, 2))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T9toEQTs <- TD_All.ts[, paste0(subID.T9toEQTs, "_hpft")]
Cycles.Reengineered.T9toEQTs <- TD_All.ts[, paste0(subID.T9toEQTs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T9toEQTs, "DEEPLEARN/Trends_Reengineered_T9toEQTs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T9toEQTs, "DEEPLEARN/Cycles_Reengineered_T9toEQTs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T9toEQTs, 
                                 emphasis.lwd.T9toEQTs, emphasis.lty.T9toEQTs)
```

T9_C
==================================================

T9_CYCLES {.tabset .tabset-fade data-height=6500}
-------------------------------------

### T9_to_Yields

```{r}
#subID is used all throught T9ENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T9toYield <- TD_All.ts.2[, paste0(subID.T9toYield, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T9toYield, "DEEPLEARN/Cycles_Visualizing_T9toYield.csv", col.names = T9UE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T9toYield, Major_id = 1)
```

### T9_to_TRs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T9toTRs <- TD_All.ts.2[, paste0(subID.T9toTRs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T9toTRs, "DEEPLEARN/Cycles_Visualizing_T9toTRs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T9toTRs, Major_id = 1)
```

### T9_to_CURs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T9toCURs <- TD_All.ts.2[, paste0(subID.T9toCURs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T9toCURs, "DEEPLEARN/Cycles_Visualizing_T9toCURs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T9toCURs, Major_id = 1)
```

### T9_to_CMDs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T9toCMDs <- TD_All.ts.2[, paste0(subID.T9toCMDs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T9toCMDs, "DEEPLEARN/Cycles_Visualizing_T9toCMDs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T9toCMDs, Major_id = 1)
```

### T9_to_EQTs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T9toEQTs <- TD_All.ts.2[, paste0(subID.T9toEQTs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T9toEQTs, "DEEPLEARN/Cycles_Visualizing_T9toEQTs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T9toEQTs, Major_id = 1)
```

T10_T
==================================================

T10_TRENDS {.tabset .tabset-fade}
-------------------------------------

### T10_to_Yields

```{r}
#Abtain reengineered dataset. 
subID.T10toYield <- c(T10, 
                     "CN_10yry", "US_10yry",
                     "UK_10yry", "GR_10yry", "IT_10yry", "AU_10yry", "INA_10yry", "IND_10yry"
                     ) 
emphasis.lwd.T10toYield <- c(rep(3, length(T10)), rep(4, 2), rep(3, 6))
emphasis.lty.T10toYield <- c(rep(1, length(T10)), rep(4, 2), rep(3, 6))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T10toYield <- TD_All.ts[, paste0(subID.T10toYield, "_hpft")]
Cycles.Reengineered.T10toYield <- TD_All.ts[, paste0(subID.T10toYield, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T10toYield, "DEEPLEARN/Trends_Reengineered_T10toYield.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T10toYield, "DEEPLEARN/Cycles_Reengineered_T10toYield.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T10toYield, 
                                 emphasis.lwd.T10toYield, emphasis.lty.T10toYield)
```

### T10_to_TRs

```{r}
#Abtain reengineered dataset. 
subID.T10toTRs <- c(T10,
                   "T00C1", 
                   "TF00C1",
                   "TY00Y",
                   "FV00Y"
                   ) 
emphasis.lwd.T10toTRs <- c(rep(3, length(T10)), rep(4, 2), rep(3, 2))
emphasis.lty.T10toTRs <- c(rep(1, length(T10)), rep(4, 2), rep(3, 2))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T10toTRs <- TD_All.ts[, paste0(subID.T10toTRs, "_hpft")]
Cycles.Reengineered.T10toTRs <- TD_All.ts[, paste0(subID.T10toTRs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T10toTRs, "DEEPLEARN/Trends_Reengineered_T10toTRs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T10toTRs, "DEEPLEARN/Cycles_Reengineered_T10toTRs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T10toTRs, 
                                 emphasis.lwd.T10toTRs, emphasis.lty.T10toTRs)
```

### T10_to_CURs

```{r}
#Abtain reengineered dataset. 
subID.T10toCURs <- c(T10, 
                    "USDCNH", "USDX",
                    CUR.ind) 
emphasis.lwd.T10toCURs <- c(rep(3, length(T10)), rep(4, 2), rep(3, 4))
emphasis.lty.T10toCURs <- c(rep(1, length(T10)), rep(4, 2), rep(3, 4))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T10toCURs <- TD_All.ts[, paste0(subID.T10toCURs, "_hpft")]
Cycles.Reengineered.T10toCURs <- TD_All.ts[, paste0(subID.T10toCURs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T10toCURs, "DEEPLEARN/Trends_Reengineered_T10toCURs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T10toCURs, "DEEPLEARN/Cycles_Reengineered_T10toCURs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T10toCURs, 
                                 emphasis.lwd.T10toCURs, emphasis.lty.T10toCURs)
```

### T10_to_CMDs

```{r}
#Abtain reengineered dataset. 
subID.T10toCMDs <- c(T10, 
                    CMD.ind
                   ) 
emphasis.lwd.T10toCMDs <- c(rep(3, length(T10)), rep(4, 3), rep(3, length(CMD.ind)-3))
emphasis.lty.T10toCMDs <- c(rep(1, length(T10)), rep(4, 3), rep(3, length(CMD.ind)-3))
#Use subID throught T10ENDS and CYCLES
T10ends.Reengineered.T10toCMDs <- TD_All.ts[, paste0(subID.T10toCMDs, "_hpft")]
Cycles.Reengineered.T10toCMDs <- TD_All.ts[, paste0(subID.T10toCMDs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(T10ends.Reengineered.T10toCMDs, "DEEPLEARN/T10ends_Reengineered_T10toCMDs.csv", col.names = T10UE)
write.csv(Cycles.Reengineered.T10toCMDs, "DEEPLEARN/Cycles_Reengineered_T10toCMDs.csv", col.names = T10UE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(T10ends.Reengineered.T10toCMDs, 
                                 emphasis.lwd.T10toCMDs, emphasis.lty.T10toCMDs)
```

### T10_to_EQTs

```{r}
#Abtain reengineered dataset. 
subID.T10toEQTs <- c(T10,
                    "IH00C1", "IF00C1", 
                    "SPX", "FTSE"
                   ) 
emphasis.lwd.T10toEQTs <- c(rep(3, length(T10)), rep(4, 2), rep(3, 2))
emphasis.lty.T10toEQTs <- c(rep(1, length(T10)), rep(4, 2), rep(3, 2))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T10toEQTs <- TD_All.ts[, paste0(subID.T10toEQTs, "_hpft")]
Cycles.Reengineered.T10toEQTs <- TD_All.ts[, paste0(subID.T10toEQTs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T10toEQTs, "DEEPLEARN/Trends_Reengineered_T10toEQTs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T10toEQTs, "DEEPLEARN/Cycles_Reengineered_T10toEQTs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T10toEQTs, 
                                 emphasis.lwd.T10toEQTs, emphasis.lty.T10toEQTs)
```

T10_C
==================================================

T10_CYCLES {.tabset .tabset-fade data-height=6500}
-------------------------------------

### T10_to_Yields

```{r}
#subID is used all throught T10ENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T10toYield <- TD_All.ts.2[, paste0(subID.T10toYield, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T10toYield, "DEEPLEARN/Cycles_Visualizing_T10toYield.csv", col.names = T10UE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T10toYield, Major_id = 1)
```

### T10_to_TRs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T10toTRs <- TD_All.ts.2[, paste0(subID.T10toTRs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T10toTRs, "DEEPLEARN/Cycles_Visualizing_T10toTRs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T10toTRs, Major_id = 1)
```

### T10_to_CURs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T10toCURs <- TD_All.ts.2[, paste0(subID.T10toCURs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T10toCURs, "DEEPLEARN/Cycles_Visualizing_T10toCURs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T10toCURs, Major_id = 1)
```

### T10_to_CMDs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T10toCMDs <- TD_All.ts.2[, paste0(subID.T10toCMDs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T10toCMDs, "DEEPLEARN/Cycles_Visualizing_T10toCMDs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T10toCMDs, Major_id = 1)
```

### T10_to_EQTs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T10toEQTs <- TD_All.ts.2[, paste0(subID.T10toEQTs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T10toEQTs, "DEEPLEARN/Cycles_Visualizing_T10toEQTs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T10toEQTs, Major_id = 1)
```

T11_T
==================================================

T11_TRENDS {.tabset .tabset-fade}
-------------------------------------

### T11_to_Yields

```{r}
#Abtain reengineered dataset. 
subID.T11toYield <- c(T11, 
                     "CN_10yry", "US_10yry",
                     "UK_10yry", "GR_10yry", "IT_10yry", "AU_10yry", "INA_10yry", "IND_10yry"
                     ) 
emphasis.lwd.T11toYield <- c(rep(3, length(T11)), rep(4, 2), rep(3, 6))
emphasis.lty.T11toYield <- c(rep(1, length(T11)), rep(4, 2), rep(3, 6))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T11toYield <- TD_All.ts[, paste0(subID.T11toYield, "_hpft")]
Cycles.Reengineered.T11toYield <- TD_All.ts[, paste0(subID.T11toYield, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T11toYield, "DEEPLEARN/Trends_Reengineered_T11toYield.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T11toYield, "DEEPLEARN/Cycles_Reengineered_T11toYield.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T11toYield, 
                                 emphasis.lwd.T11toYield, emphasis.lty.T11toYield)
```

### T11_to_TRs

```{r}
#Abtain reengineered dataset. 
subID.T11toTRs <- c(T11,
                   "T00C1", 
                   "TF00C1",
                   "TY00Y",
                   "FV00Y"
                   ) 
emphasis.lwd.T11toTRs <- c(rep(3, length(T11)), rep(4, 2), rep(3, 2))
emphasis.lty.T11toTRs <- c(rep(1, length(T11)), rep(4, 2), rep(3, 2))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T11toTRs <- TD_All.ts[, paste0(subID.T11toTRs, "_hpft")]
Cycles.Reengineered.T11toTRs <- TD_All.ts[, paste0(subID.T11toTRs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T11toTRs, "DEEPLEARN/Trends_Reengineered_T11toTRs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T11toTRs, "DEEPLEARN/Cycles_Reengineered_T11toTRs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T11toTRs, 
                                 emphasis.lwd.T11toTRs, emphasis.lty.T11toTRs)
```

### T11_to_CURs

```{r}
#Abtain reengineered dataset. 
subID.T11toCURs <- c(T11, 
                    "USDCNH", "USDX",
                    CUR.ind) 
emphasis.lwd.T11toCURs <- c(rep(3, length(T11)), rep(4, 2), rep(3, 4))
emphasis.lty.T11toCURs <- c(rep(1, length(T11)), rep(4, 2), rep(3, 4))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T11toCURs <- TD_All.ts[, paste0(subID.T11toCURs, "_hpft")]
Cycles.Reengineered.T11toCURs <- TD_All.ts[, paste0(subID.T11toCURs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T11toCURs, "DEEPLEARN/Trends_Reengineered_T11toCURs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T11toCURs, "DEEPLEARN/Cycles_Reengineered_T11toCURs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T11toCURs, 
                                 emphasis.lwd.T11toCURs, emphasis.lty.T11toCURs)
```

### T11_to_CMDs

```{r}
#Abtain reengineered dataset. 
subID.T11toCMDs <- c(T11, 
                    CMD.ind
                   ) 
emphasis.lwd.T11toCMDs <- c(rep(3, length(T11)), rep(4, 3), rep(3, length(CMD.ind)-3))
emphasis.lty.T11toCMDs <- c(rep(1, length(T11)), rep(4, 3), rep(3, length(CMD.ind)-3))
#Use subID throught T11ENDS and CYCLES
T11ends.Reengineered.T11toCMDs <- TD_All.ts[, paste0(subID.T11toCMDs, "_hpft")]
Cycles.Reengineered.T11toCMDs <- TD_All.ts[, paste0(subID.T11toCMDs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(T11ends.Reengineered.T11toCMDs, "DEEPLEARN/T11ends_Reengineered_T11toCMDs.csv", col.names = T11UE)
write.csv(Cycles.Reengineered.T11toCMDs, "DEEPLEARN/Cycles_Reengineered_T11toCMDs.csv", col.names = T11UE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(T11ends.Reengineered.T11toCMDs, 
                                 emphasis.lwd.T11toCMDs, emphasis.lty.T11toCMDs)
```

### T11_to_EQTs

```{r}
#Abtain reengineered dataset. 
subID.T11toEQTs <- c(T11,
                    "IH00C1", "IF00C1", 
                    "SPX", "FTSE"
                   ) 
emphasis.lwd.T11toEQTs <- c(rep(3, length(T11)), rep(4, 2), rep(3, 2))
emphasis.lty.T11toEQTs <- c(rep(1, length(T11)), rep(4, 2), rep(3, 2))
#Use subID throught TRENDS and CYCLES
Trends.Reengineered.T11toEQTs <- TD_All.ts[, paste0(subID.T11toEQTs, "_hpft")]
Cycles.Reengineered.T11toEQTs <- TD_All.ts[, paste0(subID.T11toEQTs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Trends.Reengineered.T11toEQTs, "DEEPLEARN/Trends_Reengineered_T11toEQTs.csv", col.names = TRUE)
write.csv(Cycles.Reengineered.T11toEQTs, "DEEPLEARN/Cycles_Reengineered_T11toEQTs.csv", col.names = TRUE)
##Ploting Results
AssFun$Reengineered_Dataset_Plot(Trends.Reengineered.T11toEQTs, 
                                 emphasis.lwd.T11toEQTs, emphasis.lty.T11toEQTs)
```

T11_C
==================================================

T11_CYCLES {.tabset .tabset-fade data-height=6500}
-------------------------------------

### T11_to_Yields

```{r}
#subID is used all throught T11ENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T11toYield <- TD_All.ts.2[, paste0(subID.T11toYield, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T11toYield, "DEEPLEARN/Cycles_Visualizing_T11toYield.csv", col.names = T11UE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T11toYield, Major_id = 1)
```

### T11_to_TRs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T11toTRs <- TD_All.ts.2[, paste0(subID.T11toTRs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T11toTRs, "DEEPLEARN/Cycles_Visualizing_T11toTRs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T11toTRs, Major_id = 1)
```

### T11_to_CURs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T11toCURs <- TD_All.ts.2[, paste0(subID.T11toCURs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T11toCURs, "DEEPLEARN/Cycles_Visualizing_T11toCURs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T11toCURs, Major_id = 1)
```

### T11_to_CMDs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T11toCMDs <- TD_All.ts.2[, paste0(subID.T11toCMDs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T11toCMDs, "DEEPLEARN/Cycles_Visualizing_T11toCMDs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T11toCMDs, Major_id = 1)
```

### T11_to_EQTs

```{r}
#subID is used all throught TRENDS and CYCLES to keep coinherence. 
Cycles.Visualizing.T11toEQTs <- TD_All.ts.2[, paste0(subID.T11toEQTs, "_hpfc")]
#Output to CSV files for Deep Learning Modeling.
write.csv(Cycles.Reengineered.T11toEQTs, "DEEPLEARN/Cycles_Visualizing_T11toEQTs.csv", col.names = TRUE)
AssFun$Cycles_Visualize_f3(Cycles.Visualizing.T11toEQTs, Major_id = 1)
```
